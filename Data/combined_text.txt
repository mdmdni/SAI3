MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Yi Yu 1 2 Song Xia 2 Siyuan Yang 2 Chenqi Kong 2 Wenhan Yang † 3 Shijian Lu 4 Yap-Peng Tan 2 Alex C. Kot 2
Abstract
Most existing unlearnable strategies focus on pre-
venting unauthorized users from training single-
task learning (STL) models with personal data.
Nevertheless, the paradigm has recently shifted
towards multi-task data and multi-task learning
(MTL), targeting generalist and foundation mod-
els that can handle multiple tasks simultaneously.
Despite their growing importance, MTL data and
models have been largely neglected while pursu-
ing unlearnable strategies. This paper presents
MTL-UE, the first unified framework for generat-
ing unlearnable examples for multi-task data and
MTL models. Instead of optimizing perturbations
for each sample, we design a generator-based
structure that introduces label priors and class-
wise feature embeddings which leads to much bet-
ter attacking performance. In addition, MTL-UE
incorporates intra-task and inter-task embedding
regularization to increase inter-class separation
and suppress intra-class variance which enhances
the attack robustness greatly. Furthermore, MTL-
UE is versatile with good supports for dense pre-
diction tasks in MTL. It is also plug-and-play
allowing integrating existing surrogate-dependent
unlearnable methods with little adaptation. Exten-
sive experiments show that MTL-UE achieves su-
perior attacking performance consistently across
4 MTL datasets, 3 base UE methods, 5 model
backbones, and 5 MTL task-weighting strategies.
†Corresponding author 1Rapid-Rich Object Search Lab, Inter-
disciplinary Graduate Programme, Nanyang Technological Uni-
versity, Singapore 2School of Electrical and Electronic Engineer-
ing, Nanyang Technological University, Singapore 3PengCheng
Laboratory, Shenzhen, China 4School of Computer Science and
Engineering, Nanyang Technological University, Singapore. Cor-
respondence to: Yi Yu <yuyi0010@e.ntu.edu.sg>, Wenhan Yang
<yangwh@pcl.ac.cn>.
Proceedings of the 42 nd International Conference on Machine
Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).
5 O'clock Shadow
Arched Eyebrows
Young
⋮
Clean MTL Dataset
5 O'clock Shadow
Arched Eyebrows
Young
⋮
Protected MTL Dataset
⋯
⋯
Train
Train
Test
Test
Task 1: 93.3%
Task 2: 82.4%
Task 40: 86.9%
⋮
⋯
High Performance
Clean Test Data
Task 1: 50.4%
Task 2: 42.1%
Task 40: 24.4%
⋮
⋯
Clean Test Data
Low Performance
MTL-UE
Perturbation
MTL Models
MTL Models
Figure 1. Illustration of MTL-UE to prevent unauthorized training
of MTL models on datasets like CelebA (Liu et al., 2015), having
40 binary attribute classifications. MTL-UE adds invisible, sample-
specific perturbations to transform a clean dataset into a protected
one, leading to poor test performance of trained MTL models.
1. Introduction
Multi-task learning (MTL) (Caruana, 1993; Guo et al., 2020)
is a branch of machine learning that tackles multiple tasks
simultaneously, making it a more practical approach than
single-task learning (STL). For instance, autonomous ve-
hicles (Achituve et al., 2024) need to detect objects, track
vehicles, monitor lanes, and estimate free space in real time.
MTL trains a single model to handle multiple tasks, reduc-
ing the need for separate models. By leveraging shared
data across tasks, MTL lowers computational costs and im-
proves generalization (Baxter, 2000), making it essential
in fields like vision (Liu et al., 2019a; Misra et al., 2016),
NLP (Chen et al., 2021; Fontana et al., 2024), autonomous
driving (Chowdhuri et al., 2019; Chen et al., 2018), and
recommendation systems (Hadash et al., 2018).
Deep neural networks have achieved impressive success
across machine learning tasks (Hu et al., 2024; Yang et al.,
2024; Jin et al., 2025a;b), but also raised growing AI se-
curity concerns (Gao et al., 2019; 2022; Yu et al., 2021;
2023a; 2022b; 2023b; 2024b; 2025; Wang et al., 2024a;
2025b; Zheng et al., 2024; Xia et al., 2024b;a; 2025; Liu
et al., 2025a;b). As large-scale models become more preva-
lent, massive data is likely to be scraped from the web
1
arXiv:2505.05279v1  [cs.LG]  8 May 2025
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
and incorporated into training datasets, naturally raising
concerns about the unauthorized use of personal informa-
tion for training DNNs (Burt, 2020; Vincent, 2019). This
has led to efforts to develop defenses that prevent DNNs
from exploiting private data. In STL, privacy protection
methods (Feng et al., 2019; Sun et al., 2024) have been
widely explored. These methods apply carefully crafted
perturbations to images to compromise the generalization
of models, commonly referred to as unlearnable examples
(UE) (Huang et al., 2021; Yu et al., 2024a;c), and are also
known as perturbative availability (Liu et al., 2023) or in-
discriminate poisoning attacks (He et al., 2023). Models
trained on these UE often capture spurious features, which
are patterns added to the data that are irrelevant to the ac-
tual task. While UE have been extensively studied for STL,
their use in complex MTL scenarios as well as the related
datasets, e.g., NYUv2 (Nathan Silberman & Fergus, 2012)
with semantic segmentation, depth estimation, and normal
estimation tasks, remains a challenge. These include man-
aging the heightened complexity of perturbations designed
to introduce spurious features across a greater number of
tasks simultaneously, and dealing with more complex tasks
that extend beyond classification.
In this work, we propose MTL-UE, a framework for gen-
erating effective UE for MTL, with the goal of degrading
the performance of all tasks in both MTL and STL mod-
els, as shown in Fig. 1. We first conduct a straightforward
empirical benchmark analysis of existing methods to re-
veal our motivations. We implement several baseline UE
methods, including surrogate-free methods using predefined
shortcut patterns as class-wise perturbations, and surrogate-
dependent methods relying on surrogate models to optimize
sample-wise perturbations. Our initial findings suggest that
surrogate-dependent methods underperform for both MTL
and STL models, due to poor control over intra-class vari-
ance caused by independent optimization for each sample.
Patch-based AR (Sandoval-Segura et al., 2022), as shown
in Sec. 4.2, using class-wise perturbations in task-specific
patches, performs better with lower intra-class variance but
loses effectiveness as tasks increase, likely due to smaller
patch sizes and limited representation capacity.
Building on these insights, we propose a plug-and-play
framework to address these challenges by generating UE
through class-wise feature embedding injections. By incor-
porating task label priors via embeddings, we narrow the
perturbation searching space from ∥δ∥∞≤
8
255 to the de-
coder’s output space, resulting in lower intra-class variance.
This approach effectively combines spurious features from
multiple tasks into a unified perturbation. In addition to the
generator’s structural design, we introduce intra-task and
inter-task embedding regularization (Intra-ER & Inter-ER)
to improve inter-class distance and minimize feature space
redundancy, further improving the attack’s effectiveness. In
summary, our contributions are outlined below:
• To the best of our knowledge, we propose MTL-UE, the
first plug-and-play framework for generating UE on MTL
datasets, effective against both MTL and STL models, and
compatible with any surrogate-dependent UE methods.
• MTL-UE comprises an encoder-decoder network paired
with learnable class-wise feature embeddings, which lower
the intra-class variance of spurious features for each task.
The addition of intra-task and inter-task embedding regular-
ization further enhances performance.
• MTL-UE can extend beyond MTL classifications to multi-
ple dense prediction tasks by using task-specific embedding
modules to map task labels to embeddings.
• Experiments on 4 MTL datasets, 3 base UE methods, 5
backbones, and 5 MTL task-weighting strategies show con-
sistent improvements of MTL-UE in attacking performance.
Moreover, MTL-UE supports partial protection, making
some tasks unlearnable while keeping others learnable.
2. Related Work
Data Poisoning. Data poisoning attacks (Barreno et al.,
2010; Goldblum et al., 2022) manipulate training data to
disrupt the test-time performance of models, and are cat-
egorized into integrity attacks and availability attacks. In-
tegrity attacks, such as backdoor attacks (Gu et al., 2017;
Schwarzschild et al., 2021), trigger malicious behavior with
specific inputs, while availability attacks degrade model per-
formance on test sets (Biggio et al., 2012; Xiao et al., 2015).
Typically, they inject poisoned data into the clean training
set, where a small portion of the samples, with unrestricted
changes, are added (Koh & Liang, 2017; Zhao & Lao, 2022;
Lu et al., 2023). Though malicious, these samples are often
detectable and have a limited overall impact.
Unlearnable Examples (UE). UE (Huang et al., 2021;
Zhang et al., 2023; Zhu et al., 2024a;b; Liu et al., 2024a;b;
Chen et al., 2024; Qin et al., 2023b; 2024; 2023a; Meng
et al., 2024; Lin et al., 2024; Wang et al., 2024b; 2025a)
is an emerging approach, where subtle modifications, such
as bounded perturbations ∥δ∥∞≤
8
255, are applied across
the entire training dataset without altering the correct labels.
This method shows potential for data protection, resulting
in models performing close to random guessing on clean
test data. EM (Huang et al., 2021) applies error-minimizing
noise, while NTGA (Yuan & Wu, 2021) generates noise
via neural tangent kernels. TAP (Fowl et al., 2021) uses
targeted adversarial examples as UE, and REM (Fu et al.,
2022) targets adversarial training (AT) (Madry et al., 2018).
LSP (Yu et al., 2022a) and AR (Sandoval-Segura et al.,
2022) are surrogate-free UE. OPS (Wu et al., 2023) uses
one-pixel shortcuts to improve robustness against AT and
2
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
strong augmentations.
Multi-task Learning (MTL). MTL focuses on learning
multiple tasks in a joint manner, typically using a shared
encoder with task-specific heads for each task (Ruder, 2017;
Zhang & Yang, 2021; Sener & Koltun, 2018; Standley et al.,
2020; Fifty et al., 2021; Navon et al., 2022). A major
focus in MTL research is the optimization process. The
usual method uses linear scalarization (LS) along with a
grid or random search to find the best weight vectors (Lin
et al., 2019). To address task balancing and conflict resolu-
tion, strategies fall into loss-based and gradient-based (Dai
et al., 2023). Loss-based methods assign task weights based
on factors like task difficulty (Guo et al., 2018), random
weights (Lin et al., 2022), geometric mean of losses (Yun &
Cho, 2023), or uncertainty (Kendall et al., 2018). Gradient-
based approaches adjust gradients directly, e.g., PCGrad (Yu
et al., 2020) projects gradients to prevent conflicts, Aligned-
MTL (Senushkin et al., 2023) aligns gradient components,
and FairGrad (Ban & Ji, 2024) adopts utility maximization.
3. Preliminaries
UE (Huang et al., 2021; Fowl et al., 2021; Wang et al.,
2024b) leverage clean-label data poisoning to trick DNNs
into learning minimal useful knowledge from the data,
thereby achieving the objective of data protection. Let T
and D denote the clean training and test datasets, respec-
tively. A model F(·; θ) trained on T typically performs well
on D. UE aims to transform T into an unlearnable dataset
P, causing F(·; θ) trained on P to perform poorly on D.
In a C-class image classification, T = {(xi, yi)}N
i=1 con-
tains N samples, where xi ∈Rd are inputs, and yi ∈
{1, . . . , C} are labels. P is crafted by adding perturbations
δi to each xi, such that P = {(xi + δi, yi)}N
i=1. Perturba-
tions δ ∈S are constrained to maintain visual imperceptibil-
ity, where S denotes the feasible region, e.g., ∥δ∥∞≤
8
255.
The attacker’s success is measured by the accuracy of F
trained on P when evaluated on D. UE methods can be
classified into two categories based on whether a surrogate
model is required for optimizing the perturbations.
Surrogate-free methods (Yu et al., 2022a) do not rely on a
surrogate model, and instead utilize predefined shortcut pat-
terns as class-wise perturbations. δi added to each sample
xi depend solely on its label yi, i.e., δi =δ(yi).
Surrogate-dependent methods optimize sample-wise per-
turbations δi for each data (xi, yi) using surrogate models.
Most follow variations of error-minimizing (EM) (Huang
et al., 2021) or error-maximizing (AP) (Fowl et al., 2021).
EM constructs δi by solving the bi-level optimizations:
min
θ
X
(xi,yi)∈T

min
δi L(F ′(xi + δi; θ), yi)

, s.t. ∥δi∥p ≤ϵ, (1)
where F ′ is the surrogate model. Typically, the inner min-
imization employs the first-order optimization approach
PGD (Madry et al., 2018), and the outer one optimizes the
parameters using optimizers such as SGD. In contrast, AP
constructs δi to maximize the loss of the pretrained F ′ on
clean dataset T , i.e. generating adversarial examples:
max
δi
X
(xi,yi)∈T

L(F ′(xi + δi; θ∗), yi)

,
s.t. ∥δi∥p ≤ϵ. (2)
Multi-task learning (MTL) enhances the performance
of several related tasks by training them simultaneously.
The training samples are typically tuples consisting of a
shared input for all tasks and the labels for K tasks, i.e.,
TMTL ={(xi, {yk
i }K
k=1)}N
i=1, where N is the number of train-
ing samples. Our focus is on the scenario where the input
are consistent across tasks. When the input varies for each
task, it is often referred to as multi-domain learning (Royer
et al., 2023). In such cases, UE for each domain dataset can
usually be constructed independently. Common architec-
tures for MTL (Achituve et al., 2024) have a shared encoder
f(·; θf) and task-specific linear heads gk(·; θgk). A MTL
problem involves a set of K tasks with a loss vector:
min
{θf ,{θgk }K
k=1} L = (L1(θf, θg1), · · · , LK(θf, θgK))⊤,
(3)
where Lk(θf, θgk) is the loss of the k-th task. An MTL
algorithm seeks to optimize all tasks simultaneously by
leveraging the shared structure and information across them.
4. Methodology
4.1. Problem Formulation
Previous UE (Feng et al., 2019; Huang et al., 2021) mainly
target STL with K = 1 task. However, practical scenarios
often involve multi-task datasets. This work aims to develop
UE for these datasets, ensuring better data protection against
both MTL and STL models, with the following goals1:
• Effectiveness against MTL models: For a MTL model
FMTL = {f, {gk}K
k=1} trained on the poisoned multi-task
dataset PMTL = {(xi +δi, {yk
i }K
k=1)}N
i=1, the objective is to
maximize the loss on clean test data for all tasks, i.e., maxi-
mizing PK
k=1Lk(x, yk; θf, θgk).
• Effectiveness against STL models: For any k-th task
and a STL model F k
STL = {f, gk} trained on the poisoned
dataset Pk
MTL ={(xi+δi, yk
i )}N
i=1 (the k-th attribute of PMTL),
the objective is to maximize the loss Lk(x, yk; θf, θgk).
4.2. Baseline methods for UE against MTL
This section presents several MTL-specific baseline UE
methods, starting with surrogate-dependent methods that
1We will omit “MTL” in TMTL and PMTL in later sections.
3
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Figure 2. Performance of UE (Accuracy ↓) Vs. the number of tasks on the CelebA (Liu et al., 2015) for both MTL and STL models.
Table 1. Intra-class std of the features for various UE methods. (P)
and (A) are the patch and averaging based. All 40 tasks are used.
UEs →
Clean EM
TAP
SEP LSP (P) AR (P) LSP (A) AR (A)
Average
5.357 2.191 3.656 6.719 1.828
1.733
5.264
5.180
Maximum 91.97 82.13 103.12 96.24 34.84
20.59
93.50
103.41
typically use the MTL model itself as the surrogate model.
Next, we consider surrogate-free methods and class-wise
perturbations. Treating each combination {yk}K
k=1 as a dis-
tinct class, where yk ∈{1, . . . , Ck}, yields a total of QK
k=1Ck
class-wise perturbations, which grows exponentially with
K. This reduces the average number of data points per per-
turbation to
N
QK
k=1Ck , complicating the creation of spurious
relationships between perturbations and target combinations.
To address this, we propose generating separate sets of per-
turbations for each task, {{δk
yk}Ck
yk=1}K
k=1, and then combining
them into a final perturbation. We explore two strategies
for this combination: (1) Averaging-based: using the mean
of {δk
yk}K
k=1 as δ; and (2) Patch-based: adding {δk
yk}K
k=1 to
task-specific non-overlapping patches of x.
We assess UE effectiveness across varying task numbers on
CelebA (Liu et al., 2015), a facial dataset with 40 binary
classifications. We evaluate 5 UE methods: EM (Huang
et al., 2021), TAP (Fowl et al., 2021), and SEP (Chen et al.,
2023) are surrogate-dependent using surrogate MTL models
with uniform task-weighting, while LSP (Yu et al., 2022a)
and AR (Sandoval-Segura et al., 2022) are surrogate-free.
Effectiveness of UE Vs. the number of tasks. To examine
the impact of task quantity on the effectiveness of baseline
UE, we select the first k tasks, generate the corresponding
UE, and train MTL and STL models. The experimental
results as shown in Fig. 2 highlight several key findings:
1. STL models are more robust to UE than MTL models.
2. As k increases, the performance of most UE initially
increases on MTL and STL models, then declines, with near
total failure on STL when all tasks are included.
3. Patch-based AR excels in both MTL and STL models.
The first observation arises from MTL models sharing rep-
resentations across tasks, allowing them to more effectively
capture similar shortcut patterns in UE and enhancing their
focus on spurious features over benign ones. The following
explanations address the remaining two points.
As discussed in (Yu et al., 2024a), spurious features with
lower intra-class variance and greater inter-class distance
are more effective for attacks. We denote the encoder’s
features in MTL models as z = [z1, z2, . . . , zD] ∈RD.
For each zd, we compute the average relative intra-class
std (standard deviation) across all classes and tasks as
1
P
k Ck
P
k
P
yk
h
Std[zd|yk]
E[zd|yk]
i
. The average and maximum val-
ues across the D dimensions are in Tab. 1. Note that features
are from the MTL models using the poisoned dataset.
Our results show that patch-based AR has the lowest intra-
class variance, with another patch-based approach that ranks
second. This may be due to class-wise perturbations being
applied to distinct, task-specific patches, thereby minimizing
intra-class variance across locations. These lower intra-class
variances likely contribute to the effectiveness. However, as
k increases, the reduction in patch size constrains the pertur-
bations’ ability as effective shortcuts, ultimately leading to
a performance decline. In contrast, averaging-based AR and
LSP have higher intra-class variance and perform worse than
patch-based methods, as aggregating perturbations across
tasks can introduce conflicts, leading to suboptimal results.
Surrogate-dependent methods like EM, TAP, and SEP op-
timize perturbations individually for each sample, which
limits control over intra-class variance. This limitation can
reduce performance, particularly as k increases, since per-
turbations must serve as shortcuts across multiple tasks,
complicating the optimization. As shown in Tab. 1 and
Fig. 2, most UE methods have higher intra-class variance
and lower performance compared to patch-based AR and
LSP, although EM achieves the second-best attack perfor-
mance among MTL models and the lowest intra-class vari-
ance among surrogate-dependent methods. Overall, we see
that LSP (A), AR (A), TAP, and SEP achieve intra-class vari-
ance comparable to that of clean data, resulting in limited
effectiveness in attacking both MTL and STL models.
4.3. MTL-UE: a plug-and-play UE method for MTL
What is missing in existing UE methods? Based on our ob-
servations in Sec. 4.2, we identify: (1) Surrogate-dependent
4
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
𝑧
𝑒𝑦1
1
Encoder
𝐸(∙; 𝜙𝐸)
Decoder
𝐷(∙; 𝜙𝐷)
𝒙
𝑒𝑦2
2
𝑒𝑦𝐾−1
𝐾−1
𝑒𝑦𝐾
𝐾
⋯
𝑦1
𝑦2
⋮
𝑦𝐾−1
𝑦𝐾
↑
𝒚
1
0
⋮
0
1
0
1
⋮
0
1
1
1
⋮
0
1
0
0
⋮
0
1
𝜹
𝒙+ 𝜹
Intra-task Embedding Regularization
Inter-task Embedding Regularization
Clip
Figure 3. Visual depiction of MTL-UE, concatenating the task-specific class-wise embeddings with latents to generate UE for MTL data.
Algorithm 1 Optimization of the UE Generator in MTL-UE
Input:
Surrogate model F ′
MTL = {f, {gk}K
k=1}, encoder
E(·; ϕE), decoder D(·; ϕD), embeddings

{ek
i }Ck
i=1
	K
k=1,
clean multi-task dataset T = {(xi, {yk
i }K
k=1)}N
i=1, epochs R,
Adam optimizer, weights λ1 & λ2, Train-surrogate, iterations I,
bound ϵ, loss function of the base UE method Lb
Output: Optimized E(·; ϕE), D(·; ϕD),

{ek
i }Ck
i=1
	K
k=1
# Initialize surrogate model if no training is needed in the Alg.
if not Train-surrogate then
Initialize F ′
MTL with pretrained weights on T
end if
for epoch ←1 to R do
# Optimize the perturbation generator
for image batch (x, y = {yk}K
k=1) ∈T do
z=E(x; ϕE), δ =Clip(D([z, e1
y1, . . . , eK
yK]; ϕD), −ϵ, ϵ)
L = Lb(F ′
MTL, x + δ, y) + λ1 · LIntra + λ2 · LInter
Minimize L with Adam to update ϕE, ϕD, and ek
i
end for
if Train-surrogate then
# Optimize F ′
MTL if training is needed
for epoch ←1 to I do
Sample image batch (x, y = {yk}K
k=1) ∈T
δ =Clip(D([E(x; ϕE), e1
y1, . . . , eK
yK]; ϕD), −ϵ, ϵ)
Train F ′
MTL with Adam on (x + δ, y)
end for
end if
end for
UE perform poorly due to uncontrolled intra-class variance
caused by individual sample optimization, and the pixel-
level search space which is hard to control; (2) Surrogate-
free UEs face challenges primarily due to the imperfect
fusion of class-wise perturbations from different tasks.
This raises the question: Can we reduce the pixel-level
searching space to learn task-specific class-wise spurious
features and use an integration network to merge them into
a unified perturbation?
To address these, we propose MTL-UE, which generates
UEs by injecting class-wise features to manage intra-class
variance and combining spurious features from multiple
tasks into a unified perturbation. The framework is shown in
Fig. 3. For any input x, the encoder E(·; ϕE) maps it to a la-
tent representation z. Based on its labels {yk}K
k=1, the corre-
sponding learnable class-wise feature embeddings {ek
yk}K
k=1
are selected. The embeddings and z are concatenated, and
fed into a decoder D(·; ϕD) to generate the final perturba-
tions for x. To regulate the amplitude of the perturbations,
a clip operation is applied following the decoder. By shift-
ing from direct perturbation searching to spurious features
and integration network learning, MTL-UE can seamlessly
integrate with any surrogate-dependent method.
Besides MTL-UE’s structural design, we introduce embed-
ding regularizations to further improve attack performance:
• Intra-task ER (Intra-ER). This term minimizes the co-
sine similarity between embeddings within each task, ensur-
ing diversity among the embeddings:
LIntra =
2
PK
k=1 Ck(Ck −1)
K
X
k=1
Ck−1
X
m=1
Ck
X
n=m+1
cos(ek
m, ek
n).
(4)
• Inter-task ER (Inter-ER). This term promotes geometric
independence between embeddings across different tasks:
LInter =
1
PK−1
k=1
PK
l=k+1CkCl
K−1
X
k=1
K
X
l=k+1
Ck
X
m=1
Cl
X
n=1
|cos(ek
m, el
n)|. (5)
For Intra-ER, as discussed in (Yu et al., 2024a), greater
inter-class distance of spurious features enhances attack per-
formance. This distance can be expressed as∥ek
m−ek
n∥2
2 =
∥ek
m∥2
2 + ∥ek
n∥2
2 −2∥ek
m∥2∥ek
n∥2·cos(ek
m, ek
n). To ensure the
model effectively learns the introduced features, it is impor-
tant to enlarge the inter-class distance for each task. How-
ever, simply increasing the norm of ek
m doesn’t suffice, as
the decoder D(·; ϕD) can rescale the weights. Thus, mini-
mizing cosine similarity between embeddings is better.
For Inter-ER, geometric independence offers several ben-
efits: (1) Minimized Redundancy: It helps minimize re-
dundancy in the features, and the decoder can exploit the
5
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
𝑧
Encoder
Decoder
𝒙
𝜹
𝒚𝟏
𝒚𝟐
𝒚𝟑
𝐸(∙; 𝜙𝐸)
𝐷(∙; 𝜙𝐷)
Embedder
ℰ1(∙; 𝜙ℰ1)
Embedder
ℰ2(∙; 𝜙ℰ2)
Embedder
ℰ3(∙; 𝜙ℰ3)
Clip
Figure 4. MTL-UE applied to dense prediction tasks, e.g., NYUv2.
unique information carried by each feature. (2) Reduced
Coupling: It helps reduce coupling, and the decoder can fo-
cus on each feature independently, leading to more accurate
perturbations. (3) Improved Interpretability: Geometric in-
dependence facilitates understanding of the role each feature
plays in generating spurious features.
Optimization of MTL-UE. The generator optimization in
Alg. 1 can be applied to surrogate-dependent UE methods.
After optimization, we transform clean T to unlearnable P.
Advantages. MTL-UE offers key advantages over baselines.
First, by incorporating task label priors through embeddings,
we reduce the perturbation search space from ∥δ∥∞≤
8
255
to the decoder’s output space, leading to lower intra-class
variance. Second, since the generator is trained across the
entire dataset, it captures global features more effectively,
supporting the effective learning of spurious features. Ad-
ditionally, both Intra-ER and Inter-ER are introduced to
further improve attack performance.
4.4. Application to Dense Prediction Tasks
In this section, we demonstrate the effective application of
MTL-UE to multi-task datasets for dense prediction tasks,
using the NYUv2 dataset (Nathan Silberman & Fergus,
2012) as an example. As shown in Fig. 4, instead of using
class-wise embeddings for each task, we apply the embed-
ding module Ek(·; ϕEk) to map the corresponding dense la-
bel yk to spurious features. Since MTL-UE on such dataset
requires manipulating dense prediction results, where redun-
dancy in spurious features is minimal, we do not employ
embedding regularizations here.
5. Experiments
5.1. Experimental Setup
Datasets. We choose 4 popular multi-task vision datasets:
CelebA (Liu et al., 2015), ChestX-ray14 (Wang et al., 2017),
UTKFace (Zhang et al., 2017), and NYUv2 (Nathan Silber-
Figure 5. Performance Vs. the number of tasks on the CelebA.
man & Fergus, 2012). CelebA has 202,599 face images
with 40 binary attribute classifications. We use 162,770
images for training and 19,962 for testing, resizing all to
70×70. ChestX-ray14 has 112,000 chest X-ray images with
14 binary classes for thoracic diseases. The official splits are
used, with images resized to 256×256. UTKFace has 23,705
images annotated for age, gender, and race. We follow
Karkkainen & Joo (2021) to treat age as a nine-class task,
gender as binary, and race as five-class, splitting 80% for
training and 20% for testing, with images resized to 140×140.
NYUv2 is an indoor scene dataset, with 795 training and
654 testing images for tasks like 13-class semantic segmen-
tation, depth estimation, and surface normal prediction. We
follow Liu et al. (2019b) to resize images to 288×384.
Models. We use ResNet-18 (He et al., 2016) as the shared
encoder for both surrogate and target models. To eval-
uate transferability, we also include various backbones
like ResNet-50, VGG16 (Simonyan & Zisserman, 2015),
DenseNet-121 (Huang et al., 2017), and ViT-B (Dosovitskiy
et al., 2021) for the target models. For MTL models, we em-
ploy the HPS (Caruana, 1993) architecture, which includes
a shared feature extractor and task-specific heads.
Task-weighting for MTL. We adopt LS with a uniform
weight. To assess transferability, we include Random Loss
Weighting (RLW) (Lin et al., 2022), Uncertainty Weighting
(UW) (Kendall et al., 2018), Aligned-MTL (Senushkin et al.,
2023), and FairGrad (Ban & Ji, 2024).
Unlearnable examples.
We include baseline methods
EM (Huang et al., 2021), TAP (Fowl et al., 2021), and
SEP (Chen et al., 2023) with an ℓ∞=
8
255 bound, and
LSP (Yu et al., 2022a) and AR (Sandoval-Segura et al.,
2022) with an ℓ2 = 1 bound, following default settings.
Adaptations for MTL are detailed in Sec. 4.2. MTL-UE
is compatible with EM, TAP, and SEP, resulting in MTL-
UE-EM, MTL-UE-TAP, and MTL-UE-SEP, all using the
same ℓ∞=
8
255 bounds. More details of the baselines are in
6
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Table 2. Results on classification datasets: We report average accuracy (%) for CelebA and UTKFace, and AUC-ROC for ChestX-ray14.
For UTKFace, accuracy for age, race, and gender is also shown. All models use ResNet-18, and MTL models use LS for task weighting.
Dataset →
CelebA (Liu et al., 2015) ChestX-ray14 (Wang et al., 2017)
UTKFace (Zhang et al., 2017)
Model →
MTL
STL
MTL
STL
MTL
STL
Tasks →
Avg.↓
Avg.↓
Avg.↓
Avg.↓
Age↓Race↓Gender↓Avg.↓Age↓Race↓Gender↓Avg.↓
Clean
91.11
90.35
0.7577
0.6493
60.32 84.07
92.51
78.97 60.46 84.45
91.86
78.92
LSP (Patch) (Yu et al., 2022a)
78.12
84.80
0.6467
0.6543
18.40 17.51
49.83
28.58 19.62 15.04
62.62
32.43
AR (Patch) (Sandoval-Segura et al., 2022)
73.12
84.41
0.5306
0.6118
9.70 19.66
52.87
27.41 19.16 13.92
47.17
26.75
LSP (Average) (Yu et al., 2022a)
91.07
90.35
0.7218
0.6452
12.59 19.72
52.17
28.16 23.21 44.20
70.34
45.91
AR (Average) (Sandoval-Segura et al., 2022) 91.14
90.37
0.7259
0.6400
13.92 41.03
55.42
36.79 14.26 42.89
52.85
36.67
EM (Huang et al., 2021)
75.66
89.91
0.4976
0.5548
19.24 17.43
58.57
31.74 25.74 37.36
89.54
50.88
TAP (Fowl et al., 2021)
85.24
87.00
0.5478
0.6005
25.86 39.28
52.74
39.29 32.15 59.35
86.58
59.36
SEP (Chen et al., 2023)
84.25
89.91
0.5462
0.5926
25.42 44.03
52.64
40.70 33.73 60.59
88.04
60.78
MTL-UE-EM
74.38
74.26
0.4813
0.5302
10.00 12.78
54.73
25.84 9.66 12.47
56.81
26.32
MTL-UE-TAP
59.51
68.65
0.5341
0.6091
9.49 18.23
31.81
19.84 15.97 19.03
41.75
25.59
MTL-UE-SEP
58.73
76.39
0.4929
0.6068
7.28 16.20
40.08
21.19 7.26 21.84
55.61
28.24
EM
TAP
SEP
LSP (Patch)
AR (Patch)
LSP (Avg.)
AR (Avg.)
MTL-UE-EM MTL-UE-TAP MTL-UE-SEP
Clean
CelebA
NYUv2
EM
TAP
SEP
MTL-UE-EM
MTL-UE-TAP
MTL-UE-SEP
Clean
Figure 6. Visual results: Odd rows show perturbations (independently normalized to [0,1]), and even rows show poisoned images.
Table 3. Intra-class std of the features for competing UE methods.
UEs →EM
TAP
SEP LSP (P)AR (P)MTL-UE-EMMTL-UE-TAPMTL-UE-SEP
Avg.
2.191 3.656 6.719 1.828
1.733
1.715
2.130
2.387
Max.
82.13103.1296.24 34.84
20.59
18.04
47.93
64.57
Sec. A.1.
Model and MTL-UE training. Details for training the
MTL/STL models and MTL-UE are given in Sec. A.2.
Metrics. We use accuracy for CelebA and UTKFace, and
AUC-ROC for ChestX-ray14 (Lin et al., 2022; Achituve
et al., 2024). For NYUv2, we use mean Intersection over
Union (mIoU) and pixel accuracy (PAcc) for segmentation,
absolute errors (AErr) and relative errors (RErr) for depth
estimation, and mean absolute error (Mean) and median ab-
solute error (MED) for normal estimation (Liu et al., 2019b).
5.2. Experimental Results
We first evaluate MTL-UE on CelebA and ChestX-ray14 for
binary classifications. We then demonstrate its effectiveness
on UTKFace with more than two categories, and finally,
show its generalization to the NYUv2, which includes dense
predictions for both classification and regression tasks.
Results on the CelebA. As shown in Tab. 2, MTL-UE
consistently improves surrogate-dependent UE methods like
EM, TAP, and SEP. Notably, for STL models, MTL-UE-TAP
achieves around 68% accuracy, much better than the base-
line, while for MTL models, MTL-UE-TAP and MTL-UE-
SEP achieve accuracies below 60%. While MTL-UE-EM
has minimal impact on MTL models, it significantly boosts
performance on STL models. Fig.5 shows UE performance
as a function of task number, highlighting the effectiveness
of MTL-UE across varying task counts. MTL-UE shows
consistent results for MTL models when the task number
exceeds 10. For STL models, it performs well with around
15 tasks, while performance under more tasks remains an
area for future exploration. Tab. 3 demonstrates that MTL-
UE significantly reduces the intra-class standard deviation
of the features, resulting in improved attack performance.
Results on the ChestX-ray14. As shown in Tab. 2, MTL-
7
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Table 4. Quantitative results on the NYUv2 dataset. ResNet-18 is used as the encoder, with LS for task weighting in MTL models.
Model →
MTL
STL
Task →
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Metric →
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
Clean
53.05
75.01
0.3920
0.1665
23.72
17.29
53.16
75.30
39.80
16.50
22.53
16.00
EM
26.45
46.22
0.6109
0.2352
30.32
24.46
27.03
44.66
0.6280
0.2426
29.09
22.53
TAP
21.96
36.40
0.6412
0.2561
33.79
27.87
14.51
26.32
0.6340
0.2389
30.75
23.25
SEP
11.41
23.49
0.7113
0.2884
37.11
31.52
9.76
24.16
0.7517
0.2774
33.01
26.14
MTL-UE-EM
2.37
16.04
0.9249
0.3013
38.04
33.65
1.65
15.64
0.9109
0.2978
33.98
27.49
MTL-UE-TAP
16.88
30.37
0.9459
0.3161
39.69
34.61
17.14
30.01
1.1182
0.3607
41.56
35.08
MTL-UE-SEP
17.76
33.13
0.8260
0.2850
41.78
36.47
15.35
33.44
0.9570
0.3188
40.24
33.08
Table 5. Results of Transferability: performance on CelebA when transferring to MTL and STL models with different backbones or to
MTL models with various weighting strategies. Note that RN denotes the ResNet, and DN denotes the DenseNet.
Transfer to MTL and STL models with various backbones
Transfer to MTL models with various task-weighting
Model →
MTL (LS as the task-weighting)
STL
MTL(ResNet-18 as the backbone
Backbone/Weighting →RN-18 RN-50 VGG-16 DN-121 ViT-B Avg. RN-18 RN-50 VGG-16 DN-121 ViT-B Avg.
LS
UW RLW Align FairGrad
Avg.
Clean
91.11
91.20
91.33
91.37
89.39 90.88 90.35
90.13
90.40
89.61
87.25 89.55 91.11 90.82 91.00 91.08
90.75
90.95
LSP (Patch)
78.12
76.37
77.96
77.07
81.96 78.70 84.80
84.26
82.08
84.70
86.96 84.56 78.12 77.48 72.95 77.43
73.80
75.56
AR (Patch)
73.12
73.07
72.23
75.49
85.73 75.53 84.41
85.40
75.77
78.19
87.03 82.16 73.12 71.87 74.59 72.59
67.76
71.99
LSP (Average)
91.07
91.15
91.31
91.32
89.16 90.60 90.35
90.08
90.56
89.77
87.01 89.55 91.07 90.73 90.98 90.89
90.62
90.86
AR (Average)
91.14
91.20
64.78
67.09
89.35 80.31 90.37
90.12
89.47
88.15
87.16 89.05 91.14 90.80 91.01 90.93
90.69
90.91
EM
75.66
74.26
72.29
76.20
83.76 76.83 89.91
89.50
75.87
86.93
86.93 85.03 75.66 75.30 75.32 75.34
74.54
75.23
TAP
85.24
85.44
87.34
87.65
88.58 86.45 87.00
86.74
85.38
84.57
86.83 86.10 85.24 85.27 85.52 85.23
84.94
85.24
SEP
84.25
81.27
83.10
82.81
89.31 84.55 89.91
89.68
84.93
86.52
86.33 87.47 84.25 89.54 87.33 87.28
87.78
87.24
MTL-UE-EM
74.38
72.81
69.81
70.31
71.12 71.69 74.26
74.52
78.78
76.68
79.03 76.25 74.38 70.84 72.71 71.78
73.25
72.59
MTL-UE-TAP
59.51
64.76
60.50
60.36
76.69 64.76 68.65
70.73
68.27
75.14
83.22 73.20 59.51 58.66 62.95 63.60
56.61
60.27
MTL-UE-SEP
58.73
60.06
64.61
63.71
80.14 65.85 76.39
79.87
70.17
75.25
84.78 77.69 58.73 53.54 58.24 60.54
53.60
56.53
UE-EM excels, and MTL-UE-TAP and MTL-UE-SEP im-
prove upon TAP and SEP. As TAP and SEP use adversarial
examples, the low performance of clean surrogate models
lowers the results, explaining why MTL-UE-EM is better.
Results on the UTKFace. The results in Tab. 2 show that
with 3 tasks, MTL-UE consistently outperforms the base-
lines on both MTL and STL models, despite the increased
class numbers. Notably, on STL models, MTL-UE reduces
average accuracies by over 30% compared to the base UEs.
Sec. B.1 presents UE performance vs. task numbers.
Results on the NYUv2. We show the results on the NYUv2
involving dense classification and regression tasks. From
Tab. 4, MTL-UE consistently enhances the performance of
all baseline UE across all tasks. Each variant—MTL-UE-
EM, MTL-UE-TAP, and MTL-UE-SEP—exhibits different
trade-offs across the three tasks: MTL-UE-EM performs
best in segmentation, MTL-UE-TAP excels in depth esti-
mation, and MTL-UE-SEP outperforms others in surface
normal estimation. As AR and LSP cannot be applied to
dense tasks, they are not included for comparison.
Visual results. We offer visual results in Fig. 6. We can
see that compared to baselines, our perturbations are more
structured. For instance, MTL-UE-TAP displays clearer
semantic information than TAP, with more distinct contours
and sketch lines. The more structured perturbations tend
to have lower intra-class variance, leading to the improved
performance. Among the baselines, AR adopts ℓ2-norm, and
appears sparser, though the overall perturbation magnitudes
Table 6. Results of MTL-UE with smaller bounds on CelebA.
Bound →
ℓ∞= 8/255
ℓ∞= 6/255
ℓ∞= 4/255
ℓ∞= 2/255
Model →
MTL
STL
MTL
STL
MTL
STL
MTL
STL
MTL-UE-EM
74.38
74.26
74.38
75.11
75.56
76.25
78.81
79.24
MTL-UE-TAP
59.51
68.65
63.69
72.58
63.91
80.01
69.61
85.19
MTL-UE-SEP
58.73
76.39
60.98
80.45
61.82
83.58
81.35
86.82
Table 7. Ablation study of the MTL-UE design on CelebA.
Model →
MTL
STL
Base UE →
EM
TAP
SEP
EM
TAP
SEP
①: the baseline UE
75.66 85.24 84.25 89.91 87.00 89.91
②: w/o the feature embeddings
90.75 88.08 86.73 89.95 88.81 87.78
③: w/o the E(·; ϕE) and z
74.47 62.37 68.63 78.82 71.06 78.45
④: w/o the Intra-ER
77.87 63.07 63.41 79.82 69.52 79.25
⑤: w/o the Inter-ER
75.81 64.95 63.69 78.42 76.05 75.40
MTL-UE
74.38 59.51 58.73 74.26 68.65 76.39
are similar across all methods. More results are in Sec. B.5.
5.3. Discussion
Smaller perturbations. We evaluate smaller bounds ℓ∞=
2
255,
4
255,
6
255 alongside ℓ∞= 8
255. Tab. 6 shows MTL-UE are
effective, outperforming baselines even with larger bounds.
MTL-UE-EM excels on STL models, while the other two
perform better on MTL models under small bounds.
Transferability. We assess UE transferability to MTL and
STL models with varying encoder backbones and MTL
weighting strategies. Results on CelebA are shown in Tab. 5.
Our methods, particularly MTL-UE-TAP and MTL-UE-
8
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Table 8. Results of partial task protection on on the UTKFace.
Model →
MTL
STL
Protected task ↓
Age
Race
Gender
Age
Race
Gender
None
60.32
84.07
92.51
60.46
84.45
91.86
Age, Race
12.68
20.53
88.52
10.25
19.64
90.95
Age, Gender
10.72
78.82
43.90
10.70
82.68
46.41
Race, Gender
52.64
35.49
56.79
57.11
16.52
52.97
All
7.28
16.20
40.08
7.26
21.84
55.61
Table 9. Results of partial data protection on the NYUv2.
r →
0%
20%
40%
60%
80%
100%
T1
P0.2+T0.8 T0.8 P0.4+T0.6 T0.6 P0.6+T0.4 T0.4 P0.8+T0.2 T0.2
P1
PAcc
75.0
74.0
74.5
72.3
71.1
69.9
67.4
63.5
60.8
33.1
RErr
0.167
0.167
0.169
0.173
0.180
0.183
0.199
0.194
0.237 0.285
Mean 23.7
24.2
24.3
24.7
25.6
25.3
27.4
29.0
32.8
41.8
SEP, generalize well across CNNs, while MTL-UE-EM
performs better on ViT-B. This may be because SEP and
TAP rely on adversarial examples, limiting transferability
from CNNs to ViT, as ResNet-18 was used as the surrogate
backbone. Our methods also generalize well to MTL models
with different weighting strategies, with MTL-UE-SEP ex-
celling in several cases. Additional results on NYUv2, along
with MTL architecture transfer, are provided in Sec. B.4.
Ablation study (design & λ1, λ2). We do an ablation study
of the MTL-UE design, with results in Tab. 7. Compared
to ①, ②introduces an auto-encoder for perturbation gener-
ation, but shows little impact, even reducing performance
on MTL models. ③, which relies solely on learnable class-
wise feature embeddings, shows a significant performance
improvement over ①, emphasizing the role of embedding
priors in reducing intra-class variance. Additionally, build-
ing on ③, ours incorporates latents z from the input x,
and further enhances performance, likely due to improved
optimization by leveraging additional information from x.
Finally, ④excludes intra-task and ⑤excludes inter-task
embedding regularization, both showing that embedding
regularization enhances performance. We also provide an
ablation study of hyperparameters λ1 and λ2 in Sec. B.2,
showing that MTL-UE is not sensitive to them.
Partial task protection. We explore the scenario, where
only selected tasks are unlearnable, using MTL-UE-SEP.
After optimizing the generator, we generate UE by using the
mean of {ek
i }
Ck
i=1 for learnable tasks instead of ek
yk. Results
in Tab. 8 show that for STL models, unprotected tasks match
clean data accuracy, while protected tasks perform like those
trained to protect all tasks. In contrast, MTL models show
degraded performance for all tasks, likely due to shared
encoder learning both benign and spurious features.
Partial data protection. Following Huang et al. (2021), we
convert a portion r of clean T into unlearnable Pr, leaving
the rest as T1−r. We experiment on the NYUv2 using MTL-
UE-SEP. Table 9 shows results for models trained on Pr
mixed with T1−r and only on T1−r. The effectiveness drops
(a) Ours (w/ Intra-ER & Inter-ER) (b) Ours (w/o Intra-ER & Inter-ER)
Figure 7. T-SNE results of the learned class-wise embeddings.
(a) MTL models trained on clean data
(b) MTL models trained on unlearnable data
Age
Race
Gender
Age
Race
Gender
Figure 8. GradCAM of models trained on clean/unlearnable data.
quickly when the data is not fully unlearnable, a limitation
also noted in Huang et al. (2021). Models trained on the
mixture or only partial clean data show similar results, indi-
cating that Pr is ineffective and unlearnable during training.
Computational cost & Parameter count. Sec. A.3 shows
MTL-UE’s efficiency is close to EM and much lower than
TAP and SEP, and LSP and AR are faster due to predefined
patterns. Sec. A.4 shows MTL-UE needs fewer parameters
than EM, TAP, and SEP, but slightly more than AR and LSP.
Resistance to defenses. Sec. B.3 shows MTL-UE is much
more robust to SOTA defenses than baseline UE, likely due
to its clearer semantic patterns, distinct contours, and sketch
lines, which better withstand ISS-induced corruptions.
Feature visualization on UTKFace with MTL-UE-TAP.
Fig.7 shows t-SNE results of the learned class-wise embed-
dings for each task, where Inter-ER improves task separa-
tion and Intra-ER disperses embeddings within tasks. Fig. 8
shows GradCAM results for MTL models on their training
samples, revealing that MTL-UE introduces spurious fea-
tures, shifting focus to irrelevant areas like facial contours
instead of key regions like eyes and noses.
6. Conclusion
This paper presents MTL-UE, the first framework for gen-
erating UE on multi-task datasets for both MTL and STL
models, featuring a plug-and-play design that seamlessly in-
tegrates with existing surrogate-dependent methods. Instead
of optimizing perturbations for each sample, we utilize an
encoder-decoder network with additional sets of class-wise
embeddings. By incorporating task label priors through em-
beddings, MTL-UE reduces the intra-class variance of spu-
rious features for each task. Additionally, the intra-task and
inter-task embedding regularization improve the inter-class
separation of spurious features and minimize redundancy,
further enhancing performance. MTL-UE is also versatile,
supporting dense prediction tasks in MTL. Extensive exper-
iments demonstrate the effectiveness of MTL-UE.
9
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Acknowledgements
This work was carried out at the Rapid-Rich Object Search
(ROSE) Lab, Nanyang Technological University (NTU),
Singapore. This research is supported by the National Re-
search Foundation, Singapore and Infocomm Media Devel-
opment Authority under its Trust Tech Funding Initiative,
the Basic and Frontier Research Project of PCL, the Major
Key Project of PCL, and Guangdong Basic and Applied
Basic Research Foundation under Grant 2024A1515010454.
Any opinions, findings and conclusions or recommendations
expressed in this material are those of the author(s) and do
not reflect the views of National Research Foundation, Sin-
gapore and Infocomm Media Development Authority.
Impact Statement
In summary, our paper introduces MTL-UE, a novel frame-
work for generating unlearnable examples (UEs) that pro-
tects multi-task learning (MTL) data and tasks from unau-
thorized exploitation. As MTL models become increasingly
important for handling a wide range of tasks simultane-
ously, safeguarding such models is critical to ensure privacy
and prevent the misuse of sensitive data. Our approach ad-
dresses the growing need to protect personal or proprietary
data from unauthorized use while reducing the risks of data
theft in critical sectors like healthcare, finance, and security.
Furthermore, it fosters ethical AI development by encour-
aging responsible data use, promoting trust between data
providers and model developers, and contributing to broader
conversations on data protection and privacy regulations.
References
Achituve, I., Diamant, I., Netzer, A., Chechik, G., and Fe-
taya, E. Bayesian uncertainty for gradient aggregation in
multi-task learning. In Proc. Int’l Conf. Machine Learn-
ing, 2024.
Ban, H. and Ji, K. Fair resource allocation in multi-task
learning. In Proc. Int’l Conf. Machine Learning, 2024.
Barreno, M., Nelson, B., Joseph, A. D., and Tygar, J. D.
The security of machine learning. Machine Learning, 81:
121–148, 2010.
Baxter, J. A model of inductive bias learning. J. Artif. Intell.
Res., 12:149–198, 2000.
Biggio, B., Nelson, B., and Laskov, P. Poisoning attacks
against support vector machines. In Proc. Int’l Conf. Ma-
chine Learning, pp. 1467–1474, 2012.
Burt, C. Facial biometrics training dataset leads to bipa
lawsuits against amazon, alphabet and microsoft, jul 2020.
URL https://reurl. cc/dV4rD8, 2020.
Caruana, R. Multitask learning: A knowledge-based source
of inductive bias.
In Utgoff, P. E. (ed.), Proc. Int’l
Conf. Machine Learning, pp. 41–48. Morgan Kaufmann,
1993.
Chen, C., Zhang, J., Li, Y., and Han, Z. One for all: A
universal generator for concept unlearnability via multi-
modal alignment. In Proc. Int’l Conf. Machine Learning,
2024.
Chen, S., Zhang, Y., and Yang, Q. Multi-task learning in nat-
ural language processing: An overview. ACM Computing
Surveys, abs/2109.09138, 2021.
Chen, S., Yuan, G., Cheng, X., Gong, Y., Qin, M., Wang, Y.,
and Huang, X. Self-ensemble protection: Training check-
points are good data protectors. In Proc. Int’l Conf. Learn-
ing Representations, 2023.
Chen, Y., Zhao, D., Lv, L., and Zhang, Q. Multi-task learn-
ing for dangerous object detection in autonomous driving.
Inf. Sci., 432:559–571, 2018.
Chowdhuri, S., Pankaj, T., and Zipser, K. Multinet: Multi-
modal multi-task learning for autonomous driving. In
IEEE Winter Conference on Applications of Computer
Vision, WACV 2019, Waikoloa Village, HI, USA, January
7-11, 2019, pp. 1496–1504. IEEE, 2019.
Dai, Y., Fei, N., and Lu, Z. Improvable gap balancing for
multi-task learning. In Uncertainty in Artificial Intelli-
gence, pp. 496–506. PMLR, 2023.
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer,
M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby,
N. An image is worth 16x16 words: Transformers for
image recognition at scale. In Proc. Int’l Conf. Learning
Representations, 2021. URL https://openreview.
net/forum?id=YicbFdNTTy.
Feng, J., Cai, Q.-Z., and Zhou, Z.-H. Learning to con-
fuse: generating training time adversarial data with auto-
encoder. Proc. Annual Conf. Neural Information Process-
ing Systems, 32, 2019.
Fifty, C., Amid, E., Zhao, Z., Yu, T., Anil, R., and Finn,
C. Efficiently identifying task groupings for multi-task
learning. In Proc. Annual Conf. Neural Information Pro-
cessing Systems, volume 34, pp. 27503–27516, 2021.
Fontana, M., Spratling, M. W., and Shi, M. When multitask
learning meets partial supervision: A computer vision
review. Proc. IEEE, 112(6):516–543, 2024.
Fowl, L., Goldblum, M., Chiang, P.-y., Geiping, J., Czaja,
W., and Goldstein, T. Adversarial examples make strong
poisons. Proc. Annual Conf. Neural Information Process-
ing Systems, 34:30339–30351, 2021.
10
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Fu, S., He, F., Liu, Y., Shen, L., and Tao, D. Robust unlearn-
able examples: Protecting data privacy against adversarial
learning. In Proc. Int’l Conf. Learning Representations,
2022.
Gao, X., Zhao, Y., Dudziak, Ł., Mullins, R., and Xu, C.-z.
Dynamic channel pruning: Feature boosting and sup-
pression. In Proc. Int’l Conf. Learning Representations,
2019.
Gao, X., Xu, C.-Z., et al. Mora: Improving ensemble ro-
bustness evaluation with model reweighing attack. In
Proc. Annual Conf. Neural Information Processing Sys-
tems, pp. 26955–26965, 2022.
Goldblum,
M.,
Tsipras,
D.,
Xie,
C.,
Chen,
X.,
Schwarzschild, A., Song, D., Madry, A., Li, B., and Gold-
stein, T. Dataset security for machine learning: Data poi-
soning, backdoor attacks, and defenses. IEEE Trans. on
Pattern Analysis and Machine Intelligence, 45(2):1563–
1580, 2022.
Gu, T., Dolan-Gavitt, B., and Garg, S. Badnets: Identify-
ing vulnerabilities in the machine learning model supply
chain. arXiv preprint arXiv:1708.06733, 2017.
Guo, M., Haque, A., Huang, D.-A., Yeung, S., and Fei-Fei,
L. Dynamic task prioritization for multitask learning. In
Proc. IEEE European Conf. Computer Vision, pp. 270–
287, 2018.
Guo, P., Lee, C.-Y., and Ulbricht, D. Learning to branch
for multi-task learning. In Proc. Int’l Conf. Machine
Learning, pp. 3854–3863. PMLR, 2020.
Hadash, G., Shalom, O. S., and Osadchy, R. Rank and
rate: multi-task learning for recommender systems. In
Pera, S., Ekstrand, M. D., Amatriain, X., and O’Donovan,
J. (eds.), Proceedings of the 12th ACM Conference on
Recommender Systems, pp. 451–454. ACM, 2018.
He, H., Zha, K., and Katabi, D. Indiscriminate poisoning at-
tacks on unsupervised contrastive learning. In Proc. Int’l
Conf. Learning Representations. OpenReview.net, 2023.
He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn-
ing for image recognition. In Proc. IEEE Int’l Conf. Com-
puter Vision and Pattern Recognition, pp. 770–778, 2016.
Hu, Z., Li, X., Tang, S., Liu, J., Hu, Y., and Duan, L.-Y.
Lead: Exploring logit space evolution for model selec-
tion. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 28664–
28673, 2024.
Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger,
K. Q. Densely connected convolutional networks. In
Proc. IEEE Int’l Conf. Computer Vision and Pattern
Recognition, pp. 4700–4708, 2017.
Huang, H., Ma, X., Erfani, S. M., Bailey, J., and Wang,
Y. Unlearnable examples: Making personal data unex-
ploitable. In Proc. Int’l Conf. Learning Representations,
2021.
Jin, C., Li, Y., Zhao, M., Zhao, S., Wang, Z., He, X., Han,
L., Che, T., and Metaxas, D. N. Lor-VP: Low-rank vi-
sual prompting for efficient vision model adaptation. In
Proc. Int’l Conf. Learning Representations, 2025a.
Jin, C., Peng, H., Zhang, Q., Tang, Y., Metaxas, D. N., and
Che, T. Two heads are better than one: Test-time scaling
of multi-agent collaborative reasoning. arXiv preprint
arXiv:2504.09772, 2025b.
Karkkainen, K. and Joo, J. Fairface: Face attribute dataset
for balanced race, gender, and age for bias measurement
and mitigation. In Proceedings of the IEEE/CVF winter
conference on applications of computer vision, pp. 1548–
1558, 2021.
Kendall, A., Gal, Y., and Cipolla, R. Multi-task learning
using uncertainty to weigh losses for scene geometry and
semantics. In Proc. IEEE Int’l Conf. Computer Vision
and Pattern Recognition, pp. 7482–7491, 2018.
Koh, P. W. and Liang, P. Understanding black-box predic-
tions via influence functions. In Proc. Int’l Conf. Machine
Learning, pp. 1885–1894. PMLR, 2017.
Lin, B., Ye, F., Zhang, Y., and Tsang, I. Reasonable effec-
tiveness of random weighting: A litmus test for multi-task
learning. Transactions on Machine Learning Research,
2022.
Lin, X., Zhen, H.-L., Li, Z., Zhang, Q.-F., and Kwong, S.
Pareto multi-task learning. In Proc. Annual Conf. Neural
Information Processing Systems, volume 32, 2019.
Lin, X., Yu, Y., Xia, S., Jiang, J., Wang, H., Yu, Z., Liu, Y.,
Fu, Y., Wang, S., Tang, W., et al. Safeguarding medical
image segmentation datasets against unauthorized train-
ing via contour-and texture-aware perturbations. arXiv
preprint arXiv:2403.14250, 2024.
Liu, S., Johns, E., and Davison, A. J. End-to-end multi-task
learning with attention. In Proc. IEEE Int’l Conf. Com-
puter Vision and Pattern Recognition, pp. 1871–1880.
Computer Vision Foundation / IEEE, 2019a.
Liu, S., Johns, E., and Davison, A. J. End-to-end multi-task
learning with attention. In Proc. IEEE Int’l Conf. Com-
puter Vision and Pattern Recognition, pp. 1871–1880,
2019b.
Liu, S., Wang, Y., and Gao, X.-S. Game-theoretic unlearn-
able example generator. In Proc. AAAI Conf. on Artificial
Intelligence, volume 38, pp. 21349–21358, 2024a.
11
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Liu, W., Deng, Z., Niu, Z., Wang, J., Wang, H., Zeng, Z.,
and Li, R. Breaking free from MMI: A new frontier in
rationalization by probing input utilization. In Proc. Int’l
Conf. Learning Representations, 2025a.
Liu, W., Niu, Z., Gao, L., Deng, Z., Wang, J., Wang, H.,
and Li, R. Adversarial cooperative rationalization: The
risk of spurious correlations in even clean datasets. In
Proc. Int’l Conf. Machine Learning, 2025b.
Liu, X., Jia, X., Xun, Y., Liang, S., and Cao, X. Mul-
timodal unlearnable examples: Protecting data against
multimodal contrastive learning. In Proceedings of the
32nd ACM International Conference on Multimedia, pp.
8024–8033, 2024b.
Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face
attributes in the wild. In Proc. IEEE Int’l Conf. Computer
Vision, pp. 3730–3738, 2015.
Liu, Z., Zhao, Z., and Larson, M. Image shortcut squeez-
ing: Countering perturbative availability poisons with
compression. Proc. Int’l Conf. Machine Learning, 2023.
Lu, Y., Kamath, G., and Yu, Y. Exploring the limits of
model-targeted indiscriminate data poisoning attacks. In
Proc. Int’l Conf. Machine Learning, 2023.
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and
Vladu, A. Towards deep learning models resistant to
adversarial attacks. In Proc. Int’l Conf. Learning Repre-
sentations, 2018.
Meng, R., Yi, C., Yu, Y., Yang, S., Shen, B., and Kot, A. C.
Semantic deep hiding for robust unlearnable examples.
IEEE Transactions on Information Forensics and Security,
2024.
Misra, I., Shrivastava, A., Gupta, A., and Hebert, M. Cross-
stitch networks for multi-task learning. In Proc. IEEE
Int’l Conf. Computer Vision and Pattern Recognition, pp.
3994–4003. IEEE Computer Society, 2016.
Nathan Silberman, Derek Hoiem, P. K. and Fergus, R. In-
door segmentation and support inference from rgbd im-
ages. In Proc. IEEE European Conf. Computer Vision,
2012.
Navon, A., Shamsian, A., Achituve, I., Maron, H.,
Kawaguchi, K., Chechik, G., and Fetaya, E. Multi-task
learning as a bargaining game. In Proc. Int’l Conf. Ma-
chine Learning, pp. 16428–16446. PMLR, 2022.
Qin, T., Gao, X., Zhao, J., and Ye, K.
Destruction-
restoration suppresses data protection perturbations
against diffusion models. In 2023 IEEE 35th Interna-
tional Conference on Tools with Artificial Intelligence
(ICTAI), pp. 586–594. IEEE, 2023a.
Qin, T., Gao, X., Zhao, J., Ye, K., and Xu, C.-Z. Learn-
ing the unlearnable: Adversarial augmentations sup-
press unlearnable example attacks.
arXiv preprint
arXiv:2303.15127, 2023b.
Qin, T., Gao, X., Zhao, J., Ye, K., and Xu, C.-z.
Ap-
bench: A unified availability poisoning attack and de-
fenses benchmark. Transactions on Machine Learning
Research, 2024.
Royer, A., Blankevoort, T., and Ehteshami Bejnordi, B.
Scalarization for multi-task and multi-domain learning at
scale. In Proc. Annual Conf. Neural Information Process-
ing Systems, volume 36, 2023.
Ruder, S. An overview of multi-task learning in deep neural
networks. arXiv preprint arXiv:1706.05098, 2017.
Sandoval-Segura, P., Singla, V., Geiping, J., Goldblum, M.,
Goldstein, T., and Jacobs, D. Autoregressive perturba-
tions for data poisoning.
Proc. Annual Conf. Neural
Information Processing Systems, 35:27374–27386, 2022.
Schwarzschild, A., Goldblum, M., Gupta, A., Dickerson,
J. P., and Goldstein, T. Just how toxic is data poisoning?
a unified benchmark for backdoor and data poisoning
attacks. In Proc. Int’l Conf. Machine Learning, pp. 9389–
9398. PMLR, 2021.
Sener, O. and Koltun, V.
Multi-task learning as multi-
objective optimization. In Proc. Annual Conf. Neural
Information Processing Systems, volume 31, 2018.
Senushkin, D., Patakin, N., Kuznetsov, A., and Konushin, A.
Independent component alignment for multi-task learning.
In Proc. IEEE Int’l Conf. Computer Vision and Pattern
Recognition, pp. 20083–20093, 2023.
Simonyan, K. and Zisserman, A. Very deep convolutional
networks for large-scale image recognition. In Bengio, Y.
and LeCun, Y. (eds.), Proc. Int’l Conf. Learning Repre-
sentations, 2015.
Standley, T., Zamir, A., Chen, D., Guibas, L., Malik, J.,
and Savarese, S. Which tasks should be learned together
in multi-task learning?
In Proc. Int’l Conf. Machine
Learning. PMLR, 2020.
Sun, Y., Zhang, H., Zhang, T., Ma, X., and Jiang, Y.-G.
Unseg: One universal unlearnable example generator is
enough against all image segmentation. arXiv preprint
arXiv:2410.09909, 2024.
Vincent, J. Google accused of inappropriate access to medi-
cal data in potential class-action lawsuit, jun 2019. URL
https://reurl. cc/bzK69v, 2019.
12
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Wang, C., Yu, Y., Guo, L., and Wen, B. Benchmarking
adversarial robustness of image shadow removal with
shadow-adaptive attacks. In Proc. IEEE Int’l Conf. Acous-
tics, Speech, and Signal Processing, pp. 13126–13130.
IEEE, 2024a.
Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., and Sum-
mers, R. M. Chestx-ray8: Hospital-scale chest x-ray
database and benchmarks on weakly-supervised clas-
sification and localization of common thorax diseases.
In Proc. IEEE Int’l Conf. Computer Vision and Pattern
Recognition, pp. 2097–2106, 2017.
Wang, X., Li, M., Liu, W., Zhang, H., Hu, S., Zhang,
Y., Zhou, Z., and Jin, H. Unlearnable 3d point clouds:
Class-wise transformation is all you need. arXiv preprint
arXiv:2410.03644, 2024b.
Wang, X., Gao, X., Liao, D., Qin, T., Lu, Y., and Xu, C.-
Z. A3: Few-shot prompt learning of unlearnable ex-
amples with cross-modal adversarial feature alignment.
In Proc. IEEE Int’l Conf. Computer Vision and Pattern
Recognition, 2025a.
Wang, X., Liang, S., Liao, D., Fang, H., Liu, A., Cao, X.,
Lu, Y.-l., Chang, E.-C., and Gao, X. Lie detector: Uni-
fied backdoor detection via cross-examination framework.
arXiv preprint arXiv:2503.16872, 2025b.
Wu, S., Chen, S., Xie, C., and Huang, X. One-pixel shortcut:
On the learning preference of deep neural networks. In
Proc. Int’l Conf. Learning Representations, 2023.
Xia, S., Yang, W., Yu, Y., Lin, X., Ding, H., DUAN, L., and
Jiang, X. Transferable adversarial attacks on sam and
its downstream models. In Proc. Annual Conf. Neural
Information Processing Systems, 2024a.
Xia, S., Yi, Y., Jiang, X., and Ding, H. Mitigating the
curse of dimensionality for certified robustness via dual
randomized smoothing. In Proc. Int’l Conf. Learning
Representations, 2024b.
Xia, S., Yu, Y., Yang, W., Ding, M., Chen, Z., Duan, L.,
Kot, A. C., and Jiang, X. Theoretical insights in model
inversion robustness and conditional entropy maximiza-
tion for collaborative inference systems. arXiv preprint
arXiv:2503.00383, 2025.
Xiao, H., Biggio, B., Brown, G., Fumera, G., Eckert, C.,
and Roli, F. Is feature selection secure against training
data poisoning? In Proc. Int’l Conf. Machine Learning,
pp. 1689–1698. PMLR, 2015.
Yang, W., Hu, Z., Lin, L., Liu, J., and Duan, L.-Y. Coding
for intelligence from the perspective of category. arXiv
preprint arXiv:2407.01017, 2024.
Yu, D., Zhang, H., Chen, W., Yin, J., and Liu, T.-Y. Avail-
ability attacks create shortcuts. In Proceedings of the 28th
ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, pp. 2367–2376, 2022a.
Yu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and
Finn, C. Gradient surgery for multi-task learning. In
Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and
Lin, H. (eds.), Proc. Annual Conf. Neural Information
Processing Systems, 2020.
Yu, Y., Gao, X., and Xu, C.-Z. Lafeat: Piercing through
adversarial defenses with latent features. In Proceedings
of the IEEE/CVF conference on computer vision and
pattern recognition, pp. 5735–5745, 2021.
Yu, Y., Yang, W., Tan, Y.-P., and Kot, A. C. Towards robust
rain removal against adversarial attacks: A comprehen-
sive benchmark analysis and beyond. In Proc. IEEE
Int’l Conf. Computer Vision and Pattern Recognition, pp.
6013–6022, 2022b.
Yu, Y., Gao, X., and Xu, C.-Z. Lafit: Efficient and reliable
evaluation of adversarial defenses with latent features.
IEEE Trans. on Pattern Analysis and Machine Intelli-
gence, 46(1):354–369, 2023a.
Yu, Y., Wang, Y., Yang, W., Lu, S., Tan, Y.-P., and Kot, A. C.
Backdoor attacks against deep image compression via
adaptive frequency trigger. In Proc. IEEE Int’l Conf. Com-
puter Vision and Pattern Recognition, pp. 12250–12259,
2023b.
Yu, Y., Wang, Y., Xia, S., Yang, W., Lu, S., Tan, Y.-P.,
and Kot, A. C. Purify unlearnable examples via rate-
constrained variational autoencoders. In International
Conference on Machine Learning, ICML 2024, 2024a.
Yu, Y., Wang, Y., Yang, W., Guo, L., Lu, S., Duan, L.-
Y., Tan, Y.-P., and Kot, A. C. Robust and transferable
backdoor attacks against deep image compression with se-
lective frequency prior. IEEE Trans. on Pattern Analysis
and Machine Intelligence, 2024b.
Yu, Y., Zheng, Q., Yang, S., Yang, W., Liu, J., Lu, S., Tan,
Y.-P., Lam, K.-Y., and Kot, A. Unlearnable examples de-
tection via iterative filtering. In International Conference
on Artificial Neural Networks, pp. 241–256. Springer,
2024c.
Yu, Y., Xia, S., Lin, X., Yang, W., Lu, S., Tan, Y.-P., and Kot,
A. Backdoor attacks against no-reference image quality
assessment models via a scalable trigger. In Proc. AAAI
Conf. on Artificial Intelligence, volume 39, pp. 9698–
9706, 2025.
Yuan, C.-H. and Wu, S.-H. Neural tangent generalization
attacks. In Proc. Int’l Conf. Machine Learning, pp. 12230–
12240. PMLR, 2021.
13
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Yun, H. and Cho, H. Achievement-based training progress
balancing for multi-task learning. In Proc. IEEE Int’l
Conf. Computer Vision, pp. 16935–16944, 2023.
Zhang, J., Ma, X., Yi, Q., Sang, J., Jiang, Y.-G., Wang, Y.,
and Xu, C. Unlearnable clusters: Towards label-agnostic
unlearnable examples. In Proc. IEEE Int’l Conf. Com-
puter Vision and Pattern Recognition, pp. 3984–3993,
2023.
Zhang, Y. and Yang, Q. A survey on multi-task learning.
IEEE transactions on knowledge and data engineering,
34(12):5586–5609, 2021.
Zhang, Z., Song, Y., and Qi, H. Age progression/regression
by conditional adversarial autoencoder. In Proc. IEEE
Int’l Conf. Computer Vision and Pattern Recognition.
IEEE, 2017.
Zhao, B. and Lao, Y. Clpa: Clean-label poisoning avail-
ability attacks using generative adversarial nets.
In
Proc. AAAI Conf. on Artificial Intelligence, volume 36,
pp. 9162–9170, 2022.
Zheng, Q., Yu, Y., Yang, S., Liu, J., Lam, K.-Y., and Kot,
A.
Towards physical world backdoor attacks against
skeleton action recognition. In Proc. IEEE European
Conf. Computer Vision, pp. 215–233. Springer, 2024.
Zhu, Y., Miao, Y., Dong, Y., and Gao, X.-S.
Toward
availability attacks in 3d point clouds. arXiv preprint
arXiv:2407.11011, 2024a.
Zhu, Y., Yu, L., and Gao, X.-S. Detection and defense of
unlearnable examples. In Proc. AAAI Conf. on Artificial
Intelligence, volume 38, pp. 17211–17219, 2024b.
14
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
A. More experimental details
A.1. Details of the baseline UE methods
For experiments on classification datasets, we follow specific setups for both surrogate-dependent and surrogate-free
methods:
• Surrogate-dependent Methods:
– For EM (Huang et al., 2021), TAP (Fowl et al., 2021), and SEP (Chen et al., 2023), we use MTL models with
Linear Scalarization (LS) as the surrogate model.
– For TAP and SEP, following their default settings, we employ PGD (Madry et al., 2018) with 250 steps and a step
size of 0.064
255 to generate adversarial perturbations via targeted attacks. The target class for the k-th task is set as
(yk + Ck//2)%Ck, where yk is the original label and Ck represents the total number of classes for the k-th task.
– For SEP, we use an ensemble of 15 checkpoints to enhance attack effectiveness.
– For EM, perturbations are optimized using PGD with 20 steps and a step size of 0.8
255. Surrogate models are trained
for 10 iterations after each loop of perturbation optimization. The stopping criterion, as per the default setting,
requires the overall training set accuracy to reach 99%.
• Surrogate-free Methods:
– For LSP (Yu et al., 2022a) and AR (Sandoval-Segura et al., 2022), we evaluate two fusion strategies:
* Averaging-based Fusion: For each k-th task, Ck class-wise perturbations with the same shape as the input are
generated. These are then fused using the averaging-based approach.
* Patch-based Fusion: We divide the input into N × N patches, where N = 2⌈log2(⌈K0.5⌉)⌉. For an input
shape of 3 × H × W, the patch size becomes 3 × H//N × W//N. Perturbations for the K tasks are placed
in corresponding patches (the first K patches) based on their labels yk. These perturbations are generated
separately for Ck classes in each patch for each k-th task, and then the whole perturbations are interpolated
from shape 3 × N ∗(H//N) × N ∗(W//N) to match the input shape 3 × H × W.
– It is worth noting that for both LSP and AR, the perturbation bound is set to ℓ2 = 1 regarding the inputs with
a shape of 32 × 32, as per their default settings. However, for larger input sizes, such as H × W, the bound is
adjusted to ℓ2 = 1 × H
32 × W
32 to ensure comparability with other methods.
For experiments on the NYUv2 dataset, we include only surrogate-dependent methods:
• For EM (Huang et al., 2021), TAP (Fowl et al., 2021), and SEP (Chen et al., 2023), we use MTL models with Linear
Scalarization (LS) as the surrogate model.
• For TAP and SEP, following their default settings, PGD (Madry et al., 2018) is employed to generate adversarial
perturbations via targeted attacks. For the semantic segmentation task, the target class is defined as (yk + 13//2)%13,
given there are 13 semantic classes in total. For the depth estimation and surface normal estimation tasks, where
defining a target is challenging, untargeted attacks are used, aiming to maximize the loss between the attacked prediction
and the ground truth labels.
• For SEP, an ensemble of 10 checkpoints is used to enhance attack effectiveness.
• For EM, perturbations are optimized using PGD, while surrogate models are trained for 10 iterations after each loop of
perturbation optimization. The stopping criterion is reached when the loop of perturbation optimization completes
10 iterations, resulting in a total of 200 iterations for each perturbation optimization (as each PGD step runs for 20
iterations).
15
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
A.2. Details of the models and the training
Design of MTL-UE generator. Assume the input shape is set to 3 × H × W or 1 × H × W for Grayscale images such as
the ChestX-ray-14 dataset, and there are K tasks. For the design of MTL-UE’s generator, we use 9 convolutional layers
and ×0.5 downsampling as E(·; ϕE), resulting in z with shape 128 × H
2 × W
2 . For the set

{ek
i }Ck
i=1
	K
k=1, each ek
yk is
designed to match the length and width of z, giving it the shape 16 × H
2 × W
2 . For D(·; ϕD), we use 4 ConvTranspose2d
layers and one ×2 upsampling. The input to D(·; ϕD) is the concatenation of z and {ek
yk}K
k=1, resulting in a shape of
(128 + 16 × K) × H
2 × W
2 , and the output is the same shape as the input to E(·; ϕE).
Specifically, for the NYUv2 dataset, we use the embedder Ek(·; ϕEk) instead of ek
yk. The structure of the embedder is
identical to that of the corresponding E(·; ϕE), with the input shape for segmentation labels and depth being 1 × H × W,
and the input for normal labels being 3 × H × W.
MTL and STL model training. For the CelebA, ChestX-ray14, and UTKFace datasets, we train the models for 60 epochs
using the Adam optimizer, starting with a learning rate of 1e-3. We apply the MultiStepLR scheduler, with milestones at
epochs 36 and 48, and a gamma of 0.1 to adjust the learning rate. The batch size is set to 512 for CelebA and UTKFace,
and 128 for ChestX-ray14. Data augmentation techniques include RandomCrop and RandomHorizontalFlip to improve the
model’s generalization. For the NYUv2 dataset, we train the models for 200 epochs, starting with a learning rate of 1e-4,
and use a StepLR scheduler with a step size of 100 and a gamma of 0.1 to reduce the learning rate during training. We set
the batch size to 8 for this dataset due to the larger image dimensions and the computational load involved.
MTL-UE generator training. The batch sized, training epochs, learning rates, optimizers, and learning rate schedulers
for the generator are configured identically to those used for training the MTL models on the respective datasets. For the
hyperparameters in Alg. 1, ϵ is set to match the baseline methods, with the default value ϵ =
8
255 for all datasets. The weight
λ1 is set to 20, and λ2 is set to 100 across all datasets. For MTL-UE-EM, where the ”Train-surrogate” is set to True, we use
10 iterations, consistent with the baseline EM methods. For MTL-UE-TAP and MTL-UE-SEP, where ”Train-surrogate” is
set to False, we pretrain the MTL models on the respective datasets using the default training settings as described earlier.
For the remaining configurations, we follow the same setup as the corresponding baseline methods: EM, TAP, and SEP.
A.3. Computational Complexity
We also analyze the computational complexity of MTL-UE and the baseline methods. For both EM and MTL-UE-EM,
the computational complexity is nearly identical since they share the same stopping criterion. For TAP and SEP, each
perturbation requires 250 optimization steps on each surrogate model. In contrast, for MTL-UE-TAP and MTL-UE-SEP,
perturbations are optimized once per epoch, with a total of 60 epochs for classification datasets and 200 epochs for the
NYUv2 dataset, which means 60 optimization steps on each sample for classification dataset, and 200 optimization steps on
each sample for NYUv2 dataset. This makes our methods more efficient compared to the baseline TAP and SEP. For AR
and LSP, the perturbations are predefined and hand-crafted, making these methods the most computationally efficient.
A.4. Parameter Quantity
We provide the parameter counts for all competing methods:
• For EM, TAP, and SEP, the parameters correspond to the perturbations. For example, on the CelebA dataset, the
perturbation parameters have a shape of 162770 × 3 × 70 × 70 = 2, 392, 719, 000.
• For our method, the parameters are derived from the MTL-UE generator, which consists of 3,086,147 parameters for
the CelebA dataset.
• For AR and LSP, the parameter count for the averaging-based fusion method is 2 × 40 × 3 × 70 × 70 = 1, 176, 000,
while for the patch-based fusion method, it is 2 × 40 × 3 × 8 × 8 = 15, 360.
Overall, our method is efficient, requiring only slightly more parameters than the patch-based AR and LSP methods.
16
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Table 10. Quantitative results on the UTKFace with different number of tasks: We report the average accuracy (%) across the selected
tasks. Both MTL and STL models adopt ResNet-18 as the encoder. The MTL models employ LS as the task-weighting.
Selected tasks →
Age
Age, Race
Age, Race, Gender
Model →
MTL/STL
MTL
STL
MTL
STL
Metric →
Avg.↓
Avg.↓
Avg.↓
Avg.↓
Avg.↓
Clean
57.51
70.79
70.45
78.97
78.92
LSP (Yu et al., 2022a) (Patch)
10.65
13.11
18.27
28.58
32.43
AR (Sandoval-Segura et al., 2022) (Patch)
9.47
14.60
14.61
27.41
26.75
LSP (Yu et al., 2022a) (Average)
10.65
18.23
30.73
28.16
45.91
AR (Sandoval-Segura et al., 2022) (Average)
9.47
12.34
14.07
36.79
36.67
EM (Huang et al., 2021)
10.89
19.16
19.26
31.74
50.88
TAP (Fowl et al., 2021)
25.82
31.57
49.10
39.29
59.36
SEP (Chen et al., 2023)
22.74
32.63
48.86
40.70
60.78
MTL-UE-EM
18.82
10.60
8.82
25.84
26.32
MTL-UE-TAP
9.18
9.74
11.92
19.84
25.59
MTL-UE-SEP
5.49
11.78
12.61
21.19
28.24
Table 11. Ablation study of the hyperparameters of MTL-UE on CelebA.
Model →
MTL
STL
Base UE →
EM
TAP
SEP
EM
TAP
SEP
⑥: λ1 = 2, λ2 = 100
75.04
60.53
59.39
73.88
69.67
75.43
⑦: λ1 = 200, λ2 = 100
74.27
59.60
59.06
75.13
67.49
76.02
⑧: λ1 = 20, λ2 = 10
73.85
58.86
58.81
73.29
67.84
77.08
⑨: λ1 = 20, λ2 = 1000
74.23
60.02
58.09
74.95
68.98
75.82
MTL-UE (λ1 = 20, λ2 = 100)
74.38
59.51
58.73
74.26
68.65
76.39
Table 12. Results under state-of-the-art defenses. We select the UTKFace dataset and train the MTL models.
Defense →
None
ISS-JPEG (Liu et al., 2023)
ISS-Grayscale (Liu et al., 2023)
ISS-BDR (Liu et al., 2023)
Tasks →
Age↓
Race↓
Gender↓
Avg.↓
Age↓
Race↓
Gender↓
Avg.↓
Age↓
Race↓
Gender↓
Avg.↓
Age↓
Race↓
Gender↓
Avg.↓
Clean
60.32
84.07
92.51
78.97
59.26
83.92
92.24
78.47
59.45
83.19
91.77
78.14
58.69
82.45
92.32
77.82
LSP (Patch)
18.40
17.51
49.83
28.58
44.51
68.48
87.78
66.93
15.80
22.26
53.00
30.35
34.56
41.84
78.92
51.77
AR (Patch)
9.70
19.66
52.87
27.41
47.07
82.55
90.99
73.54
27.41
41.35
52.72
40.49
14.64
26.24
52.78
31.22
LSP (Average)
12.59
19.72
52.17
28.16
49.81
80.76
90.86
73.81
16.98
54.81
56.50
42.76
32.41
65.70
78.23
58.78
AR (Average)
13.92
41.03
55.42
36.79
57.87
83.40
92.07
77.78
6.46
19.28
52.83
26.19
24.54
48.06
81.16
51.25
EM
19.24
17.43
58.57
31.74
58.38
82.49
91.86
77.57
19.81
24.81
58.84
34.49
19.81
24.81
58.84
34.49
TAP
25.86
39.28
52.74
39.29
46.69
78.27
89.18
71.38
24.20
56.54
69.37
50.04
24.20
56.54
69.37
50.04
SEP
25.42
44.03
52.64
40.70
47.09
78.69
89.51
71.77
23.06
49.03
57.97
43.35
23.06
49.03
57.97
43.35
MTL-UE-EM
10.00
12.78
54.73
25.84
6.75
14.05
57.78
26.20
7.72
16.31
57.62
27.22
12.93
22.51
63.35
32.93
MTL-UE-TAP
9.49
18.23
31.81
19.84
15.82
26.27
26.39
22.83
10.68
16.73
40.27
10.68
15.02
24.73
26.39
22.05
MTL-UE-SEP
7.28
16.20
40.08
21.19
15.23
39.83
43.27
32.78
5.86
28.78
45.04
26.56
18.02
34.14
42.93
31.69
B. Additional Results
B.1. More quantitative results
Performance of UE Vs. the number of tasks. Additional results on the UTKFace dataset with varying numbers of tasks
are presented in Tab. 10. Even with a limited number of tasks, MTL-UE consistently outperforms the baseline approaches.
B.2. More ablation study
We do additional ablation studies on MTL-UE, focusing on the hyperparameters λ1 and λ2 in Alg. 1. Specifically,
experiments are conducted on the CelebA dataset. The results in Tab. 11 indicate that MTL-UE is relatively insensitive to
these hyperparameters. This may be because LIntra and LInter are easier to optimize within the combined loss framework in
Alg. 1. As long as λ1 and λ2 are not set too small, these hyperparameters have minimal impact on the optimization process
of MTL-UE.
B.3. Results to defenses
We evaluate MTL-UE and competing methods against existing UE defenses applicable to MTL models. Experiments
are conducted on the UTKFace dataset using MTL models. We select the SOTA defense, Image Shortcut Squeezing
(ISS) (Liu et al., 2023), which includes three preprocessing-based techniques: JPEG compression (quality set to 10),
grayscale conversion, and bit-depth reduction (BDR, depth set to 2), follwoing their default settings. Results in Tab. 12
show that MTL-UE remains significantly more robust and consistent than baseline UE methods. Notably, under JPEG
compression, all baseline methods fail, whereas MTL-UE maintains strong performance. This robustness is likely due to
MTL-UE’s clearer semantic patterns, distinct contours, and sketch lines, which better withstand ISS-induced corruptions.
17
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
Table 13. Backbone transfer: Performance on the NYUv2 (Nathan Silberman & Fergus, 2012) when transfering to MTL and STL models
with various backbone. The MTL models employ HPS (Caruana, 1993) as architecture and linear scalarization as the task-weighting
strategy.
Backbone →
ResNet-101
ResNet-152
WideResNet-50
Task →
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Metric →
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
Clean
54.38
76.00
0.3802
0.1582
23.16
16.79
54.88
76.29
0.3690
0.1502
22.71
16.33
52.42
74.55
0.4044
0.1746
24.14
17.80
EM
31.78
50.72
0.5634
0.2076
28.25
22.41
32.51
50.03
0.5395
0.1990
28.09
22.09
29.08
45.71
0.6352
0.2246
30.71
25.84
TAP
37.73
56.71
0.4905
0.1908
27.59
21.25
32.96
50.58
0.5176
0.1922
28.22
21.97
37.98
57.13
0.5051
0.2016
29.41
23.26
SEP
27.85
40.81
0.5457
0.2151
30.61
24.97
29.78
43.91
0.5789
0.2061
30.11
24.18
30.73
45.99
0.5425
0.2175
29.81
23.61
MTL-UE-EM
2.38
16.03
0.8887
0.2903
38.23
33.47
1.75
15.82
0.9638
0.3062
34.91
29.19
2.34
16.16
0.8448
0.2812
36.71
31.71
MTL-UE-TAP
23.25
37.00
0.9739
0.3203
37.56
31.66
24.10
35.71
0.8993
0.2942
36.66
30.25
23.59
36.66
0.8403
0.2853
38.72
32.87
MTL-UE-SEP
18.55
29.78
0.9043
0.3046
42.07
36.44
19.31
25.59
0.8499
0.2835
37.64
31.72
17.38
29.48
0.8095
0.2836
41.15
35.84
Table 14. Weighting strategies transfer: Performance on the NYUv2 (Nathan Silberman & Fergus, 2012) when transfering to MTL and
STL models with various task-weighting strategies. The MTL models employ HPS (Caruana, 1993) as architecture and ResNet-18 (He
et al., 2016) as encoder’s backbone.
Weighting →
UW
RLW
Align
FairGrad
Task →
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Metric →
mIoU↓PAcc↓AErr↑RErr↑Mean↑MED↑mIoU↓PAcc↓AErr↑RErr↑Mean↑MED↑mIoU↓PAcc↓AErr↑RErr↑Mean↑MED↑mIoU↓PAcc↓AErr↑RErr↑Mean↑MED↑
Clean
52.99
74.77 0.3941 0.1696 23.76
17.33
52.70
74.90 0.3906 0.1622 23.43
16.92
52.50
74.24 0.3966 0.1707 22.96
16.37
52.21
74.32 0.3927 0.1694 22.85
16.34
EM
25.70
43.96 0.6124 0.2312 30.23
24.30
28.64
50.19 0.6407 0.2391 30.57
24.94
26.01
44.12 0.5997 0.2281 29.53
23.15
28.03
48.94 0.6367 0.2314 30.02
23.72
TAP
21.02
35.33 0.6273 33.76
27.86 0.2532 19.79
34.79 0.6449 0.2485 34.22
27.78
18.88
31.75 0.6261 0.2441 33.06
26.68
21.12
36.06 0.6314 0.2382 32.95
26.29
SEP
12.20
24.40 0.6996 0.2823 36.77
31.19
11.40
23.67 0.7048 0.2899 35.88
30.20
12.36
24.72 0.6882 0.2813 35.98
29.73
13.47
25.78 0.6812 0.2766 35.16
29.59
MTL-UE-EM
2.33
15.96 0.9515 0.3110 38.33
34.14
2.05
15.79 1.0405 0.3344 37.03
32.16
1.78
15.74 1.0002 0.3265 37.34
31.58
2.07
15.82 0.9987 0.3240 35.84
29.91
MTL-UE-TAP
17.08
28.98 0.9620 0.3177 40.03
34.48
16.85
29.16 1.0631 0.3489 40.96
35.68
18.31
29.53 1.0100 0.3310 38.17
31.78
17.93
30.83 0.9513 0.3169 38.78
32.89
MTL-UE-SEP
13.96
21.71 0.8600 0.2936 41.19
35.85
15.64
28.85 0.9047 0.3057 42.49
37.15
16.50
26.67 0.8981 0.3024 41.85
35.67
16.58
26.36 0.9020 0.3017 40.59
34.87
Table 15. Architecture transfer: Performance on the NYUv2 (Nathan Silberman & Fergus, 2012) when transfering to MTL and STL
models with various architecture. The MTL models employ ResNet-18 (He et al., 2016) as encoder’s backbone and linear scalarization as
the task-weighting strategy.
Backbone →
Cross-stitch
MTAN
LTB
Task →
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Segmentation
Depth
Normal
Metric →
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
mIoU↓
PAcc↓
AErr↑
RErr↑
Mean↑
MED↑
Clean
52.48
74.74
0.3874
0.1621
23.34
16.52
53.99
75.44
0.3806
0.1619
23.34
16.67
51.53
74.30
0.3819
0.1585
23.44
16.54
EM
24.03
42.11
0.6582
0.2377
30.29
23.96
27.04
45.61
0.6241
0.2334
30.32
24.03
28.55
50.00
0.6357
0.2334
30.04
23.65
TAP
21.05
38.89
0.6622
0.2455
33.99
27.18
19.72
30.56
0.6468
0.2484
34.06
27.94
18.24
32.63
0.6527
0.2472
33.57
26.86
SEP
9.80
21.18
0.7687
0.2814
36.03
29.83
10.53
21.45
0.7049
0.2854
36.06
30.25
10.53
21.98
0.7679
0.2793
36.46
30.47
MTL-UE-EM
1.78
15.77
1.0116
0.3249
35.18
29.46
1.54
15.66
0.9962
0.3211
36.00
30.29
1.52
15.67
1.0654
0.3408
36.16
30.67
MTL-UE-TAP
17.34
30.07
1.0652
0.3457
39.06
32.83
14.85
25.33
1.1076
0.3587
42.24
36.80
20.44
36.43
1.0231
0.3309
38.96
32.33
MTL-UE-SEP
15.78
30.89
0.9215
0.3099
42.77
36.85
14.94
26.49
0.8888
0.3015
43.73
38.62
17.87
30.27
0.9095
0.3036
40.71
34.88
B.4. More transferability results for NYUv2 dataset
Transferability results for the NYUv2 dataset are shown in Tab. 13, Tab. 14, and Tab. 15. In addition to backbone and
weighting strategy transfer on the CelebA dataset, we also evaluate architecture transfer for NYUv2. For backbone transfer,
we use ResNet-101, ResNet-152, and WideResNet-50 as backbones for victim models. For weighting strategy transfer,
we adopt the same strategies as in the CelebA experiments. For architecture transfer, Cross-stitch (Misra et al., 2016),
MTAN (Liu et al., 2019b), and LTB (Guo et al., 2020) are included for evaluation. As observed, MTL-UE consistently
protects against unauthorized model training on the NYUv2 dataset across various model backbones, weighting strategies,
and MTL architectures.
18
MTL-UE: Learning to Learn Nothing for Multi-Task Learning
EM
TAP
SEP
LSP (P)
AR (P)
LSP (A)
AR (A)
Ours-EM Ours-TAP Ours-SEP
Clean
CelebA
UTKFace
NYUv2
EM
TAP
SEP
Ours-EM
Ours-TAP
Ours-SEP
Clean
ChestXray-14
Figure 9. Visual results: the odd/even rows show the perturbations/images, respectively. Perturbations are in dependently normalized to
[0,1] for clarity.
B.5. More visual results
We provide additional visual examples of perturbations and poisoned images from the CelebA (Liu et al., 2015), ChestX-
ray14 (Wang et al., 2017), UTKFace (Zhang et al., 2017), and NYUv2 (Nathan Silberman & Fergus, 2012) datasets, as
shown in Fig. 9. We observe across all datasets that our methods offer more interpretable cues, guiding the model to learn
the added perturbations rather than the benign features of the clean data. In particular, MTL-UE-TAP and MTL-UE-SEP
display distinct outlines or contour lines.
19


arXiv:2505.05292v1  [cs.CR]  8 May 2025
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature
to Perform Data Exfiltration Attacks
Thomas Grübl
Communication Systems Group CSG, Department of
Informatics IfI, University of Zurich UZH
Zürich, Switzerland
gruebl@ifi.uzh.ch
Weijie Niu
Communication Systems Group CSG, Department of
Informatics IfI, University of Zurich UZH
Zürich, Switzerland
niu@ifi.uzh.ch
Jan von der Assen
Communication Systems Group CSG, Department of
Informatics IfI, University of Zurich UZH
Zürich, Switzerland
vonderassen@ifi.uzh.ch
Burkhard Stiller
Communication Systems Group CSG, Department of
Informatics IfI, University of Zurich UZH
Zürich, Switzerland
stiller@ifi.uzh.ch
Abstract
The QUIC protocol is now widely adopted by major tech companies
and accounts for a significant fraction of today’s Internet traffic.
QUIC’s multiplexing capabilities, encrypted headers, dynamic IP
address changes, and encrypted parameter negotiations make the
protocol not only more efficient, secure, and censorship-resistant,
but also practically unmanageable by firewalls. This opens up doors
for attackers that may exploit certain traits of the QUIC protocol to
perform targeted attacks, such as data exfiltration attacks. Whereas
existing data exfiltration techniques, such as TLS and DNS-based
exfiltration, can be detected on a firewall level, QUIC-based data
exfiltration is more difficult to detect, since changes in IP addresses
and ports are inherent to the protocol’s normal behaviour.
To show the feasibility of a QUIC-based data exfiltration attack,
we first introduce a novel method which leverages the server pre-
ferred address feature of the QUIC protocol and, thus, allows an
attacker to exfiltrate sensitive data from an infected machine to a
malicious server, disguised as a server-side connection migration.
The attack is implemented in the form of a proof of concept tool in
Rust. We evaluated the performance of five anomaly detection clas-
sifiers — Random Forest, Multi-Layer Perceptron, Support Vector
Machine, Autoencoder, and Isolation Forest — trained on datasets
collected from three distinct network traffic scenarios. The classi-
fiers were trained on ∼700K benign and malicious QUIC packets
and 786 connection migration events, but were unable to effectively
detect the data exfiltration attempts. Furthermore, post-analysis of
the traffic captures did not reveal any identifiable fingerprint. As
part of our evaluation, we also interviewed five leading firewall
vendors and found that, as of today, no major firewall vendor im-
plements functionality capable of distinguishing between benign
and malicious QUIC connection migrations.
This work is licensed under a Creative Commons Attribution 4.0 International License.
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
© 2025 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-1410-8/2025/08
https://doi.org/10.1145/3708821.3733872
CCS Concepts
• Security and privacy →Network security; Intrusion/anomaly
detection and malware mitigation; • Networks →Transport pro-
tocols.
Keywords
QUIC, Network Security, Data Exfiltration, Anomaly Detection
ACM Reference Format:
Thomas Grübl, Weijie Niu, Jan von der Assen, and Burkhard Stiller. 2025.
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform
Data Exfiltration Attacks. In ACM Asia Conference on Computer and Commu-
nications Security (ASIA CCS ’25), August 25–29, 2025, Hanoi, Vietnam. ACM,
New York, NY, USA, 14 pages. https://doi.org/10.1145/3708821.3733872
1
Introduction
The QUIC protocol, originally developed by [39], is an IETF stan-
dardized, connection-oriented, UDP-based transport protocol that
serves as a replacement to TLS over TCP [24]. Its main benefits
include One Round Trip Time (1-RTT) handshakes, Zero Round
Trip Time (0-RTT) connection re-establishments when prior com-
munication has taken place, seamless network path migration, and
state-of-the-art security [19]. As of today, QUIC has been widely
deployed by major tech companies such as Google, Meta, Apple,
and Cloudflare. The popularity of QUIC has led to some application-
layer protocols adopting it as their main transport protocol, such
as DNS-over-QUIC [17] or HTTP/3 [4]. QUIC plays a fundamental
role within HTTP/3 [4], making it ubiquitous in today’s Internet
traffic. In 2023, HTTP/3 already accounted for around 30% of HTTP
requests, with adoption expected to continue growing as more web
servers and browsers integrate QUIC support [3].
QUIC packets are encapsulated in UDP datagrams. Each packet
has a QUIC header that contains details such as the flags indicating
a certain packet type and the Connection ID (CID). The CID is a
randomly generated, variable-length identifier that endpoints use
to demultiplex network traffic sent between them [19]. Since the
QUIC protocol encrypts the entire communication, including a sig-
nificant part of the handshake, it is inherently difficult to analyze
the underlying traffic. Although QUIC was primarily designed for
performance improvements, QUIC’s properties also enhance pri-
vacy and make it more resilient to network interference through
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
features such as the frequent rotation of CIDs and the concurrent
transmission of packets over multiple streams [29].
While these features improve the security and privacy for end-
users, they pose challenges for firewall vendors. The general con-
sensus among firewall vendors and administrators appears to be
that QUIC-based traffic should be blocked because it renders Deep
Packet Inspection (DPI) and Intrusion Detection/Prevention Sys-
tems (IDS/IPS) useless (cf. Section 6). Typically, the communication
between client and server is then forced to fall back to TLS over TCP,
allowing enterprise firewalls to perform HTTPS DPI [6]. As of now,
firewall vendors do not provide any specifics on how enterprise-
level firewalls can filter QUIC traffic effectively.
Some inherent traits of the QUIC protocol, such as the connection
migration capability and the encrypted handshake, make QUIC-
based data exfiltration techniques arguably more devious than TLS
or DNS-based data exfiltration because middleboxes are not able
to differentiate between benign and spoofed connection migration
attempts. It is, therefore, crucial to understand how the underlying
properties of the QUIC protocol can impact the success of data
exfiltration attacks.
The goal of data exfiltration is to covertly extract sensitive data
from an infected host. There exist many methods to exfiltrate data —
depending on the underlying protocol used, some are more effective
than others. According to the MITRE ATT&CK framework [31],
data exfiltration attacks can be broadly divided into network-based
and physical exfiltration methods. The former leverages widely-
used network protocols, such as HTTP, HTTPS, or DNS, to send
data to a target device owned by a malicious actor. As part of the
latter, adversaries may use removable storage, such as external hard
drives or USB drives, to exfiltrate data. Effectiveness in this context
can be seen as a combination of data throughput and covertness
of the method. The severity of data exfiltration attacks becomes
apparent when considering the financial impact of data breaches.
The average cost of data breaches has been consistently rising over
the last years, with current estimations reaching a global all-time
high of 4.88 million USD per data breach. The top three industries
to experience the highest data breach costs are healthcare, financial,
and industrial [18].
In this paper, we specifically focus on QUIC’s server-side con-
nection migration feature. We show that an attack can be designed
that replicates the behavior of this feature to covertly exfiltrate data
to a target server. The attack can be leveraged by adversaries that
have already infected a host machine. From the perspective of a
middlebox, the exfiltration payload packets are not distinguishable
from packets that originate from a benign server-side connection
migration. While we initially explored classifiers as a potential de-
fense strategy to detect QUIC-based data exfiltration traffic, our
findings indicate that machine learning-based classifiers are inef-
fective in reliably distinguishing the attack from legitimate traffic.
To the best of our knowledge, this paper provides the first analysis
of QUIC-based data exfiltration attacks and potential mitigations.
The contributions of the paper can be summarized as follows:
✓We develop a QUIC-based data exfiltration method that ex-
ploits the QUIC connection migration feature by mimicking
a server-side path migration procedure to exfiltrate sensitive
data from an infected host machine. The method does not
require any changes to the QUIC client or server applications
and is designed based on the version-independent properties
of IETF QUIC.
✓We implement a PoC prototype in Rust, which comprises a
packet sniffer and a custom QUIC parser and mimics benign
packet features such as payload length, entropy, time differ-
ences between outgoing packets as well as the server-side
connection migration packets.
✓We show that due to the limited number of visible features
available in QUIC traffic, it is difficult to differentiate between
benign and malicious QUIC traffic. Our custom detectors
— Random Forest, Multi-Layer Perceptron, Support Vector
Machine, Autoencoder, and Isolation Forest — were trained
on over 700K QUIC packets and 786 server-side connection
migration events, collected across three distinct network
traffic scenarios.
✓In addition, we conducted unstructured interviews with five
leading firewall vendors to gain insights into the current
state of their QUIC traffic filtering capabilities.
First, we begin with the background (Section 2) and the prob-
lem statement (Section 3). Section 4 presents the data exfiltration
method and the threat model. Section 5 describes the PoC imple-
mentation written in Rust. Section 6 presents the experimental
setup, the anomaly detection results and the survey of leading
firewall vendors, followed by a brief discussion of additional mit-
igation strategies in Section 7, the related work in Section 8, and
the conclusion in Section 9.
2
Background
This section briefly introduces the main characteristics of the QUIC
protocol, focusing on its header structures and the connection mi-
gration features for both client-side and server-side migrations
since those are the most relevant aspects for the attack. The descrip-
tion of the packet headers mainly relies on the version-independent
properties of QUIC, defined in RFC 8999 [33], and connection mi-
grations are described based on RFC 9000 [19].
2.1
A QUIC Overview
QUIC packets generally come in two different forms: long header
and short header packets. Long header packets are sent as part of the
handshake messages before 1-RTT keys are established. Thereafter,
the QUIC endpoints switch to sending short header packets [19].
Long header packets include version-specific bits, the version num-
ber, CIDs for both source and destination as well as their respective
lengths, other version-dependent data, and the payload itself. In
comparison, short header packets only contain version-specific bits,
the Destination Connection ID (DCID), version-dependent data,
and the payload, meaning that the length of the CID cannot be
determined from a short header packet alone. Without observing
the initial long header packets, the necessary context for under-
standing short header packets, e.g., which connection they belong
to, cannot be established. All QUIC endpoints, therefore, need to
keep track of the CIDs in use [33].
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
2.2
Connection Migration
Compared to traditional TCP and UDP connections, where each
connection is uniquely identifiable by its 5-tuple (source IP address,
destination IP address, source port, destination port, protocol), a
QUIC connection may change its underlying 5-tuple without es-
tablishing a new connection using a handshake. This is referred
to as connection migration or (network) path migration. The pri-
mary benefit of QUIC connection migrations lies in the reduction
of Round Trip Times (RTT) since it eliminates performing hand-
shakes repeatedly whenever an endpoint changes IP address. This
feature is particularly time-saving when a QUIC endpoint migrates
multiple times [25].
Client-side connection migration is a feature within the IETF
QUIC standard that allows clients to change their source IP address
while retaining an existing connection with a QUIC server. This
process is presented in Fig. 1. The CM Initiator (i.e., client) detects
a source IP address change and sends a PATH_CHALLENGE frame
to the CM Responder (i.e., server). The server responds with a
PATH_RESPONSE frame, confirming receipt of the challenge and
the viability of the new path. The number of probing packet round
trips is version-dependent. Once the PATH_RESPONSE is received
by the client, the client may use the new source IP address for
all further (non-probing) communication with the server. Client-
side connection migrations are beneficial in cases where a QUIC
endpoint moves from Wi-Fi to the cellular network or vice versa
[19].
Server-side connection migration, like client-side migration,
ensures that a QUIC connection can continue seamlessly when-
ever the server’s IP address changes mid-connection. The server
preferred_address transport parameter is a data structure within
the quic_transport_parameters extension, which defines a sec-
ondary (preferred) server address. It is sent from a QUIC server to a
client as part of the handshake. The parameter contains fields for an
IPv4 Address, IPv4 Port, IPv6 Address, IPv6 Port, CID Length, CID,
and the Stateless Reset Token (cf. Fig. 2). A server may specify a pre-
ferred IPv4 and/or IPv6 address during the initial handshake, that
Figure 1: Client-side QUIC Connection Migration [26]
the client can use to communicate with the server at any time after a
successful connection establishment to the primary server address.
To initiate a server-side connection migration, the client simply
sends a path validation packet, containing a PATH_CHALLENGE
frame to the secondary address and waits for the server’s acknowl-
edgment [19]. It is important to note that both client-side and
server-side connection migrations are initiated by the client. The
server-side connection migration can, for example, be used in mi-
croservice deployment at the network edge to seamlessly migrate
a container hosting a QUIC-based service from one server address
to a different one with minimum latency [35]. Another use case
for server-side connection migration is splitting network traffic
mid-session across different network paths to increase privacy.
Wang et al. [45] introduce Connection Migration Powered Splitting
(CoMPS), which helps to reduce the risk of traffic analysis attacks
by network-level adversaries.
RFC 9000 [19] recommends reducing the linkability of QUIC
connections by, inter alia, using a new CID and source port when
migrating to another IP address. Consequently, a middlebox is
unable to tell whether a client performed a connection migration,
or if a second client is starting to communicate [15].
The prevalence of QUIC connection migrations has been shown
by [5], who found that the top providers that support connection
migrations are Cloudflare, AWS, Hostinger, Akamai and Google.
However, connection migration is not yet supported by other major
providers.
3
Problem Statement
In this section, we describe how server-side connection migrations
can be mimicked to exfiltrate sensitive data from a device. We com-
pare this approach to existing client-side request forgery attacks
and highlight the shortcomings of current firewall technologies in
analyzing QUIC traffic.
3.1
Connection Migration
As specified in RFC 9000 [19], “the use of a connection ID allows
connections to survive changes to endpoint addresses (IP address and
port), such as those caused by an endpoint migrating to a new net-
work.” Consequently, both a client and a server can use different IP
addresses to communicate while retaining an existing connection
[25].
Further, a “server might receive a packet addressed to its preferred
IP address at any time after it accepts a connection” [19]. Concretely,
a client can choose to migrate the connection to a preferred server
Figure 2: Format of the Server Preferred Address Transport
Parameter [19]
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
destination IP address and initiate the path migration by sending
a QUIC packet encapsulating a PATH_CHALLENGE frame to the
new (preferred) server IP address. This feature can be exploited by
an adversary who wants to mimic a QUIC server-side connection
migration by changing the destination IP address of an outgoing
QUIC packet and thus sending an illegitimate packet to the ad-
versary’s server. The payload of such a packet can be arbitrarily
modified so that it encapsulates sensitive data from the victim’s
machine. As specified in [19], the preferred server address is sent
from the server to the client as part of the encrypted handshake.
Hence, it remains unknown to a middlebox. Therefore, a middlebox
is unable to differentiate between legitimate preferred server ad-
dresses and malicious ones. It is important to note that migrating
to a new path does not require a dedicated handshake [25, 41]. The
path validation process is solely initiated by the client sending a
“PATH_CHALLENGE frame containing an unpredictable payload on
the path to be validated” [19].
Similarly to [12], who evaluated the effectiveness of client-side
Connection Migration Request Forgery (CMRF) attacks, our method
shows that the server-side connection migration feature can be
exploited to exfiltrate data from an infected client to a target server.
RFC 9000 [19] describes “Request Forgery with Spoofed Migration”
(i.e., CMRF) attacks, where clients can spoof the source address of
a QUIC packet as part of an apparent connection migration. This
tricks the server into sending datagrams to the spoofed address
[19]. However, [19] fails to mention that spoofing the destination
address using the preferred_address transport parameter of a
QUIC packet can be misused to covertly exfiltrate data from a
QUIC endpoint to a malicious server — disguised as a server-side
connection migration.
As per RFC 9000 [19], the preferred_address transport param-
eter may store a single secondary address for each address family
(IPv4 and IPv6). There are Internet draft specifications that aim
to increase the number of additional addresses that a server can
use, such as the Multipath Extension for QUIC by [25]. According
to [32], a QUIC frame can be specified which securely advertises
additional server IP addresses that a client may use to communicate
with the server. Such additional addresses are transmitted inside an
ADDITIONAL_ADDRESSES frame, which is also encrypted with the
rest of the handshake and thus remains invisible to a middlebox.
Therefore, a malicious exfiltration program may specify an exfiltra-
tion server IP address as the destination IP, and a middlebox has to
assume that this is a previously advertised server IP address.
3.2
Firewalls
It is inherent to the QUIC protocol that CID renegotiation happens
in an encrypted way — out of sight of potential path-based net-
work filtering devices such as firewalls. In order to keep track of a
QUIC connection, a stateful firewall would need to store the Source
Connection ID (SCID) during the handshake [11] and subsequently
match the DCID of an outgoing packet with the previously stored
SCID. However, changes in DCID are not visible to a middlebox,
as renegotiation of CIDs can occur post-handshake inside the en-
crypted “Protected Payload” packets. QUIC does not expose any
more unencrypted information on the connection migration pro-
cess. Since path validation packets are not preceded by a dedicated
handshake and the connection can be migrated to another endpoint
on both the client and the server-side at any time [19], firewalls
would need to treat QUIC packets without a prior handshake as
connection migration attempts, yielding UDP 5-tuple checks and
CID tracking unfeasible.
If no full decryption of the QUIC traffic is done, it is almost
impossible for a middlebox to differentiate between a legitimate
connection migration and a spoofed one by only analyzing un-
encrypted packet headers. Currently, firewalls simply filter QUIC
traffic based on the handshake packets, but may not be able to
perform further stateful inspection after the handshake. Therefore,
to further motivate this research, we have conducted unstructured
interviews with five leading firewall vendors, who support our
findings regarding the challenges of effectively analyzing QUIC
traffic. They emphasize the difficulty in distinguishing between
legitimate and spoofed connection migrations without decrypting
QUIC traffic.
In summary, connection migration — a feature that enhances
QUIC’s performance — can also be misused by the data exfiltration
method proposed in this paper. In the following section, we present
a methodology and the PoC implementation for demonstrating
how QUIC’s connection migration feature can be exploited and
we show that QUIC-based data exfiltration attacks are difficult to
differentiate from the normal protocol behavior.
4
Methodology
In the following, we provide a comprehensive description of the
proposed data exfiltration attack. After presenting an overview of
the threat model and the underlying assumptions, we introduce
the methodology, which comprises a sniffing phase, spoofed path
validation, and a continued exfiltration phase.
4.1
Threat Model & Assumptions
We consider a scenario in which an attacker has already infected a
victim’s machine and aims to covertly exfiltrate sensitive data to a
target server owned by the attacker. The attack is performed as per
the MITRE ATT&CK framework sub-technique “Exfiltration Over
Alternative Protocol: Exfiltration Over Symmetric Encrypted Non-
C2 Protocol” [31]. Circumventing on-device anomaly detection
systems is out of the scope of this paper, as we only consider on-
path middleboxes and additional on-path traffic analysis software
to be the main defenders.
The underlying assumptions can be summarized as follows:
(1) It is assumed that the adversary has successfully gained ac-
cess to a compromised machine within the internal network
of a victim. The compromised machine is firewalled, mean-
ing it is located behind a host-based and/or enterprise-level
network-based stateful firewall.
(2) The adversary is also capable of secretly deploying the data
exfiltration software onto the compromised machine and has
gained elevated privileges to successfully execute the attack.
(3) We assume that a defender (e.g., the firewall administrator)
does not enforce a strict packet inspection policy (i.e., full
decryption of traffic) and does not outright block UDP ports
80 and 443.
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
(4) We further assume that the defender knows how to perform
(encrypted) traffic analysis, which encompasses the analysis
of packet lengths, time deltas between adjacent packets, pay-
load entropy, and the analysis of all the cleartext information
sent during the handshake.
4.2
Data Exfiltration Method
We base our method on the version-independent properties of the
IETF QUIC protocol [33] and the connection migration feature
described in RFC 9000 [19], in which a QUIC client has prior knowl-
edge of the alternative server addresses to which it can choose
to migrate its connections. During connection establishment, the
server notifies the client about its alternative addresses by populat-
ing the preferred_address transport parameter with one or more
alternative addresses. If a packet gets lost during the communica-
tion, the client can assume that the server has migrated to a new
address and the client can choose to validate the new network path
by sending a probing packet to the new server address [35]. Alter-
natively, the client may initiate a server-side connection migration
at any time by sending a path validation packet to the preferred
server address.
Fig. 3 presents the data exfiltration methodology, which is di-
vided into three distinct phases — a sniffing phase, a path validation
phase, and the main exfiltration phase. The involved entities are (i)
the client (victim), whose machine is infected with the exfiltration
tool, (ii) a middlebox, whose task is to detect and block suspicious
network traffic, (iii) a benign server, and (iv) the malicious exfiltra-
tion server, which accepts all incoming connections and sends the
respective response messages. During the initial sniffing phase, the
data exfiltration software collects all outgoing QUIC short header
packets and stores relevant information such as IP, UDP, and QUIC
headers, as well as timestamps and the QUIC payload lengths. This
Client
(Victim)
Middlebox
Legitimate QUIC Packets
Benign
Server
Exfiltration
Server
Spoofed QUIC Path Validation
Spoofed QUIC Path Validation
Spoofed QUIC Path Validation
Sniffing
phase 
Legitimate QUIC Packets
Builds
state table
payload = Enc{benign_data}
DCID = abcdef
udp.src = 12345
udp.dst = 443
ip.src = 127.0.0.1
ip.dst = 10.11.12.13
Wait for
sufficient
dataset 
Mimic path
validation
Continued
exfiltration
phase
Assumes that
connection
migration has
occurred
Legitimate QUIC Packets
payload = Enc{secret_data}
DCID = fedcba
udp.src = 54321
udp.dst = 443
ip.src = 127.0.0.1
ip.dst = 10.10.10.10
Spoofed QUIC Path Validation
Spoofed QUIC Protected Payload
Spoofed QUIC Protected Payload
Spoofed QUIC Protected Payload
Spoofed QUIC Responses
Spoofed QUIC Responses
Figure 3: Proposed Data Exfiltration Attack.
information is reused at a later stage to mimic the structure of
benign packets.
As part of the sniffing phase, the exfiltration tool waits for ex-
isting connections to retire their CID by continuously probing
whether the socket that binds the currently used source port can be
re-bound. Once the CID has been retired, the exfiltration tool can
immediately emulate a server-side connection migration, without
having to fear that benign traffic continues to be sent and causing
suspicious overlaps of benign and malicious traffic originating from
the same QUIC connection.
The first step of a connection migration is the path validation,
which is mimicked by sending a spoofed path validation request to
the malicious exfiltration server. The spoofed path validation packet
may already contain the first bytes of sensitive data since a benign
path validation packet is also sent via an encrypted channel and
is, therefore, not visible to a middlebox. As per [19], a benign path
validation request includes an 8-byte PATH_CHALLENGE frame,
which in turn expects an 8-byte PATH_RESPONSE frame. An end-
point must use datagram sizes of at least 1200 bytes to transmit
PATH_CHALLENGE and PATH_RESPONSE frames, as this ensures
that the path is able to handle datagrams of this size [19]. Therefore,
the spoofed path validation datagrams are also designed to have
a size of at least 1200 bytes. When the middlebox first encounters
the path validation packet, it must either assume that a QUIC con-
nection migration is occurring or that an arbitrary UDP packet is
sent to a destination address that has not been seen before. In both
cases, middleboxes generally allow connections initiated from the
inside (trusted) network to the outside.
Lastly, the main exfiltration phase begins by continuously send-
ing packets to the spoofed exfiltration server address and receiving
the appropriate spoofed responses from the exfiltration server, to
mimic a “healthy” connection between a QUIC client and a QUIC
server. Thereafter, the malicious connection may then be retired at
any time and a new suitable connection can be selected to mimic
another connection migration.
It is important to note that the method does not attempt to
transmit any handshake packets. Therefore, middleboxes and/or
fingerprinting software cannot detect nor block an illegitimate
connection establishment attempt based on a handshake packet (cf.
Section 6.3).
4.3
Increasing Stealthiness
In order to increase stealthiness, the data exfiltration tool can store
a range of exfiltration server destination IP addresses; it may only
use an address once to mimic a single connection migration and
discards the address afterwards.
Furthermore, to minimize the payload size variance between
benign and malicious traffic, the malicious payload lengths are
sampled from a distribution of benign payload lengths, making a
statistical analysis of packet lengths less feasible. Similarly, the time
deltas between QUIC packets, which can be considered a unique
fingerprint of the application, are also mimicked (cf. Section 6.2).
The exfiltration payloads are encrypted with an AES-256 key stored
in the data exfiltration executable. This key is not used to establish
secrecy, but rather to increase the entropy of the data exfiltration
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
Infected Host
Exfiltration Server
Packet Sniffer
<pcap>
UDP Payload
Packet Parser
<etherparse>
Custom
QUIC Parser
Default
Network
Interface
Packet Bytes
Data
Exfiltration
Payload
Builder
UDP Payload
UDP Socket
Listener
QUIC Payload
Custom QUIC
Parser
Data
Reconstructor
Data
Figure 4: Proof-of-Concept Prototype Architecture.
payloads, in order to resemble the entropy of benign QUIC protected
payload packets.
Data exfiltration is only attempted when a legitimate connection
is retired, i.e., when its DCID changes, or stops being used by the
QUIC endpoint. Additionally, our method’s exfiltration throughput
is dependent on the user’s activity, and only exfiltrates data while
the user is actively browsing the web.
4.4
Domain Registration Records
Detecting exfiltration traffic based on mismatches between domain
registration records of old and new destination IP addresses is
possible. However, as shown in [27], the WHOIS records may not
be publicly accessible under certain jurisdictions. The EU General
Data Protection Regulation (GDPR) requires certain WHOIS data to
be redacted, which could make this attack more difficult to detect.
Furthermore, an attacker could host an exfiltration server on
Amazon Web Services (AWS), resulting in domain registration
records in which the organization’s name appears identical to those
of legitimate Amazon.com traffic. Similarly, YouTube traffic IP ad-
dresses have WHOIS records pointing to Google LLC. Data exfiltra-
tion servers hosted on Google Cloud would have similar WHOIS
records, making it challenging to identify them as malicious based
only on WHOIS records.
Checking published IP address ranges specific to a cloud provider,
which can be obtained directly from a cloud provider’s documenta-
tion, is one way to identify exfiltration attempts. For instance, when
a QUIC connection to google.com migrates to a new destination
server hosted in a Google Cloud, with identical domain registration
records, it may be possible to cross-check against public IP address
ranges of Google Cloud services to identify spoofed connection
migration attempts. However, as of now, there is no indicator that
leading firewall vendors offer such functionality in their products
to identify connection migrations and differentiate between benign
and malicious ones (cf. Section 6.4).
5
Implementation
The PoC prototype was implemented in Rust as depicted in Fig.
4 and the client’s source code has been released1. It consists of a
client-side data exfiltration executable, which comprises a packet
sniffer, packet parser, custom QUIC parser, and exfiltration payload
builder module. The server-side executable consists of a UDP socket
listener, a custom QUIC parser and a data reconstruction module.
Every exfiltration task is performed in a new thread, meaning
that multiple malicious connection migrations can be performed in
parallel for different QUIC connections, while the outgoing benign
traffic is continuously monitored for suitable connections that can
be used to mimic new connection migrations. The outgoing QUIC
packets are sniffed using the Rust pcap library [9] (version 1.2.0)
and parsed using the Rust etherparse library [40] (version 0.14.2).
It is assumed that QUIC uses port 443 over UDP. Every outgoing
UDP packet’s payload is parsed as per the version-independent
properties of the QUIC protocol [33]. The header structure of short
header packets does not specify where the DCID ends nor does it
specify the length of the DCID. Hence, observing a short header
packet alone, does not give any indication to where the DCID bytes
end and where the payload bytes start. If the parser identifies a
QUIC long header packet as part of a handshake, it extracts its DCID,
stores it, and subsequently discards the packet. The DCID is then
used to map succeeding short header packets to their preceding
handshake. This is required to (i) replicate the exact length of the
original DCID in spoofed packets, as QUIC endpoints usually stick
to a certain CID length, and (ii) mimic the lengths of the original
payloads. Special cases, such as packets that contain a long and a
short header at the same time or packets that contain a zero-length
DCID, are discarded.
Monitoring all outgoing packets on the default network interface
can result in a loop, as the exfiltration client itself also transmits
packets over this interface. Sniffing and parsing those packets would
result in an unnecessary performance overhead and would dilute
the observed features of benign packets. To prevent this, the exfil-
tration client maintains a blacklist to ignore all malicious packets.
This blacklist contains the SHA-3-256 hashes of all previously sent
malicious packets, against which every outgoing packet is checked.
6
Evaluations
This section first introduces the experimental setup and the three
different user activity scenarios that were considered. Subsequently,
this section focuses on identifying unique features of QUIC connec-
tion migrations and training anomaly detection classifiers to try to
detect the proposed attack. The remainder of this section discusses
the feasibility of detecting the proposed attack using fingerprinting
tools, followed by the results of a survey of leading firewall vendors,
who were asked to assess the QUIC-filtering capabilities of their
firewall products as part of unstructured interviews.
1https://github.com/thomasgruebl/quic-exfil
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Table 1: Network Traffic Generation and Device Roles in the Experimental Testbed.
Device Number
Traffic Type
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
QUIC Traffic
Benign Migration
Exfiltration
Non-QUIC Traffic
Table 2: Number of Benign and Malicious Connection Migra-
tions per Scenario.
Scenario
Benign
Malicious
Mixed
245
27
YouTube
371
34
Noise
98
11
Total
714
72
6.1
Experimental Setup
In our experimental setup, we simulate a small network of devices
to generate QUIC traffic, including benign and malicious server-
side connection migrations. The network consists of 16 Docker
containers running Ubuntu 18.04 LTS with the Xfce desktop envi-
ronment and VNC/noVNC servers to provide remote access [1]. Our
machine acting as a firewall is a virtual machine (VM) with 32 GB of
RAM, running Ubuntu 22.04 LTS. It uses iptables with the conntrack
module for stateful packet filtering and connection tracking. Packet
capturing is performed on the inward-facing interface of the firewall
(i.e., the Docker virtual Ethernet bridge adapter). As shown in Table
1, the network generates multiple types of traffic. Devices 1–8 gen-
erate QUIC traffic, including benign QUIC connection migrations
to simulate real-world user-initiated network traffic. Devices 9–16
represent other backend (non user-controlled) machines, which do
not generate QUIC traffic. Devices 7–10 are infected with the data
exfiltration software and generate malicious connection migrations
as well as QUIC-based data exfiltration traffic. All devices (1–16)
also generate other types of non-QUIC network traffic. To emu-
late QUIC server-side connection migrations, we used a modified
version of Cloudflare quiche v0.23.2 [7]. The quiche server is run-
ning on the firewall, the quiche clients are running on devices 1–8
and trigger QUIC connection migrations at random time intervals
every 0–30 minutes. This allows us to collect benign connection
migration fingerprints. The total number of generated connection
migrations, benign and malicious, are presented in Table 2. Every
single malicious connection migration in the dataset, that is fol-
lowed by at least one exfiltration payload packet, constitutes a data
exfiltration attempt.
As mentioned in Section 4.3, to increase the stealthiness of the
method, the exfiltration throughput depends on the network activ-
ity of the infected hosts. Therefore, the following evaluation does
not demonstrate that a certain throughput can be achieved. Instead,
it considers three different user scenarios in which the exfiltration
tool attempts to send data to a target server and evaluates the per-
formance of the anomaly detection classifiers. The following user
activity scenarios were considered:
(1) General Network Activity (24h of Mixed Traffic): A simulated
small company network consisting of 16 Docker containers,
each representing a host that collectively generates web traf-
fic over a 24-hour period. This includes browsing across var-
ious domains (e.g., youtube.com, google.com, facebook.com,
instagram.com, cloudflare.com, amazon.com, chatgpt.com)
and thus creating a number of different overlapping QUIC
connections.
(2) Isolated Streaming Scenario (24h of YouTube Traffic): The
same simulated network, but now restricted to generating
primarily YouTube video traffic over a 24-hour period. This
scenario serves as a controlled test case to contrast with the
more diverse traffic patterns of the general network activity.
(3) Background Noise Traffic (24h Idle Mode): A subset of de-
vices generating low-interaction background traffic for 24
hours, simulating idle devices with existing open QUIC con-
nections (e.g., open browser tabs, apps, etc.) but minimal
active user interaction.
Across all three scenarios, we gathered a total of 710,690 outgo-
ing QUIC short header packets, of which 690,101 are benign and
20,589 are spoofed. Scenario 1 (i.e., mixed traffic) generated 427,644
outgoing QUIC short header packets, 416,961 of which are benign
and 10,683 of which are spoofed. The total achieved exfiltration vol-
ume is 6.34 MB. Scenario 2 (i.e., YouTube traffic) generated 255,649
outgoing QUIC short header packets, 247,624 of which are benign
and 8,025 of which are spoofed, resulting in a total data exfiltration
volume of 2.97 MB. Scenario 3 (i.e., noise traffic) generated a total
of 27,397 packets, including 25,516 benign and 1,881 malicious ones
and achieved a total volume of 1.10 MB.
It is evident that the data exfiltration throughput is highly de-
pendent on the victim’s activity. In cases where the user browses
websites that do not require large amounts of data to be down-
loaded, only infrequent QUIC acknowledgment packets are being
sent back to the server. YouTube traffic generates many outgoing
QUIC acknowledgments with small payload sizes. Data uploads to a
cloud provider typically generate a high number of outgoing QUIC
packets using the maximum payload size. Mimicking a connection
migration in the latter case enables the attacker to exfiltrate large
amounts of sensitive data.
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
Table 3: Anomaly Detection Features.
Category
Feature
Considered
Justification
Handshake
TLS Client Hello, Server Hello, etc.
✗
Both legitimate and spoofed connection migrations cannot be reliably mapped to a preceding
handshake.
Short Header Packets
Packet Length
✗
The length of the entire packet is dependent on features that may also differ across benign
packets (e.g., IP header structure).
SCID/DCID
✗
Both the length of the CIDs and the CIDs themselves have no informational content and can
vary across benign and malicious traffic.
QUIC Payload Length
✓
The payload length may be used as an indicator of irregular traffic patterns. Unusual payload
sizes can indicate data exfiltration attempts.
Connection Migration Payload Length
✓
The payload length of a connection migration packet (i.e., a packet containing a
PATH_CHALLENGE frame) can be used as an indicator of unusual connection migration
attempts.
Time Δ between two outgoing packets
✓
The data exfiltration tool may have different processing times compared to a benign QUIC
endpoint.
Time Δ between two ingoing packets
✗
This feature is similar to the previous one, since the exfiltration server’s QUIC endpoint would
be functioning identically to the QUIC endpoint running on the client, therefore only one of
the two features need to be considered.
Time Δ between a request-response pair
✗
The RTT latency can be arbitrary for both legitimate and spoofed addresses, depending on the
physical location of the destination server.
Payload Entropy
✗
The entropy of payloads can be imitated by encrypting the exfiltration payload using a crypto-
graphic key stored in the exfiltration software.
Latency Spin Bit
✗
The latency spin bit is used by on-path observers to measure the per-round-trip latency. For
every received packet from the server, the client simply flips the bit, which does not provide
enough informational content to differentiate benign from malicious traffic.
Fixed Bit
✗
As the name suggests, the fixed bit has a constant value and serves as a way to differentiate
QUIC traffic from other UDP-based traffic. It can simply be adopted by malicious packets.
Packet number
✗
In short header packets, the packet number, as well as its length, are cryptographically obfus-
cated and thus not visible to middleboxes.
Other QUIC-version dependent bits
✗
A spoofed packet can simply adopt these bits from a benign packet.
6.2
Anomaly Detection
In this evaluation section, we analyze the proposed data exfiltration
method by assessing the ability of machine learning-based anomaly
detectors to detect this kind of malicious network behaviour. Since
existing anomaly detection classifiers that detect network-based
exfiltration attempts are commonly trained on handshake metadata
[49], and QUIC connection migrations do not require handshakes, a
new feature set needs to be defined for QUIC-based data exfiltration
traffic.
Table 3 presents a range of different features that can be consid-
ered in the context of QUIC traffic analysis. Most features can be
easily imitated — only three features have been identified which
require some level of sophistication to imitate. Therefore, our ob-
jective was to mimic the following features with the help of our
PoC implementation: 1 The connection migration payload, 2
the “normal” QUIC packet payload length, and 3 the time delta
between two outgoing packets of the same QUIC flow.
Feature 1 is a binary feature that captures connection migra-
tion attempts in outgoing QUIC packets. More specifically, it ob-
serves the first packet of a connection migration and stores its
payload length. We classify every observed migration attempt ac-
cordingly, using this binary label as a potential discriminator be-
tween “normal” protected payload packets and packets containing
a PATH_CHALLENGE frame.
Feature 2 , payload length, can be imitated by first observing
benign traffic during the sniffing phase depicted in Fig. 3. After
a sufficiently sized dataset of benign QUIC payload lengths has
been collected, the data exfiltration tool randomly samples from
this dataset – essentially replicating the payload sizes of previously
seen traffic of the same QUIC flows. For instance, when mimicking
a connection migration of a YouTube server, the exfiltration tool
continues to use the same payload sizes as those observed in benign
acknowledgment packets sent from the client to the YouTube server.
We heuristically chose to gather a dataset of 1,000 packets per QUIC
connection prior to the first exfiltration attempt.
To replicate the payload sizes of benign QUIC flows, we define
D to be the entire dataset that is created over the course of an
exfiltration process. Since the dataset changes over time, we denote
the subset of the dataset at time 𝑡by D𝑡which is used to choose
the next QUIC payload size. We then randomly sample a value 𝑥
from the dataset D at time 𝑡,
𝑥𝑡∼D𝑡
and use this value 𝑥𝑡to set the length of the next malicious
payload.
Feature 3 , the time delta between two outgoing packets, is
computed as per Algorithm 1. The intervals in which the packets
are placed “on the wire” can be considered a unique fingerprint of an
application. From the attacker’s perspective, this is the most difficult
feature to mimic among the three, because it requires dynamic
adjustments of inter-arrival times on a per-flow basis. To mimic
feature 3 , Algorithm 2 was implemented.
Algorithm 1 monitors the time deltas of benign QUIC connec-
tions and stores them in a dictionary. During data exfiltration, Al-
gorithm 2 randomly samples from this distribution to determine
the appropriate sleep time before sending the next packet. The base
rate of exfiltration was determined by running a single thread of
the tool, measuring the time deltas, and averaging them. Since the
standard deviation is low, the average can be reliably used. The
base rate is typically very close to zero (median: 7 ms, average: 58
ms), meaning the required sleep times closely match the observed
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Algorithm 1 Compute Time Deltas per DCID
Require: Pre-filled hashmap 𝐻⊲Key: DCID, Value: Sorted list of
timestamps
1: Initialize an empty hashmap Δ𝑇
⊲Stores time deltas for all
DCIDs
2: for each (𝐷𝐶𝐼𝐷, 𝑇list) in 𝐻do
3:
if |𝑇list| > 1 then
4:
for 𝑖←1 to |𝑇list| −1 do
5:
Compute time delta:
Δ𝑇𝑖= 𝑇list[𝑖+ 1] −𝑇list[𝑖]
6:
Append Δ𝑇𝑖to Δ𝑇[𝐷𝐶𝐼𝐷]
7:
end for
8:
end if
9: end for
10: return Δ𝑇
Algorithm 2 Mimic Observed Time Deltas
Require: Δ𝑇= {𝐷𝐶𝐼𝐷1 : [𝑑𝑡1,𝑑𝑡2, ...], 𝐷𝐶𝐼𝐷2 : [𝑑𝑡1,𝑑𝑡2, ...]}
⊲
Observed time deltas
Require: 𝐵𝑅
⊲Base rate of packet sending
Require: 𝑛
⊲Number of packets to exfiltrate
Ensure: Adjusted sleep times for mimicking the observed rate
1: for 𝑖←1 to 𝑛do
2:
Δ𝑇𝑖= Get random sample from Δ𝑇[𝐷𝐶𝐼𝐷]
3:
Compute sleep time:
𝑆𝑖= Δ𝑇𝑖−𝐵𝑅
4:
if 𝑆𝑖> 0 then
5:
Sleep for 𝑆𝑖milliseconds
6:
else
7:
No sleep needed
8:
end if
9:
Send packet
10: end for
time deltas. This low base rate can be traced back to the fact that
the exfiltration tool bypasses common rate-limiting mechanisms
such as flow control and congestion control, making it faster than
most other applications.
We do not consider time intervals between adjacent pairs of
requests and responses, because these are dependent on the loca-
tion of the destination server – which can also significantly differ
across benign servers performing connection migrations. Nor do
we consider the time deltas between two ingoing packets, since this
feature’s expressiveness is identical to 3 .
Given the inherent challenges of anomaly detection in realistic
highly imbalanced network traffic datasets where data exfiltration
attempts constitute a small fraction (∼3%) of the overall traffic, we
evaluated the performance of five distinct anomaly detection clas-
sifiers. These classifiers use both supervised methods — Random
Forest (RF), Multi-Layer Perceptron (MLP), and Support Vector Ma-
chine (SVM) — and unsupervised methods — Autoencoder (AE)
and Isolation Forest (IF). Supervised methods, such as RF, MLP,
and SVM, typically perform well in scenarios where clear decision
Table 4: Comparison of the Classification Performance
Across Three Scenarios
Classifier
Metric
Scenario
Mixed
Youtube
Noise
RF
F1-Score
0.35
0.18
0.47
Recall
0.31
0.15
0.45
Precision
0.40
0.22
0.50
Accuracy
0.97
0.96
0.94
MLP
F1-Score
0.07
0.10
0.20
Recall
0.44
0.34
0.45
Precision
0.04
0.06
0.13
Accuracy
0.72
0.81
0.78
SVM
F1-Score
0.02
0.05
0.08
Recall
0.03
0.07
0.08
Precision
0.02
0.04
0.08
Accuracy
0.93
0.92
0.89
AE
F1-Score
0.00
0.01
0.00
Recall
0.01
0.01
0.00
Precision
0.00
0.01
0.01
Accuracy
0.92
0.92
0.93
IF
F1-Score
0.06
0.08
0.05
Recall
0.23
0.21
0.08
Precision
0.03
0.05
0.04
Accuracy
0.82
0.84
0.83
RF →Random Forest, MLP →Multi-Layer Perceptron, SVM →Support Vector
Machine, AE →Autoencoder , IF →Isolation Forest
boundaries can be learned from labeled examples [49]. Unsuper-
vised methods, like AE and IF, are designed to identify anomalies
without explicit labels, by learning the characteristics of normal
data and flagging deviations. We selected these classifiers to assess
the robustness of feature-based anomaly detection against the data
exfiltration technique designed to mimic benign traffic patterns.
We evaluated the detection performance across the three user
activity scenarios. Table 4 presents a comparative analysis of the
classifiers, which focuses on the following metrics: Precision, Recall,
and F1-Score for the anomaly class, and overall Accuracy. Due to
the class imbalance, accuracy alone is not a reliable indicator of per-
formance, as high accuracy can be trivially achieved by classifiers
that predominantly predict the majority class (i.e., benign traffic).
Across all scenarios, the results presented in Table 4 reveal that
all five classifiers are unable to effectively detect the data exfiltration
attempts. Despite achieving high accuracy scores in some scenar-
ios, these scores are misleading due to the imbalanced datasets.
The more important metrics for the anomaly class — F1-Score, Re-
call, and Precision — consistently show very low values across all
classifiers and scenarios.
In the YouTube scenario, for instance, the RF classifier achieves a
relatively high accuracy of 96%. However, its F1-Score for detecting
data exfiltration is 0.18, with a Recall of only 0.15 and a Precision of
0.22. This indicates that while RF correctly classifies the majority
of benign traffic, it fails to identify most actual data exfiltration
attempts and produces a high number of false negatives. Similar
poor performance is observed for the MLP and SVM classifiers
in the YouTube scenario, with even lower F1-Scores of 0.10 and
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
(a) Random Forest Classifier.
(b) Multi-Layer Perceptron Classifier.
Figure 5: Normalized Feature Importance Across Three Scenarios.
0.05 respectively. The AE yields a near-zero F1-Score (0.01) and IF
achieves a slightly higher but still very low F1-Score of 0.08.
In the Noise scenario, RF achieves a high accuracy of 96%, while
its F1-Score for anomaly detection remains low at 0.47. MLP per-
forms even worse with an F1-Score of 0.20 in this scenario. SVM
and AE again show very poor anomaly detection performance, with
near-zero F1-Scores. IF exhibits a slightly improved F1-Score of 0.05
compared to AE and SVM.
In the Mixed traffic scenario, the anomaly detection performance
of all classifiers is low. RF achieves the highest F1-Score among
the classifiers at 0.35, but still fails to differentiate benign from
exfiltration traffic. MLP, SVM, AE, and IF all exhibit very low F1-
Scores, ranging from 0.00 to 0.07.
We have also conducted a feature importance analysis for both
the RF and MLP detectors. We used the Gini importance metric
for RF, a measure of how much each feature contributes to the
homogeneity of nodes in decision trees. For the MLP detector, we
employed the Sharpley Additive Explanation (SHAP) method [28],
a game-theoretical approach that attributes the model output to
each feature based on their marginal contributions. Fig. 5a reveals
that feature 3 is the most important across all three scenarios.
Our analysis also indicates that for the MLP, the time delta feature
contributes 100% to its classification decisions (cf. Fig. 5b). However
due to the successful mimicking strategy of time delta feature 3 ,
it is still difficult to detect malicious attempts.
6.3
Fingerprinting Software
Network metadata fingerprinting tools collect information from
packet headers (e.g., IP addresses, port numbers, TLS-specific meta-
data) to create a “fingerprint” that uniquely identifies a network
packet flow. This fingerprint can be used not only for various pur-
poses, such as network performance optimization and device man-
agement, but also to make inferences about the underlying applica-
tion or website that is visited. The features used for fingerprinting
can be extracted by a passive eavesdropper, such as an on-path
observer [13]. Fingerprinting tools, such as the open-source tools
Cisco Mercury [30] or FATT [20], extract a fingerprint from a QUIC
handshake and try to map non-handshake packets to their preced-
ing handshakes. The mapping between the handshakes and the
corresponding payload packets is done using the 5-tuple. Packets
with modified 5-tuples and no preceding handshakes (i.e., QUIC con-
nection migration packets) are therefore not mapped to a specific
fingerprint.
Wireshark [46] offers the ability to follow QUIC streams. When
encountering unknown QUIC packets that cannot be associated
with a handshake, the packets are labeled as “Unknown QUIC connec-
tion. Missing Initial Packet or migrated connection?”, if the protected
payload packet contains a CID that was not previously seen as part
of the handshake packets. In our current PoC implementations, we
reuse existing DCIDs. Even when new DCIDs are used, Wireshark’s
labeling process cannot distinguish between benign and malicious
connection migrations.
As part of the evaluation, a post-analysis of the captured PCAP
files has been performed using Cisco Mercury [30]. The preceding
handshake for both benign and malicious connection migrations
was detected by Cisco Mercury, however, the tool fails to map the
traffic after a migration (including the migration event itself) to the
original handshake. This means, that the tool is unable to correlate
the post-migration traffic with the initial connection, hence, treating
it as an entirely new flow rather than a continuation of the original
session. As a result, since the new UDP flow lacks handshake data,
the malicious destination IP address of the exfiltration server cannot
be found in the Cisco Mercury fingerprinting results.
6.4
Survey of Leading Firewall Vendors
As part of this study, unstructured interviews with leading firewall
vendors were conducted. The qualitative approach of surveying
vendors was intended to replace a quantitative evaluation because
it directly addresses the core question: whether modern firewalls
even possess the necessary features to reliably detect QUIC con-
nection migrations. We contacted eight firewall vendors listed in
[10], five of which agreed to share their perspectives on the QUIC
protocol for research purposes. The interviewees’ roles included
“Systems Engineer”, “Cyber Security Specialist”, “Senior Sales Engi-
neer”, “Consulting Systems Engineer”, “Senior Solutions Engineer”
and “Systems Engineering Manager”. The main questions asked, pre-
sented in Table 5, revolved around the capabilities offered by their
firewall products with regard to handling QUIC traffic. Specifically,
the survey sought to determine whether the vendors (i) recom-
mend blocking QUIC entirely, (ii) include information about the
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Table 5: Perspectives on the QUIC Protocol from Leading Firewall Vendors
Firewall vendor ...
A
B
C
D
E
(i) recommends blocking QUIC entirely.
✓
✓
✓
✓
✗
(ii) builds a state table based on QUIC connection IDs.
✗
✗
✗
✗
✗
(iii) can differentiate QUIC traffic from other types of traffic.
✓
✓
✓
✓
✓
(iv) can perform basic filtering of QUIC traffic (allow / deny).
✓
✓
✓
✓
✓
(v) currently offers functionality to decrypt QUIC traffic on the firewall.
✗
✗
✓
✓
✓
(vi) has HTTP/3 Deep Packet Inspection (DPI) capabilities.
✗
✗
✓
✓
✓
(vii) can recognize QUIC connection migrations.
✗
✗
✗
✗
✗
(viii) plans on / is currently developing new QUIC-related firewall features.
✓
✓
✓
∼
✓
(ix) believes that the competitors struggle with identical challenges.
✓
✓
∼
✓
✓
∼→Is unsure / cannot provide clear answer.
QUIC protocol into their firewall state tables, (iii) can differentiate
QUIC traffic from other types of traffic, and (iv) can perform basic
filtering of QUIC traffic. Additionally, it was assessed whether the
firewalls (v) currently offer functionality to decrypt QUIC traffic,
which is similar to HTTPS decryption on a technical level, and
(vi) can perform HTTP/3 DPI. Full decryption of QUIC traffic is a
pre-requisite for performing HTTP/3 DPI, which three out of five
vendors are currently offering as part of their product suite. DPI
refers to analyzing the contents of the packet after decrypting it,
although it is also sometimes referred to as header analysis of the
unencrypted QUIC handshake portions, such as the TLS Server
Name Indication (SNI) field. Full decryption means that the firewall
performs a man-in-the-middle inspection on QUIC traffic, mak-
ing all embedded contents (e.g., HTTP/3) readable to the firewall
and enabling fine-grained content filtering. No vendor mentioned
that their firewall solutions can reliably identify QUIC connection
migrations – neither client-side nor server-side (vii).
Almost all surveyed vendors are (viii) planning on developing
or currently actively developing new QUIC-related features. How-
ever, as of now, they still recommend that their clients block the
QUIC protocol entirely. Interestingly, all participants shared that
QUIC traffic analysis features are rarely requested by clients, which
suggests that there may be a lack of awareness or understanding
about the importance and benefits of QUIC traffic analysis. Addi-
tionally, the firewall vendors were asked for their perspective on
how their competitors are dealing with the increase in QUIC traffic.
The general consensus among four out of five participants was that
QUIC traffic analysis seems to be, as expected, an industry-wide
challenge (ix).
7
Discussion
As of today, modern firewalls are not tracking QUIC connections in
state tables, meaning that state tables have to treat every outgoing
UDP packet as a new connection attempt [11]. Firewalls generally
operate under the assumption that outgoing traffic is safe, as it
originates from within the trusted network. When an outgoing UDP
packet arrives at the firewall, the firewall checks whether the state
table contains an existing entry corresponding to the packet’s 5-
tuple. If a matching entry is found, the packet is processed according
to the pre-established rules for that connection. If no matching entry
exists, the firewall may create a new entry in the state table or take
other actions based on its configuration.
Although there are ways to perform stateful treatment of QUIC
traffic based on its few observable features, such stateful treat-
ment requires trade-offs with the confidentiality and censorship-
resistance of the protocol. RFC 9312 [22] discusses the manageabil-
ity of the protocol and analyzes ways to perform stateful treatment
of QUIC traffic. Apart from observing the cleartext parts of the
handshake and implementing custom QUIC extensions that un-
conceal more information, there are limited options available to
reliably track connections. Using the CID as a stateful identifier
is not possible, since the CIDs can be renegotiated at any time
within the encrypted channel. Stateful firewalls cannot even rely
on the detection of end-of-flow signals to terminate a connection,
as end-of-flow signals are not visible to an on-path observer [22].
Therefore, a QUIC-aware firewall would have to rely on timer-based
state removals.
In the context of the proposed data exfiltration method, this
means that, as of today, most enterprise-level network-based fire-
walls cannot detect a potential QUIC connection migration, nor can
they differentiate between migrations and request forgery attacks.
7.1
Mitigation Strategies
The risk of the proposed attack can be partly mitigated through the
following countermeasures:
• A client may disable QUIC transport parameters, like active
connection migration using the disable_active_migration
(0x0c) flag, or remove the server preferred_address field
from the QUIC implementation. Any connection migration
attempt can then be flagged as anomalous activity.
• A modification to QUIC’s implementation so that the
preferred_address transport parameter field is part of the
unencrypted QUIC handshake. As a result, custom middle-
box software can be developed that can recognize connec-
tion migration attempts by monitoring QUIC packets for
changes in their source or destination IP addresses and/or
ports. These changes can then be checked against the con-
tents of the preferred_address parameter and domain reg-
istration records of the new IP addresses to verify their le-
gitimacy.
• Another approach is full decryption of QUIC traffic on a
firewall level. Although not recommended for privacy rea-
sons, as it defeats the purpose of the QUIC protocol, it al-
lows for in-depth HTTP/3 inspection. Even in such a case,
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
firewall vendors would still need to implement the afore-
mentioned custom detection mechanisms to verify that the
preferred_address address field contains a legitimate ad-
dress.
8
Related Work
8.1
QUIC Request Forgery Attacks
QUIC traffic is inherently difficult to differentiate from “normal”
UDP traffic. The encryption of QUIC headers and payloads obfus-
cates the traffic, which prevents easy inspection and classification.
Even advanced network sniffing tools such as Wireshark cannot
reliably detect QUIC if the handshake phase has not been observed.
In addition to obfuscation challenges, there are various attacks
targeting the QUIC protocol, for instance, request forgery attacks.
RFC 9000 [19] describes different types of request forgery attacks,
including “Request Forgery with Client Initial Packets”, “Request
Forgery with Preferred Addresses”, “Request Forgery with Spoofed
Migration”, and “Request Forgery with Version Negotiation”. Al-
though [19] mentions a request forgery attack on the DCID field
in packets sent to a preferred address, it fails to point out that a
packet’s destination IP may be spoofed to redirect traffic to a ma-
licious IP address. The RFC suggests no specific countermeasures
beyond generic security recommendations.
Gbur and Tschorsch [12] performed an analysis of the feasibil-
ity of client-side request forgery attacks. They focused on client-
side Server Initial Request Forgery (SIRF), Version Negotiation Re-
quest Forgery (VNRF), and Connection Migration Request Forgery
(CMRF). Their CMRF analysis only encompassed forging client-side
connection migration events, which aim to trick a legitimate QUIC
server into sending a QUIC packet to a spoofed address. It did not
cover the forging of server-side connection migration events.
One example of spoofing connection migration events with
benevolent intent is MIMIQ [15], a privacy-enhancing system that
aims to prevent traffic analysis by a middlebox. The system allows
clients to maintain anonymity by frequently rotating their source
IP address without disrupting connections. It prevents adversaries
from identifying the client or associating multiple flows with it.
Connections are broken into smaller flows and migration times are
strategically chosen, making it harder for adversaries to analyze
traffic and gather information about a particular client.
8.2
Data Exfiltration
The field of data exfiltration is vast, encompassing various attack
vectors such as exfiltration over web services, physical media, net-
work media, and alternative [network] protocols [31]. We therefore
limited the review to papers that developed attacks related to the
MITRE ATT&CK framework technique “Exfiltration over Alterna-
tive Protocol” [31], which includes all network protocols not being
used as the main C2 channel.
There have been efforts in QUIC-based data exfiltration, such as
the prototype presented in [48], which embeds data within a legiti-
mate QUIC connection. However, this approach does not attempt
to hide the exfiltration, leaves a noticeable fingerprint due to the
handshake, and does not adjust packet features like payload length.
Sudhan and Kulkarni [43] introduced a method to establish a
covert channel between two QUIC endpoints using the latency spin
bit. The spin bit is an optional QUIC protocol feature that allows for
passive on-path network latency monitoring. The proposed method
requires two QUIC endpoints to establish a legitimate connection,
making it less feasible for malicious data exfiltration attempts. Fur-
thermore, only one bit of data can be exchanged per QUIC packet,
which makes the method impractical for exfiltrating large amounts
of data.
Zhan et al. [49] proposed a method to detect DNS-over-HTTPS
(DoH) based data exfiltration by analyzing TLS-fingerprints and
training Boosted Decision Trees, Random Forest, and Logistic Re-
gression classifiers on flow-based features, achieving detection ac-
curacies of over 99%.
Vaccari et al. [44] exploit the Message Queue Telemetry Trans-
port (MQTT) protocol, commonly used within IoT networks, to
exfiltrate sensitive data from a private network. Their method suc-
cessfully exfiltrated payloads up to 3000 bytes over the MQTT
protocol, and simultaneously, they were able to achieve detection
accuracies of up to 99% using Random Forest classifiers.
Klein [21] introduced a data exfiltration method that exploits
stateful IPv4 IDs, TCP ISNs and IPv6 flow labels on popular server
operating systems. The study demonstrated the feasibility of ex-
filtrating data from firewalled networks using the global protocol
states to establish covert channels. In addition, it explored cross-
protocol attacks and measured exfiltration bandwidth, which was
sufficiently high to extract secret key material within a few hours.
9
Conclusion
This paper analyzes the feasibility of covert data exfiltration attacks
using the QUIC transport protocol. We find that adversaries can
make use of QUIC’s server-side connection migration feature to
exfiltrate data from a trusted network to a target server. We show
that, because of the inherent traits of the QUIC protocol, QUIC-
based data exfiltration techniques are difficult to differentiate from
normal protocol behaviour, and not even custom anomaly detection
classifiers are able to detect such data exfiltration attempts. Some
mitigation strategies include outright disabling server-side connec-
tion migration, sending the preferred_address parameter as part
of the unencrypted handshake, or implementing custom firewall
software that checks the preferred_address parameter against
domain registration entries. From the lack of QUIC traffic analysis
capabilities offered by leading firewall vendors, one can infer that,
as of today, firewalls cannot effectively handle the complexities of
QUIC. Our contribution lies not in demonstrating the success of
ML-based detection, but rather in revealing the limitations of cur-
rent ML methods against advanced mimicking attacks. Future work
may include developing heuristics-based QUIC traffic inspectors
that can be deployed on middleboxes.
Acknowledgments
This work was partially supported by (a) the University of Zürich
UZH, Switzerland, and (b) the Horizon Europe Framework Pro-
gram’s project Certify, Grant Agreement No. 101069471, funded by
the Swiss State Secretariat for Education, Research, and Innovation
SERI, under Contract No. 22.00165.
QUIC-Exfil: Exploiting QUIC’s Server Preferred Address Feature to Perform Data Exfiltration Attacks
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
References
[1] accetto. 2024. Headless Ubuntu/Xfce container with VNC/noVNC and Firefox (G2).
https://hub.docker.com/r/accetto/xubuntu-vnc-novnc-firefox
[2] Alibaba. 2024. xquic. https://github.com/alibaba/xquic
[3] David Belson and Lucas Pardue. 2023. Examining HTTP/3 usage one year on.
https://blog.cloudflare.com/http3-usage-one-year-on
[4] M. Bishop. 2022. HTTP/3. RFC 9114. IETF. https://www.ietf.org/rfc/rfc9114.txt
[5] Aurélien Buchet and Cristel Pelsser. 2024. An Analysis of QUIC Connection
Migration in the Wild. arXiv preprint arXiv:2410.06066 (2024).
[6] Cisco. 2023. Encrypted Visibility Engine: An overview of Cisco Secure Firewall’s
Encrypted Visibility Engine (EVE). https://secure.cisco.com/secure-firewall/v7.3/
docs/encrypted-visibility-engine-73
[7] Cloudflare. 2024. quiche.
https://github.com/cloudflare/quiche/blob/master/
quiche/src/lib.rs
[8] devsisters. 2024. libquic. https://github.com/devsisters/libquic
[9] ebfull and Kozlowski, Wojciech. 2024. pcap: A packet capture API around pcap/w-
pcap. https://crates.io/crates/pcap
[10] Gartner. 2024. Network Firewalls Reviews and Ratings. https://www.gartner.com/
reviews/market/network-firewalls
[11] Konrad Yuri Gbur and Florian Tschorsch. 2021. A quic (k) way through your
firewall? arXiv preprint arXiv:2107.05939 (2021).
[12] Konrad Yuri Gbur and Florian Tschorsch. 2023. QUICforge: Client-side Request
Forgery in QUIC. In Network and Distributed System Security (NDSS) Symposium.
[13] I. Goldberg, T. Wang, and C.A. Wood. 2020. Network-Based Website Fingerprint-
ing. Technical Report. pearg. https://www.ietf.org/archive/id/draft-irtf-pearg-
website-fingerprinting-00.html
[14] Google. 2024. Google quiche. https://github.com/google/quiche
[15] Yashodhar Govil, Liang Wang, and Jennifer Rexford. 2020. {MIMIQ}: Masking
{IPs} with Migration in {QUIC}. In 10th USENIX Workshop on Free and Open
Communications on the Internet (FOCI 20).
[16] HAProxy. 2024. haproxy. https://www.haproxy.org/
[17] Christian Huitema, Sara Dickinson, and Allison Mankin. 2024. . RFC 9250. IETF.
https://www.rfc-editor.org/rfc/rfc9250.txt
[18] IBM. 2024. Cost of a Data Breach Report 2024. https://www.ibm.com/reports/data-
breach
[19] Jana Iyengar and Martin Thomson. 2021. QUIC: A UDP-Based Multiplexed and
Secure Transport. RFC 9000. IETF. https://www.ietf.org/rfc/rfc9000.txt
[20] Karimi, Adel. 2019. FATT: fingerprint all the things! https://github.com/0x4D31/
fatt
[21] Amit Klein. 2022. Subverting Stateful Firewalls with Protocol States. In Network
and Distributed System Security (NDSS) Symposium.
[22] M. Kühlewind and B. Trammell. 2022. Manageability of the QUIC Transport
Protocol. RFC 9312. IETF. https://www.ietf.org/rfc/rfc9312.txt
[23] Lainé, Jeremy . 2024. aioquic. https://github.com/aiortc/aioquic
[24] Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles Krasic,
Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar, et al. 2017.
The quic transport protocol: Design and internet-scale deployment. In Proceedings
of the conference of the ACM special interest group on data communication. 183–
196.
[25] Yanmei Liu, Yunfei Ma, Quentin De Coninck, Olivier Bonaventure, Christian
Huitema, and Mirja Kühlewind. 2024. Multipath Extension for QUIC. Work in
Progress. IETF. https://datatracker.ietf.org/doc/draft-ietf-quic-multipath/
[26] Tan Lizhuang, Gao Xiaochuan, Su Wei, Li Na, and Zhang Wei. 2020. Connection
Migration in QUIC. Work in Progress. IETF.
https://datatracker.ietf.org/doc/
html/draft-tan-quic-connection-migration-00
[27] Chaoyi Lu, Baojun Liu, Yiming Zhang, Zhou Li, Fenglu Zhang, Haixin Duan, Ying
Liu, Joann Qiongna Chen, Jinjin Liang, Zaifeng Zhang, et al. 2021. From WHOIS
to WHOWAS: A Large-Scale Measurement Study of Domain Registration Privacy
under the GDPR. In Network and Distributed System Security (NDSS) Symposium.
[28] Scott M Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model
Predictions. In Advances in Neural Information Processing Systems 30, I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
(Eds.). Curran Associates, Inc., 4765–4774. http://papers.nips.cc/paper/7062-a-
unified-approach-to-interpreting-model-predictions.pdf
[29] Beatrice Martini and Niels ten Oever. 2019. QUIC Human Rights Review. Technical
Report. HRPC Human Rights Review Team. https://datatracker.ietf.org/meeting/
102/materials/slides-102-hrpc-slides-hrreveiw-quic-00
[30] McGrew, David and Enright, Brandon and Anderson, Blake and Messenger,
Lucas and Weller, Adam and Chi, Andrew and Acharya, Shekhar and Antonyk,
Anastasiia-Mariia and Stepanov, Oleksandr and Viswanathan, Vigneshwari and
Raj, Apoorv. 2020. Cisco Mercury: network metadata capture and analysis. https:
//github.com/cisco/mercury
[31] MITRE. 2024. MITRE ATT&CK Framework. Exfiltration Over Alternative Proto-
col. https://attack.mitre.org/techniques/T1048/
[32] Maxime Piraux and Olivier Bonaventure. 2024. Additional addresses for QUIC.
Work in Progress. IETF.
https://datatracker.ietf.org/doc/draft-piraux-quic-
additional-addresses/
[33] T. Pornin. 2021. Version-Independent Properties of QUIC. RFC 8999. IETF. https:
//www.ietf.org/rfc/rfc8999.txt
[34] private-octopus. 2024. picoquic. https://github.com/private-octopus/picoquic
[35] Carlo Puliafito, Luca Conforti, Antonio Virdis, and Enzo Mingozzi. 2022. Server-
side QUIC connection migration to support microservice deployment at the edge.
Pervasive and mobile computing 83 (2022), 101580.
[36] Puliafito, Carlo and Conforti, Luca and Virdis, Antonio and Mingozzi, Enzo. 2022.
Server-side QUIC connection migration to support microservice deployment at the
edge. https://github.com/kruviser/aioquic-explicit_UniPisa
[37] quic-go. 2024. quic-ggo. https://github.com/quic-go/quic-go
[38] quinn-rs. 2024. quinn. https://github.com/quinn-rs/quinn
[39] Jim Roskind. 2012. Quick UDP internet connections: Multiplexed stream transport
over UDP. https://www.ietf.org/proceedings/88/slides/slides-88-tsvarea-10.pdf
[40] Schmid, Julian. 2024. etherparse. https://crates.io/crates/etherparse
[41] Cherie Shi. 2019.
QUIC Connection Migration.
Technical Report.
IETF.
https://datatracker.ietf.org/doc/slides-104-maprg-quic-connection-
migration-cherie-shi/
[42] Randall R. Stewart, Michael Tüxen, and karen Nielsen. 2022. Stream Control
Transmission Protocol. RFC 9260. https://doi.org/10.17487/RFC9260
[43] H. H. Sudhan S. and Sameer G. Kulkarni. 2024. Security and Service Vulnerabilities
with HTTP/3. In 2024 16th International Conference on COMmunication Systems
& NETworkS (COMSNETS). IEEE, 55–60.
[44] Ivan Vaccari, Sara Narteni, Maurizio Aiello, Maurizio Mongelli, and Enrico Cam-
biaso. 2021. Exploiting Internet of Things protocols for malicious data exfiltration
activities. IEEE Access 9 (2021), 104261–104280.
[45] Mona Wang, Anunay Kulshrestha, Liang Wang, and Prateek Mittal. 2022. Lever-
aging strategic connection migration-powered traffic splitting for privacy. arXiv
preprint arXiv:2205.03326 (2022).
[46] Wireshark Foundation. 2024. Wireshark. https://www.wireshark.org
[47] Yamamoto, Kazu. 2024. IETF QUIC implementation in Haskell. https://hackage.
haskell.org/package/quic
[48] ytisf. 2024. PyExfil: Stress Testing Detection & Creativity. https://github.com/
ytisf/PyExfil/blob/master/USAGE.md
[49] Mengqi Zhan, Yang Li, Guangxi Yu, Bo Li, and Weiping Wang. 2022. Detecting
DNS over HTTPS based data exfiltration. Computer Networks 209 (2022), 108919.
All links above were last accessed on May 9, 2025.
A
Evaluation of Open-Source Implementations
Since the proposed attack relies on client-initiated server-side migrations, it
is vital to understand the actual adoption of this feature. Thus, this section
reviews several open-source client- and server-side implementations of the
QUIC protocol. Each solution (cf. Table 6) is statically analyzed to infer
whether it supports server-side connection migrations and/or Multipath
QUIC [25]. Furthermore, since libraries differ in terms of maturity and
adoption, a non-exhaustive set of dependents of each library (i.e., other
libraries, clients, or applications) is enumerated.
Currently, 8 out of the 11 reviewed libraries implement the feature,
whereas the remaining 3 only implement client-side connection migrations.
For example, quic-go is a widely-used library that does not actively support
server-side connection migration. aioquic parses the preferred_address
field, but does not support active migration. Similarly, Cloudflare quiche does
not support server-side connection migration. However, from the source
code, it can be inferred that it is planned to implement the feature. On the
other hand, several libraries already allow active server-side connection mi-
grations and/or QUIC Multipath connections. For example, picoquic, libquic,
quinn, aioquic_pisa, Google quiche, haproxy, Haskell quic, and Alibaba’s xquic
support the feature. These implementations are used by several operating
systems and user-space applications, including the Google Chrome browser.
Thus, based on these observations, it can be argued that server-side
connection migration is not a hypothetical feature of QUIC but instead
a relevant feature of the protocol. Therefore, the previously mentioned
attack is exploiting a well-established feature for several implementations.
However, it must be mentioned that there is no empirical evidence of the
feature’s prevalence in network traffic.
ASIA CCS ’25, August 25–29, 2025, Hanoi, Vietnam
Grübl et al.
Table 6: Overview of Statically Analyzed Implementations
Implementation
Implemented
Notable Dependents
quic-go [37]
✗
cloudflared, caddy, syncthing
libquic [8]
✓
goquic, chromium
Cloudflare quiche [7]
✗*
Cloudflare, NGINX
picoquic [34]
✓
Picotls, RIOT OS
quinn [38]
✓
h3-quinn, nestri, EasyTier
aioquic [23]
✗
airbyte, mitmproxy, envoy
aioquic_pisa [36]
✓
–
Google quiche [14]
✓
Google, Chromium
haproxy [16]
✓
Instagram, Airbnb, pfSense
Haskell quic [47]
✓
hprox, warp-quic, http3
Alibaba xquic [2]
✓
Taobao Mobile
∗Implementation of Server-Side Migration Planned
B
Wireshark Filters
The following Wireshark filters were used to extract the datasets for train-
ing the anomaly detectors:
1) Matching all outgoing QUIC Protected Payload packets in the testbed:
1
ip.src == 172.19.0.0/16 && quic && quic.
header_form == "short header" && quic.
header_form != "long header" && quic.dcid !=
""
Listing 1: Wireshark Filter Example 1
2) Matching all outgoing QUIC Protected Payload packets as well as all
benign connection migration attempts (triggered using Cloudflare quiche):
1
ip.src == 172.19.0.X && ((quic && quic.header_form
== "short header" && quic.header_form != "
long header" && quic.dcid != "") || (udp &&
udp.length == 1358))
Listing 2: Wireshark Filter Example 2
C
Additional Considerations
C.1
Potential Drawbacks of Establishing New
QUIC Connections
One of the primary challenges in executing a covert data exfiltration attack
using the QUIC protocol arises from the transparency during the connection
establishment phase. Middleboxes and fingerprinting tools typically filter
connections based on the initial handshake packets. This initial packet
exchange, which includes the “Initial” QUIC packet or potentially the “0-
RTT” packet, serves as a clear indicator of new connection establishment.
These packets contain cleartext details, such as the TLS Client Hello and
TLS Server Hello messages, that can expose a certain fingerprint. Given the
amount of metadata within the handshake packets, any attempts to establish
a new connection to exfiltrate data would likely increase the visibility of the
attack. In particular, fingerprinting tools (cf. Section 6.3) filter exclusively
based on handshakes and therefore increase the risk of the attack being
identified and blocked at an early stage.
C.2
Comparison with TLS and DNS-based Data
Exfiltration
Defense systems specifically look for TLS Client Hello or TCP SYN packets
to identify connection establishments. TCP-based connections typically
require a new handshake to establish a valid connection when an underlying
IP address changes. Similarly to QUIC, which allows connection migrations
that change the underlying IP address without requiring a new handshake,
there are further exceptions, such as the Stream Control Transmission
Protocol (SCTP) [42], which can reconfigure IP addresses mid-connection
using the Set Primary instruction. However, SCTP packets in non-telecom
networks are not as prevalent as QUIC traffic, and, as a result, QUIC-based
data exfiltration that mimics legitimate connection migrations potentially
poses a greater security concern.
DNS-based data exfiltration may raise suspicion when multiple stan-
dalone DNS queries are produced, and not followed by a TCP and/or
TLS handshake after an IP address has been resolved. This makes high-
throughput DNS-based data exfiltration practically impossible without at-
tracting attention. QUIC, since it inherently anticipates changes in the
underlying IP header, may make data exfiltration appear less anomalous
compared to other types of data exfiltration. Additionally, due to the high
adoption of the QUIC protocol in popular web services [3], a QUIC-based
data exfiltration attack may achieve high throughput without raising suspi-
cion.
C.3
Additional Insights from Leading Firewall
Vendors
Firewall Vendor C mentioned that most requests regarding the QUIC proto-
col are coming from researchers, with only very little coming from industry.
This indicates a divergence between academic interest in the protocol’s
potential and the industry’s current level of adoption or need for it. Firewall
Vendor D argues that the small performance gain through a reduced RTT
does not justify the manageability challenges and potential security risks
it entails. The vendors also correctly point out that tracking QUIC con-
nections via a CID state table is not feasible, since the privacy-preserving
mechanisms in QUIC may change CIDs at any time to prevent middleboxes
from uniquely identifying a connection. A set of usable CIDs is negotiated
as part of the encrypted QUIC handshake, and thus remains hidden from
middleboxes.


Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite
Attacks
Yixin Cheng 1 2 Hongcheng Guo 3 Yangming Li 4 Leonid Sigal 1 2
Abstract
Text watermarking aims to subtly embeds statis-
tical signals into text by controlling the Large
Language Model (LLM)’s sampling process, en-
abling watermark detectors to verify that the out-
put was generated by the specified model. The
robustness of these watermarking algorithms has
become a key factor in evaluating their effective-
ness. Current text watermarking algorithms em-
bed watermarks in high-entropy tokens to ensure
text quality. In this paper, we reveal that this
seemingly benign design can be exploited by at-
tackers, posing a significant risk to the robustness
of the watermark. We introduce a generic effi-
cient paraphrasing attack, the Self-Information
Rewrite Attack (SIRA), which leverages the vul-
nerability by calculating the self-information of
each token to identify potential pattern tokens
and perform targeted attack. Our work exposes
a widely prevalent vulnerability in current wa-
termarking algorithms. The experimental results
show SIRA achieves nearly 100% attack success
rates on seven recent watermarking methods with
only $0.88 per million tokens cost. Our approach
does not require any access to the watermark al-
gorithms or the watermarked LLM and can seam-
lessly transfer to any LLM as the attack model
even mobile-level models. Our findings highlight
the urgent need for more robust watermarking.
1. Introduction
Large language models (LLMs), exemplified by Chat-
GPT (OpenAI, 2024) and Claude (Anthropic, 2024), have
demonstrated remarkable capabilities in generating coher-
ent, human-like text. However, while these advances sig-
1University of British Columbia 2Vector Institute for AI 3Fudan
University 4University of Cambridge. Correspondence to: Leonid
Sigal <lsigal@cs.ubc.ca>.
Proceedings of the 41 st International Conference on Machine
Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).
nificantly expand AI’s potential in content creation, they
have concurrently heightened concerns regarding their mis-
use (Deshpande et al., 2023; Wang et al., 2024), including
the spread of misinformation (Monteith et al., 2024) and
threats to academic integrity (Stokel-Walker, 2022).
To mitigate risks associated with LLM-generated content,
text watermarking has emerged as a promising counter-
measure (Kirchenbauer et al., 2023; Aaronson & Kirchner,
2022). This technique subtly alters the LLM’s generation
process to embed imperceptible patterns in the output text,
the pattern is invisible to human readers and can be reliably
detected using specialized algorithms. This generate-detect
framework enables the differentiation between AI-generated
and human-authored content and allows tracking of the text
back to the specific LLM that generates the text (Li et al.,
2024). Consequently, this mechanism promotes account-
ability and helps mitigate LLM misuse, providing a reliable
means to ensure transparency and integrity in AI-generated
content.
Recent studies have demonstrated that watermarking tech-
niques exhibit significant robustness against simple manip-
ulations, including word deletions (Welbl et al., 2020) and
emoji attacks (Kirchenbauer et al., 2023). However, tra-
ditional NLP attack strategies, such as word deletion and
insertion, are increasingly insufficient for thoroughly evalu-
ating the robustness of advanced watermarking algorithms.
As LLMs continue to advance, there is a growing need for
more sophisticated testing methodologies that account for
complex manipulation tactics, ensuring that watermarking
techniques remain resilient against emerging threats.
To provide a more rigorous evaluation of watermarking ro-
bustness, paraphrasing attacks have been proposed. Despite
their potential, these approaches face several limitations.
First, current paraphrasing attacks rely on a naive and brute-
force approach, where they simply instruct LLMs to rewrite
watermarked text. This process is both inefficient and incon-
sistent in its results. The modifications to text are untargeted
and random, dictated by the LLM, often leaving portions of
the watermark intact causing the attack to fail. For newer
and more robust watermarking algorithms like SIR (Liu
et al., 2024), these methods already fail to deliver effective
attacks, making them unsuitable as robustness evaluation
1
arXiv:2505.05190v1  [cs.LG]  8 May 2025
Submission and Formatting Instructions for ICML 2025
methods for future research. Moreover, changing the words
that do not embed the watermark may cause a change in
semantics, or lead to decline in text quality. Second, cur-
rent methods require significant hardware resources and
costs, as they often rely on large-scale LLMs to achieve no-
table attack performance which could be a barrier for future
study. Thirdly, they are non-transferable, as the reliance on
specifically fine-tuned LLM (Krishna et al., 2024) prevents
them from effectively leveraging the capabilities of more
powerful, rapidly emerging language models for attacks.
To address these challenges, we propose a new paraphrasing
attack named SIRA (Self-Information Rewrite Attack). Our
approach not only introduces a more effective paraphras-
ing strategy but also reveals a fundamental vulnerability in
current watermark algorithms. Specifically, watermarking
techniques aim to be imperceptible to users while maintain-
ing text quality and semantics intact, which necessitates
embedding patterns in high-entropy tokens (Kirchenbauer
et al., 2023; Liu et al., 2023). These high-entropy tokens
also exhibit high self-information within the given text con-
text. Leveraging this otherwise harmless watermark feature,
SIRA could identify potential “green list” token candidates
within watermarked text without any prior knowledge. By
masking potential green tokens, we can transform the un-
targeted paraphrasing into a targeted fill-in-the-blank task,
achieving a stronger and more efficient attack.
In summary, we make the following contributions:
- We formalize and thoroughly investigate the threat
model of LLM watermark black-box paraphrasing, dis-
tinguishing it from other watermark attacks that rely
on probing-based modeling or online attack methods.
- We reveal a widely existing vulnerability in watermark
algorithms and propose the first, to our knowledge,
targeted paraphrasing attack. This attack is easy to
implement and transferable, making it well-suited for
future robustness evaluations.
- We comprehensively study paraphrasing attacks on re-
cent watermark algorithms. For newly proposed water-
marking algorithms, we show that existing paraphras-
ing attacks are no longer sufficient to verify robustness.
2. Related Work
Self-information. Self-information, also known as sur-
prisal, is a fundamental concept in Information Theory, first
introduced by Claude Shannon in his seminal work (Shan-
non, 1948). Shannon employed self-information as the prin-
cipal metric to quantify the information content associated
with the occurrence of specific events, effectively linking
the rarity of an event to the amount of information it com-
municates.
In the realm of Natural Language Processing (NLP), self-
information plays a crucial role in the analysis and modeling
of language. It aids in deciphering language patterns, partic-
ularly in evaluating the entropy and predictability of tokens
within sequences. The concept is particularly useful for
quantifying the informativeness or surprise of a token in a
given linguistic context. Language models predict the prob-
ability of a subsequent token in a sequence using the preced-
ing context P(tk | t1, t2, . . . , tk−1). The self-information
of the token in this context is computed as follows:
I(tk | t1, t2, . . . , tk−1) = −logb(P(tk | t1, t2, . . . , tk−1))
where I(tk | t1, t2, . . . , tk−1) denotes the self-information
of token tk given the context of previous tokens, P(tk |
t1, t2, . . . , tk−1) is the probability of token tk occurring
after the preceding sequence of tokens, and b represents the
base of the logarithm.
LLM Watermark. Watermarking techniques for large lan-
guage models are designed to embed identifiable patterns in
model outputs, allowing for the traceability of generated text
back to its originating source. These watermarks serve as an
essential tool for ensuring accountability and ownership, par-
ticularly in scenarios where identifying the specific model or
version that produced the content is crucial. LLM watermark
methods can be broadly classified into two primary cate-
gories: the KGW Family and the Christ Family. Each family
employs distinct mechanisms that are integral to the internal
workings of LLMs. The KGW Family (Kirchenbauer et al.,
2023; Liu et al., 2023; Zhao et al., 2023; Wu et al., 2024;
Lu et al., 2024) focuses on modifying the logits—the raw
output probabilities produced by the model—before they
are transformed into text. This approach involves selec-
tively adding bias to certain tokens, referred to as “green
list” tokens, which influences the model to favor these to-
kens, thus embedding a statistical signature in the output.
Post text generation, a statistical metric based on the propor-
tion of these “green” tokens is computed. A predetermined
threshold enables differentiation between watermarked and
non-watermarked text.
Conversely, the Christ Family (Aaronson & Kirchner, 2022;
Christ et al., 2024; Kuditipudi et al., 2023) modifies the
sampling process during the generation phase itself. Rather
than altering the logits, this family intervenes directly in the
token selection during decoding. Techniques such as top-
k sampling, temperature adjustment, or nucleus sampling
are adapted to ensure preferential selection of watermarked
tokens. This method provides more direct control over the
generation process, embedding watermarks that are resilient
against post-processing attacks, such as paraphrasing.
Watermark Removal Attacks. The robustness of a water-
marking algorithm is crucial, as it determines the effective-
2
Submission and Formatting Instructions for ICML 2025
ness of the watermark under various real-world conditions,
particularly in adversarial settings. Attacks against water-
mark algorithms, commonly referred to as watermark tam-
pering attacks, can be broadly categorized into two types:
Text manipulations: These attacks involve traditional NLP
techniques to straightforward text manipulations, such as
word deletion (Welbl et al., 2020), substitution (Yu et al.,
2010), or insertion (Kirchenbauer et al., 2023). By altering
the word-level structure of the text, these methods attempt
to distort or eliminate the watermark. These techniques
disrupt the statistical pattern of the watermark by adding,
removing, or replacing words. Kirchenbauer et al. (2023)
propose emoji attack and copy-paste attack which insert
emoji/human written text in the generated text to avoid de-
tection. These methods are considered variants of text ma-
nipulations, however, they are easily thwarted by detectors
equipped with content filters and often alter the semantics
of the generated text which makes them inappropriate for
real-world use.
Informed watermark attack: Such attacks rely on the ad-
versary having specific knowledge or access to the water-
marking system, such as the ability to probe the watermark
model. One typical attack is the watermark-stealing at-
tack (Jovanovi´c et al., 2024; Wu & Chandrasekaran, 2024).
These methods aim to reverse-engineer or approximate the
embedded watermark by probing watermark algorithms
with queries. Attackers construct the watermark distribu-
tion of the target model and estimate whether each token
complies with the watermark rules based on the context
by issuing a large number of pre-designed prefix queries.
However, these methods assume that the adversary has un-
limited access to the targeted watermarked LLM model.
Additionally, this method becomes ineffective when water-
marks employ dynamic strategies (e.g., using a set of hash
keys). Another notable recent attack is the random walk
attack (Zhang et al., 2023); this method iteratively perturbs
the watermarked text using multiple models, relying on the
detector’s feedback as the termination condition. While it
effectively removes watermarks, its iterative nature intro-
duces significant computational and time overhead. Another
major limitation of this approach is it does not guarantee
any semantic preservation.
The above methods share a strong assumption: the attacker
has access to the watermarked LLM, either with or with-
out the watermark detector. However, this assumption is
rarely met in real-world adversarial scenarios especially the
access to the watermark detector. The aforementioned meth-
ods also suffer from significant overhead, both in terms of
computational resource demands and execution time. As a
result, these methods are generally excluded from robust-
ness evaluations of watermarking algorithms Kirchenbauer
et al. (2023); Liu et al. (2024); Aaronson & Kirchner (2022);
Zhao et al. (2023). Due to the different threat models and
much stronger assumptions, we do not include them in this
paper.
Model-based paraphrasing: A more common and advance
form of attack involves using another LLM to paraphrase the
watermarked content. This method differs from watermark-
stealing attacks by operating in a strict black box setting,
where the attacker’s knowledge is limited to the water-
marked text. Krishna et al. (2024) propose DIPPER, a
paraphrase generation model developed by fine-tuning T5-
XXL (Raffel et al., 2020b) on an aligned paragraph dataset.
This model has been widely adopted in recent watermark
research (Zhao et al., 2023; Liu et al., 2024; Kuditipudi
et al., 2023) to evaluate the robustness of watermarking al-
gorithms. GPT Paraphraser is another model-based method,
which utilizes the GPT model as a paraphrase. Previous ap-
proaches in this category derive their effectiveness primarily
from two mechanisms: (1) paraphrased text especially new
generated portion dilutes the strength of the original wa-
termark by introducing new linguistic structures, and (2)
lexical variations introduced during paraphrasing could in-
cidentally alter a subset of green tokens. However, such
changes that are controlled by an LLM, thus occurring by
chance, leads to untargeted paraphrasing that is neither suffi-
cient nor effective. In contrast, SIRA is a targeted approach
that selectively replaces potential green tokens in the wa-
termarked text, creating a ”neutral” template for rewriting.
It transforms the paraphrasing task into a fill-in-the-blank
problem.
Our proposed SIRA falls under the category of model-based
paraphrasing attacks and offers several key advantages: (1)
High Attack Effectiveness: SIRA achieves near 100% suc-
cess rates across seven tested watermarking algorithms; (2)
Lightweight and Highly Transferable: Unlike DIPPER,
which depends on a specific fine-tuned model, SIRA oper-
ates effectively on mobile-level 3B models and can seam-
lessly adapt to future powerful model; (3) Minimal As-
sumptions: It requires no access to the watermarked LLM
or its detector, enabling robust performance in black-box sce-
narios; (4) Low Cost and Plug-and-Play: SIRA operates
with minimal computational overhead (costing only$0.88
per Million tokens). Unlike watermark stealing requiring
large samples of watermarked text to initial one piece text
attack, SIRA is ready to use out of the box. These advan-
tages position SIRA as a promising tool for evaluating the
robustness of LLM watermarking in future research.
3. Methods
In this section, we detail SIRA attack formulation and im-
plementation. First, we lay out the problem setting in Sec-
tion 3.1, then we develop the details of the method in Sec-
tion 3.2.
3
Submission and Formatting Instructions for ICML 2025
Nike Inc enjoyed big sales in gains in North
America and Europe last quarter and benefited
from fewer markdowns, helping the maker of
sports clothes and sneaker continue on its long-
term path to long-term profits and sales growth.
Nike Inc enjoyed _ _ _ gains_ _
_ _ _ _ _ _ benefited_ fewer_ _ _
_ _ _ _ sports clothes_  _ _
continue_ _ long_path _ _
long_ profits_ _ growth.
Nike has seen significant revenue growth in
North America and Europe, largely due to
reduced markdowns and a strong performance
in its core sports apparel and footwear
business. This success has enabled the
company to stay on track with its long-term
strategy of increasing profitability and sales.
Nike Inc. enjoyed significant revenue gains and
benefited from fewer markdowns, which helped
the sportswear and sneaker maker continue to
drive long-term profit and sales growth.
Reference Text
Masked Text
Watermarked Text
Mask according to 
self-infromation
paraphrase
LLama3
rewrite
Watermarked strength
Watermarked strength
Attack Text
Figure 1. SIRA pipeline consisting to two steps. First, the attack generates a masked text based on self-information. If the self-
information of a specific part above a pre-set threshold, that portion of the text is masked and replaced with a placeholder. Simultaneously,
a reference text is generated by asking the LLM to paraphrase. In the second step, the LLM is prompted to complete the masked text
while incorporating all the information from the reference text.
3.1. Problem setting
Definition 1 (Language generative model). A Language
generative model M : X →Y maps any input prompt
x ∈X to an output y ∈Y , where X the prompt space, Y
the output space. We denote Yh is human written text space,
Yu is the machine generated unwatermarked text, Yw is the
machine generated watermarked text.
Definition 2 (Watermark Algorithm): A watermark algo-
rithm consists of a watermarking function W, a secret key k,
and a detector D. The watermarking function W, parameter-
ized by the key k, denoted as Wk, modifies the output y to
embed a watermark, given an input prompt x ∈X resulting
in a watermarked output yw which M(x, Wk) →yw ∈Yw.
The detector D, using the same key k, can then verify
whether a given output ˆy ∈Y contains the embedded wa-
termark. The detector D operates as a binary classifier with
the following output behavior:
D(Wk, ˆy) =
(
1
if ˆy is detected as watermarked
0
otherwise
(1)
The detector D contains a parameter θ, where the θ is the
z-score threshold.
Definition 3 (Perturbation Function): The attacker has
a perturbation function P : Yw →Yp modifies the wa-
termarked output yw to produce a perturbed output yp =
P(yw). The function P aims to minimize the detection
success rate of the detector D on the perturbed output yp.
A function S(yw, yp) measures the semantic similarity be-
tween the original watermarked output yw and the perturbed
output yp = P(yw). The pre-set threshold ϵ ∈[0, 1] is a
parameter that quantifies the minimum required level of se-
mantic similarity between the original watermarked output
yw and the perturbed output yp = P(yw).
Assumption: We define the scenario as a black box ad-
versarial problem and we assume that the attacker should
not know the watermark algorithm W, the secret key
k and should not have access to the detector D. The
attacker does not have access to any information about the
feature distribution of the watermark algorithm or the model
architecture.
For watermark algorithm, the goal is to achieve a balance
between robustness and performance. The detector D is
formulated as an optimization problem with the objective of
minimizing classification errors. Specifically, the detector
aims to maximize its accuracy in distinguishing between
human-written text yh and watermarked text yw. The goal
of detector D can represente as:
max
θD
Eyh∼Yh [log (1 −DθD(Wk, yh))]
+ Eyw∼Yw [log (DθD(Wk, yw))]
(2)
For attacker, the perturbation function P is defined to mini-
mize the probability that the detector D successfully identi-
fies the watermark in the perturbed output yp, while ensuring
semantic preservation. The goal for P can represente as:
P ∗= arg min
P
E [D(Wk, P(yw))]
(3)
s.t.
S(yw, P(yw)) ≥ϵ
(4)
Note that D(Wk, P(yw)) is only used during the evaluation
phase. The attacker does not have access to the detector
during the training or generation stages.
4
Submission and Formatting Instructions for ICML 2025
3.2. Self-information rewrite attack
A primary challenge in watermark removal attacks is identi-
fying the “green token” defined by the watermarking algo-
rithm. Some methods, such as Random Walk (Zhang et al.,
2023), use grammatical group matching to explicitly replace
verbs. In contrast, approaches like DIPPER (Krishna et al.,
2024) and GPT Paraphraser (Liu et al., 2024) delegate the
task of rewriting and removing green token to large language
models through high-level instructions. However, methods
of this type lack transparency and control; relying on LLM
for consistency with original watermarked text.
Our attack is based on a common principle of watermark-
ing algorithms, as discussed in the KGW (Kirchenbauer
et al., 2023; Liu et al., 2023) work: since the watermark
must remain imperceptible to the user, high-entropy tokens
are ideal candidates for embedding. High-entropy tokens
exhibit a more uniform distribution of probabilities, this uni-
formity means that when logits are adjusted to increase the
likelihood of green tokens, it is easier to embed watermarks
effectively without significantly compromising the quality
of the output. Meanwhile this also implied high-entropy
token has lower probability thus higher self-information.
In our approach, we propose a straightforward and easily
implementable solution by leveraging self-information to
identify potential green-list tokens and subsequently rewrite
them. High-entropy tokens are typically associated with
high self-information due to their unpredictability and low
probability of occurrence. Meanwhile, small probability
changes caused by the watermark algorithm can reduce
self-information. By considering both the change in self-
information and high-entropy token inherent nature, we
classify tokens with high or moderate self-information as po-
tential green-list tokens and filter them out to obtain a more
neutral template for LLM rewriting. Empirically, our pre-
liminary experiments show that utilizing self-information,
rather than directly filtering based on high entropy, results in
higher attack success rates. We present a detailed discussion
in Appendix G.
Given a watermarked text y = {y0, y1, . . . , yn}, where yi
represents each token, we employ a base language model
Mattack; Mattack is distinct from the generative model M
used to produce the watermarked text. We use Mattack to
calculate the self-information for each token yt as follows:
I(yt) = −log P(yt|y0, y1, . . . , yt−1; Mattack),
where P(yt|y0, y1, . . . , yt−1; Mattack) denotes the proba-
bility of token yt given its preceding tokens in the sequence,
as estimated by the language model Mattack. To mask the
potential green list tokens, we set a threshold ϵ, and get the
overall paragraph threshold by percentile:
Algorithm 1 Pseudocode for Self-information rewrite attack
1: Input:
Watermarked
token
sequence
y
=
{y1, y2, . . . , yn},
language
model
Mattack,
self-
information percentile ϵ, instruction s
2: Output: Response token sequence yp without water-
mark.
3: y′ ←Mattack(y)
▷Paraphrase sequence y′ using
Mattack
4: I ←[ ]
5: for i = 1 to n do ▷Compute self-information for each
token in y
6:
I[i] ←−log P(yi | context)
7: end for
8: τϵ ←Percentile(I, ϵ)
▷Determine threshold from ϵ
percentile of I
9: for i = 1 to n do
10:
if I[i] > τϵ then
11:
yi ←∅
▷Mask token if above threshold
12:
end if
13: end for
14: yp ←Mattack(y′, y, s)
▷Generate de-watermarked
response yp using Mattack
15: return yp
τϵ ←Percentile(I, ϵ)
Any token with a self-information value I[i] > τϵ is consid-
ered to be a potential token and will be masked and replaced
with a placeholder. In our experiments, we discovered that
using placeholders outperformed directly masking specific
tokens. The placeholders serve as cues, maintaining the
text’s structure, indicating where tokens have been masked
which providing the LLM with hints about the original text’s
length and the likely number of words, allowing for more
high quality reconstructions.
However, the compression will still result in the loss of
watermark text information details. To address this, we
use the base LLM Mattack to rewrite the watermarked text,
creating a reference text. This rewritten text serves as a
reference to preserve semantic integrity during the second
step. The reason we do not use the original watermarked
text is that we find this leads LLM to take shortcuts: LLM
tend to directly take the content from the watermark text,
due to the high similarity between masked and watermark
text.
In the final attack phase, we provide the Mattack with the
masked text, reference text, and instructions for a fill-in-
the-blank task, guiding it to reconstruct the missing content
with greedy decoding strategy. We provide the instructions
we use in Appendix E. The pseduocode of our algorithm is
shown in Algorithm 1.
5
Submission and Formatting Instructions for ICML 2025
Table 1. Comparison of watermark algorithms under different attack methods. The best results are marked in bold and the second best
results are marked in underline. Our most lightweight method outperforms all previous paraphrasing attacks. SIRA-Large achieves 100%
or near 100% attack success rates on all seven tested watermarking algorithms under black-box settings.Due to differing threat models, we
can not conduct a fair comparison with informed watermark attack methods, thus these methods are excluded .
Comparison of Watermark Algorithms under Different Attack Methods
Attack
Watermark
KGW-1
Unigram
UPV
EWD
DIP
SIR
EXP
Word delete (Welbl et al., 2020)
22.4%
1.6%
6.6%
22.8%
57.4%
44.0%
9.4%
Synonym Substitution (Yu et al., 2010)
83.2%
17.4%
65.2%
76.2%
99.6%
82.0%
51.0%
GPT Paraphraser
100%
63.9%
71.9%
90.8%
99.8%
58.8%
72.2%
DIPPER-1 (Krishna et al., 2024)
82.4%
37.0%
58.6%
82.2%
99.6%
61.2%
73.6%
DIPPER-2 (Krishna et al., 2024)
95.8%
45.6%
61.8%
89.0%
99.8%
63.6%
82.2%
SIRA-Tiny(Ours)
96.4%
87.6%
84.4%
97.8%
99.8%
75.0%
90.6%
SIRA-Small(Ours)
100%
93.8%
93.0%
100%
99.8%
83.4%
93.4%
SIRA-Large(Ours)
100%
100%
99.6%
100%
100%
98.8%
99.8%
4. Experiments
4.1. Setup
Dataset and Prompts. Following prior watermarking re-
search (Kirchenbauer et al., 2023; Zhao et al., 2023; Liu
et al., 2024; Kuditipudi et al., 2023), we utilize the C4
dataset (Raffel et al., 2020a) for general-purpose text gener-
ation scenarios. We selected 500 random samples from the
test set to serve as prompts for generating the subsequent
230 tokens, using the original C4 texts as non-watermarked
examples.
Watermark generation algorithms and language model.
To conduct a comprehensive evaluation, we select seven
recent watermarking works: KGW (Kirchenbauer et al.,
2023), Unigram (Zhao et al., 2023), UPV (Liu et al., 2023),
EWD (Lu et al., 2024), DIP (Wu et al., 2024), SIR (Liu
et al., 2024), EXP (Aaronson & Kirchner, 2022) in the
assessment. The watermark hyperparameter settings shown
in Appendix A, and the detection settings adhere to the
default/recommendations (Pan et al., 2024) configurations
of the original works. Specifically, for KGW-k, k is the
number of preceding tokens to hash. A smaller k implies
stronger attack robustness yet simpler watermarking rules.
We use KGW-1 in our experiment. For language models, we
follow the previous work setting select (Kirchenbauer et al.,
2023; Liu et al., 2024; Zhao et al., 2023) Opt-1.3B (Zhang
et al., 2022) as the watermark text generation model. Our
SIRA Tiny,SIRA Small, and SIRA Large run on the Llama3
Instruct models (Dubey et al., 2023) with 3B, 8B, and 70B
parameters, respectively.
Baseline Methods. For our method, we use ϵ = 0.3 as thresh-
old. For the attack method, we use word deleteion (Welbl
et al., 2020), synonym substitution (Yu et al., 2010), Dip-
per (Krishna et al., 2024), and GPT Paraphaser (Liu et al.,
2024) to compare with our method. For GPT Paraphaser,
we use the GPT-4o-2024-05-13 (OpenAI, 2024) version.
For DIPPER-1 the lex diversity is 60 without order diver-
sity, and for DIPPER-2 we additionally increase the order
diversity by 40. The word deletion ratio is set to 0.3 and the
synonym substitution ratio is set to 0.5. The synonyms are
obtained from the WordNet synset (Miller, 1995).
Evaluation. We utilize the attack success rate as our primary
metric. The attack success rate is defined as the proportion
of generated attack texts for which the watermark detector
incorrectly classify the attack text as the unwatermarked
sample, compared to the total number of attack texts. To
mitigate the influence of detection thresholds, we follow
prior work (Liu et al., 2024; Zhao et al., 2023) adjust z-
threshold of detector until reaches target false positive rate
in Figure 2 . We used generated 500 attack texts as positive
samples and 500 human-written texts as negative samples.
We dynamically adjust the detector’s thresholds to establish
false positive rates at 1% and 10%, and we report the true
positive rates and F1-scores. Our method runs on NVIDIA
A100 GPUs(Tiny, Small run on a single GPU).
4.2. Experimental Results.
In Table 1, we present the attack success rates of various
watermark removal methods across different watermark-
ing algorithms. The results demonstrate that our approach
consistently outperforms all other methods for each wa-
termarking algorithm. Notably, the closest competitors to
our method are DIPPER (Krishna et al., 2024) and GPT
Paraphraser, which are model-based paraphrasing attacks.
Even Our most lightweight SIRA-Tiny method outper-
forms all previous approaches regarding attack success
rate in our experiments involving seven watermarking algo-
rithms on the C4 dataset (Raffel et al., 2020a). Our Large
6
Submission and Formatting Instructions for ICML 2025
method achieves nearly 100% attack success across all
seven tested watermarking algorithms.
To further demonstrate the effectiveness of our method and
avoid the impact of a fixed z-threshold on detector perfor-
mance, we follow previous work by setting the FPR to 1%
and 10%, and report the true positive rate of the detector
on adversarial texts based on the adjusted z-threshold cor-
responding to the FPR. Additionally, we report the best
F1 score that the watermark algorithm can achieve under
different attacks. The results are shown in Figure 2, and
the detailed numbers are provided in Appendix C. Lower
true positive at a given false positive rate indicate that the
watermark detector struggles more to differentiate between
adversarial texts and human-written texts. Our algorithm
achieves optimal attack performance in most cases; suggest-
ing a more effective attack.
4.3. Text quality analysis
To further demonstrate that our method does not adversely
affect text quality, we conduct additional evaluations of
the text generated by the model. We compare Perplex-
ity (PPL) of the text quality.
Furthermore, we use a
well-established metric sentence-level embedding similarity
(Sentence-BERT Score (s-BERT)) before and after the
attack to explore whether the attack alters the semantic con-
tent. We also conducted experiments in the Appendix F
using ChatGPT as a judge to measure overall semantic
similarity. The results, shown in Figure 3, indicate that
our method has a smaller impact on text quality compared
to other approaches.Our approach, similar to other model-
based methods, benefits from more powerful large language
models, achieving better performance in terms of the PPL
metric compared to the original watermarked text. Addi-
tionally, our method retains a greater degree of semantic
information. We show the detail numbers of two metrics in
Appendix D.
4.4. Ablation Experiment
In this section, we aim to further scrutinize the self-
information rewrite attack and emphasize the potential of
this attack. We utilize Opt-1.3b and a random sample of
50 prompts from the C4 dataset to generate watermarked
responses. Unless otherwise specified, we use Llama-3-
8b (SIRA-Small) as the base model for our attack. The
temperature for the base model is set to 0.7.
How does the self-information threshold affect final per-
formance? In this experiment, we use UPV as the water-
marking algorithm. We varied the value of ϵ from 0.25 to
0.70 in increments of 0.05 to test its impact on the success
rate of the attack using the UPV algorithm. The results are
shown in Table 2.
We observed that the attack success rate and sentence-bert is
directly influenced by the value of ϵ. For the UPV algorithm,
setting the threshold to 0.3 results in a highly effective attack.
A significant performance gap is observed when ϵ increases
from 0.60 to 0.65. Additionally, there is a tradeoff between
attack effectiveness and semantic preservation. When ϵ is
below 0.25, the generated attack text tends to lose more
detailed information from the original watermarked text.
Considering both performance and semantic preservation,
we recommend setting ϵ between 0.2 and 0.3. For less
robust algorithms, setting ϵ between 0.4 and 0.5 is sufficient
to achieve an attack success rate exceeding 90%. Setting ϵ
to 0.3 effectively removes the watermark while preserving
the original semantics.
Self-information mask versus Random mask and Itera-
tive Paraphrase(twice) In this experiment, we replace self-
information-based selective masking with a random mask-
ing strategy and Iterative Paraphrase(twice), while keeping
all other steps unchanged. We use the same masking ratios,
ranging from 0.4 to 0.8 in increments of 0.1, and compare
the resulting attack success rates. The Unigram watermark-
ing method is employed to generate the watermarked text.
The results are presented in Table 3. To ensure fair compar-
isons, the random masking strategy is executed five times,
and the final average attack success rate is reported.
The results indicate that, at any given mask ratio, the self-
information-based masking method significantly outper-
forms the random strategy. The random masking approach
also has a bottleneck, with limited improvement in attack
success rates beyond a ratio of 0.6. This is due to the ran-
dom mask not make sure all target green tokens are removed.
Also,This experiment ruled out the possibility that the attack
effectiveness is primarily caused by the double paraphrasing
process. For a single watermarked text with fixed mask
ratio, our method is deterministic, as the same tokens are
masked each time. In contrast, the random approach does
not provide this guarantee.
Does the success of the attack due to paraphrased refer-
ence text? We used the Unigram watermarking algorithm to
generate watermarked text. We set the detector’s z threshold
to 4 according to its default settings. For a given input, the
detector calculates its z-score, and if the score exceeds 4,
the text is classified as watermarked.
We measured the attack success rate for each of the follow-
ing stages: the reference text generated in the first step of
our algorithm, and the final attack text. Additionally, we cal-
culated the average z-score for each stage and reported the
z-score of human-written text as a reference. The result are
shown in Table 4. We observed that the attack success rate
for the reference text is lower than that of the final attack text.
Paraphrase strategies tend to preserve more n-grams from
the original text, which may still be detectable by the wa-
7
Submission and Formatting Instructions for ICML 2025
(a) True positive rate with FPR set to 1%.
(b) True positive rate with FPR set to 10%.
(c) Best F1-score achieved by watermark.
Figure 2. To mitigate the default z-threshold’s impact on the robustness of watermarking algorithms, we dynamically adjust the z-score
threshold until the watermark detector achieves specified false positive rates. The true positive rate (TPR↓) and the best F1 score are
shown. Lower TPR and F1 scores at a given false positive rate (FPR) indicate that the watermark detector struggles to distinguish attack
texts from human-written texts, suggesting a more effective attack. Detailed values for the figures are provided in Appendix C.
(a) Performance of PPL.
(b) Performance of s-BERT.
Figure 3. Performance comparison of watermark methods against various attack methods based on PPL (Perplexity↓) and s-BERT
(Sentence-BERT score↑). The word delete will significantly increase the PPL and lead to overflow. We marked the overflow data with
NaN in the Figure 3a. The synonym substitution will also increase the PPL. The paraphrased text has better text quality than the original
watermark text for our method and GPT Paraphraser. The detailed number are shown in Appendix D.
Table 2. Effect of self-information Threshold on the Attack Success Rate and Semantic Preservation of the UPV Algorithm
self-information threshold ϵ
0.25
0.30
0.35
0.40
0.45
0.5
0.55
0.60
0.65
0.70
Attack Success Rate
96%
94%
94%
88%
80%
76%
72%
70%
58%
32%
Sentence-BERT
0.68
0.77
0.78
0.78
0.79
0.79
0.82
0.81
0.83
0.86
Table 3. Comparison with Random Masking Strategy and Iterative
Paraphrase. Iterative Paraphrase is independent of the mask ratio.
For clearer comparison, we place its results under the 0.7 (default
mask ratio) column. Notice here the random mask performance
also benefits from other steps like rewriting in our framework. The
vanilla random mask has a similar attack success rate as word
deletion.
Mask Ratio
0.4
0.5
0.6
0.7
0.8
Iterative Paraphrase
-
-
-
56%
-
Random Mask
52%
66%
78%
80%
82%
Self-information Mask
80%
88%
92%
96%
100%
termark detection algorithm. In contrast, our attack reduces
the presence of such n-grams by utilizing self-information
filtering. Additionally, the z-score produced by our method
is closer to that of human-written text compared to simple
paraphrasing approaches.
5. Conclusion
In this paper, we present the Self-Information Rewrite At-
tack (SIRA), a lightweight and effective method for re-
moving watermarks from LLM-generated text by targeting
Table 4. Comparison of Attack Success Rate and Average z-score.
The reference text is generated by asking the base model to para-
phrase the watermarked response, while the attack text is generated
using our two-step approach.
Text
Attack Success Rate
Average z-score
Human-written Text
N/A
0.12
Reference Text
64%
3.75
Attack Text
94%
1.85
anomalous tokens. Empirical results show that SIRA outper-
forms existing methods in attack success rates across multi-
ple watermarking techniques while preserving text quality
and requiring minimal computational resources. By ex-
ploiting vulnerabilities in current watermarking algorithms,
SIRA highlights the need for more robust and adaptive wa-
termarking approaches in watermark embedding. We will
release our code to the community to facilitate further re-
search in developing responsible AI practices and advancing
the robustness of watermarking algorithms.
8
Submission and Formatting Instructions for ICML 2025
References
Aaronson, S. and Kirchner, H.
Watermarking gpt
outputs.
https://www.scottaaronson.com/
talks/watermark.ppt, 2022.
Anthropic.
Claude 3.5, 2024.
URL https://www.
anthropic.com/news/claude-3-family. Ac-
cessed: 2024-09-24.
Chao, P., Robey, A., Dobriban, E., Hassani, H., Pappas, G. J.,
and Wong, E. Jailbreaking black box large language mod-
els in twenty queries. arXiv preprint arXiv:2310.08419,
2023.
Christ, M., Gunn, S., and Zamir, O. Undetectable water-
marks for language models. In The Thirty Seventh Annual
Conference on Learning Theory, pp. 1125–1139. PMLR,
2024.
Deshpande, A., Murahari, V., Rajpurohit, T., Kalyan,
A., and Narasimhan, K. Toxicity in chatgpt: Analyz-
ing persona-assigned language models. arXiv preprint
arXiv:2304.05335, 2023.
Dubey, A., Jauhri, A., Pandey, A., et al. The llama 3 herd of
models. arXiv, arXiv:2407.21783, 2023. URL https:
//arxiv.org/abs/2407.21783.
Jovanovi´c, N., Staab, R., and Vechev, M.
Watermark
stealing in large language models.
arXiv preprint
arXiv:2402.19361, 2024.
Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I.,
and Goldstein, T. A watermark for large language models.
In International Conference on Machine Learning, pp.
17061–17084. PMLR, 2023.
Krishna, K., Song, Y., Karpinska, M., Wieting, J., and Iyyer,
M. Paraphrasing evades detectors of ai-generated text,
but retrieval is an effective defense. Advances in Neural
Information Processing Systems, 36, 2024.
Kuditipudi, R., Thickstun, J., Hashimoto, T., and Liang, P.
Robust distortion-free watermarks for language models.
TMLR, 2023.
Lau, G. K. R., Niu, X., Dao, H., Chen, J., Foo, C.-S., and
Low, B. K. H. Waterfall: Scalable framework for robust
text watermarking and provenance for llms. pp. 20432–
20466, 2024.
Li, S., Yao, L., Gao, J., Zhang, L., and Li, Y. Double-
i watermark: Protecting model copyright for llm fine-
tuning. arXiv preprint arXiv:2402.14883, 2024.
Liu, A., Pan, L., Hu, X., Li, S., Wen, L., King, I., and Philip,
S. Y. An unforgeable publicly verifiable watermark for
large language models.
In The Twelfth International
Conference on Learning Representations, 2023.
Liu, A., Pan, L., Hu, X., Meng, S., and Wen, L. A seman-
tic invariant robust watermark for large language mod-
els, 2024. URL https://arxiv.org/abs/2310.
06356.
Liu, Y. and Bu, Y. Adaptive text watermark for large lan-
guage models. arXiv preprint arXiv:2401.13927, 2024.
Lu, Y., Liu, A., Yu, D., Li, J., and King, I. An entropy-
based text watermarking detection method. arXiv preprint
arXiv:2403.13485, 2024.
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and
Vladu, A. Towards deep learning models resistant to
adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Miller, G. A. Wordnet: a lexical database for english. Com-
munications of the ACM, 38(11):39–41, 1995.
Monteith, S., Glenn, T., Geddes, J. R., Whybrow, P. C.,
Achtyes, E., and Bauer, M. Artificial intelligence and
increasing misinformation. The British Journal of Psy-
chiatry, 224(2):33–35, 2024.
OpenAI. Chatgpt-4o: Multimodal and multilingual capabil-
ities. OpenAI website, 2024. https://openai.com/chatgpt-
4o.
Pan, L., Liu, A., He, Z., Gao, Z., Zhao, X., Lu, Y., Zhou, B.,
Liu, S., Hu, X., Wen, L., et al.
Markllm: An open-
source toolkit for llm watermarking.
arXiv preprint
arXiv:2405.10051, 2024.
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S.,
Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring
the limits of transfer learning with a unified text-to-text
transformer. Journal of machine learning research, 21
(140):1–67, 2020a.
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S.,
Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring
the limits of transfer learning with a unified text-to-text
transformer. Journal of machine learning research, 21
(140):1–67, 2020b.
Reimers, N. and Gurevych, I. Sentence-bert: Sentence
embeddings using siamese bert-networks. In Proceed-
ings of the 2019 Conference on Empirical Methods in
Natural Language Processing, pp. 3982–3992, Hong
Kong, China, November 2019. Association for Compu-
tational Linguistics. doi: 10.18653/v1/D19-1410. URL
https://aclanthology.org/D19-1410.
Sadasivan, V. S., Kumar, A., Balasubramanian, S., Wang,
W., and Feizi, S. Can ai-generated text be reliably de-
tected? arXiv preprint arXiv:2303.11156, 2023.
9
Submission and Formatting Instructions for ICML 2025
Shannon, C. E. A mathematical theory of communication.
The Bell system technical journal, 27(3):379–423, 1948.
Stokel-Walker, C. Ai bot chatgpt writes smart essays-should
academics worry? Nature, 2022.
Wang, X., Chen, T., Yang, X., Zhang, Q., Zhao, X., and
Lin, D. Unveiling the misuse potential of base large
language models via in-context learning. arXiv preprint
arXiv:2404.10552, 2024.
Wei, A., Haghtalab, N., and Steinhardt, J. Jailbroken: How
does llm safety training fail?
In Advances in neural
information processing systems (NeurIPS), 2023.
Welbl, J., Huang, P.-S., Stanforth, R., Gowal, S., Dvijotham,
K. D., Szummer, M., and Kohli, P. Towards verified
robustness under text deletion interventions. In Interna-
tional Conference on Learning Representations, 2020.
Wu, Q. and Chandrasekaran, V.
Bypassing llm water-
marks with color-aware substitutions.
arXiv preprint
arXiv:2403.14719, 2024.
Wu, Y., Hu, Z., Guo, J., Zhang, H., and Huang, H. A
resilient and accessible distribution-preserving watermark
for large language models. 2024.
Yu, L.-C., Shih, H.-M., Lai, Y.-L., Yeh, J.-F., and Wu, C.-
H. Discriminative training for near-synonym substitution.
In Proceedings of the 23rd International Conference on
Computational Linguistics (Coling 2010), pp. 1254–1262,
2010.
Zhang, H., Edelman, B. L., Francati, D., Venturi, D., Ate-
niese, G., and Barak, B. Watermarks in the sand: Im-
possibility of strong watermarking for generative models.
arXiv preprint arXiv:2311.04378, 2023.
Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,
Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V.,
et al. Opt: Open pre-trained transformer language models.
arXiv preprint arXiv:2205.01068, 2022.
Zhao, X., Ananth, P., Li, L., and Wang, Y.-X. Provable
robust watermarking for ai-generated text. arXiv preprint
arXiv:2306.17439, 2023.
10
Submission and Formatting Instructions for ICML 2025
Broader Impact
In this work, we aim to provide an approach to test the robustness of Large Language Models watermark. We propose a
method that can remove different watermarks in LLM-generated text. We are aware of the potential risks that our work entails
for the security and safety of LLMs, as they are increasingly adopted in various domains and applications. Nevertheless, we
also believe that our work advances open and transparent research on the challenges and limitations of the LLM watermark,
which is crucial for devising effective solutions and protections. Similarly, the last few years the exploration of adversarial
attacks (Wei et al., 2023; Madry et al., 2017; Krishna et al., 2024) has led to the improvement of responible AI and led to
techniques to safeguard against such vulnerabilities,e further coordinated with them before publicly releasing our results.
We also emphasize that, our ultimate goal in this paper is to identify the weaknesses of existing methods.
11
Submission and Formatting Instructions for ICML 2025
Contents of the appendix
The contents of the supplementary material are organized as follows:
• In Appendix A, we list the hyperparameters of the watermarking algorithm we used in experiment Section 4.
• In Appendix B, we perform the comparison of execution time and VRAM consumption between our algorithm and
other baseline methods.
• In Appendix C, we present the specific data points corresponding to the figure shown in Section 4.2.
• In Appendix D, we provide the precise data underlying the figure depicted in Section 4.3.
• In Appendix E, we provide the prompt we used to generate attack text.
• In Appendix F, we conducted extensive experiments to evaluate the overall preservation of the semantic meaning of the
original watermarked text.
• In Appendix G, we offer a brief discussion about the change in self-information under the influence of the watermark
algorithm.
• In Appendix H, we provide the full proof of our proposed method attack success rate upper bound and lower bound,
together with the proof of lemma.
• In Appendix I, we provide a visual comparison of the text generated by our method with watermarked text, non-
watermarked text, and text generated by other attack methods.
• In Appendix J, we provide extended experiments, including a comparison between our methods and baseline approaches
on the OpenGen dataset, as well as the performance of our methods against Adaptive Watermark and Waterfall
Watermark schemes.
12
Submission and Formatting Instructions for ICML 2025
A. Watermark algorithm setting
In this section, we list the hyperparameters of the watermarking algorithm we used in Section 4 below.
1 {
2
"algorithm_name": "KGW",
3
"gamma": 0.5,
4
"delta": 2.0,
5
"hash_key": 15485863,
6
"prefix_length": 1,
7
"z_threshold": 4.0
8 }
Listing 1. configuration KGW
1 {
2
"algorithm_name": "Unigram",
3
"gamma": 0.5,
4
"delta": 2.0,
5
"hash_key": 15485863,
6
"z_threshold": 4.0
7 }
Listing 2. configuration Unigram
1 {
2
"algorithm_name": "UPV",
3
"gamma": 0.5,
4
"delta": 2.0,
5
"z_threshold": 4.0,
6
"prefix_length": 1,
7
"bit_number": 16,
8
"sigma": 0.01,
9
"default_top_k": 20,
10 }
Listing 3. configuration UPV
1 {
2
"algorithm_name": "EWD",
3
"gamma": 0.5,
4
"delta": 2.0,
5
"hash_key": 15485863,
6
"prefix_length": 1,
7
"z_threshold": 4.0
8 }
Listing 4. configuration EWD
1 {
2
"algorithm_name": "DIP",
3
"gamma": 0.5,
4
"alpha":0.45,
5
"hash_key": 42,
6
"prefix_length": 5,
7
"z_threshold": 1.513,
8
"ignore_history": 1
9 }
Listing 5. configuration DIP
13
Submission and Formatting Instructions for ICML 2025
1 {
2
"algorithm_name": "SIR",
3
"delta": 1.0,
4
"chunk_length": 10,
5
"scale_dimension": 300,
6
"z_threshold": 0.0,
7 }
Listing 6. configuration SIR
1 {
2
"algorithm_name": "EXP",
3
"prefix_length": 4,
4
"hash_key": 15485863,
5
"threshold": 2.0,
6
"sequence_length": 230
7 }
Listing 7. configuration EXP
14
Submission and Formatting Instructions for ICML 2025
B. Execution time and VRAM consumption comparison
In this section, We conducted the attack experiments using 50 distinct watermark texts, each containing approximately 230 ±
20 tokens. For each method, we measured both execution time and VRAM usage. The reported execution time reflects the
average for a single attack instance. The experiments were run on NVIDIA A100 40GB GPUs, utilizing a sequential device
map for baseline methods requiring multiple GPUs. The configuration for the GPT Paraphraser follows the setup described
in Section 4.1. The results are shown in Table 5.
One of the main limitations of current model-based watermark removal attacks is their substantial resource consumption.
For instance, DIPPER built on the T5-XXL model, necessitates two 40GB A100 GPUs for effective operation. Similarly, the
GPT parser introduces considerable costs due to its dependence on a proprietary model that employs token-based billing.The
total time consumption for SIRA consists of two parts: two generations by the base model and the self-information mask.
Using SIRA-Tiny as example, The self-information mask is nearly negligible, as it does not require any text generation (less
than 0.1 seconds). The other two generations take around 2.6 seconds per generation on a single A100 GPU. Thus the total
execution time is around 10 seconds. We use the huggingface library in our experiment.
The DIPPER method utilizes a specially fine-tuned T5-XXL model for text paraphrasing. This model needs at least 40 GB
VRAM to run and one-time generation requires around 15 seconds on two A100GPU.
Our proposed pipeline operates with a minimal configuration of the LLaMA3-3b model, which is lightweight enough
to run on mobile-level devices. This ensures compatibility with many consumer-grade GPUs, significantly reducing
hardware requirements. Notably, even our most lightweight approach, SIRA-Tiny, outperforms all previous methods in our
experiments while consuming far fewer resources.
Moreover, our method is independent of specific LLM architectures, allowing it to be seamlessly transferred to the latest
language models to leverage their superior performance at no additional cost. As demonstrated in Table 5, the data was
generated using bf16; our VRAM consumption can be further reduced by employing mixed precision or quantized models,
further enhancing efficiency.
Table 5. Comparison of Execution Time and VRAM Usage for Different Methods.
Method
Execution Time (s)
VRAM Usage (GB)
GPT Paraphraser
12.8
N/A
DIPPER
14.7
44.56
SIRA-Tiny
5.3
7.06
SIRA-Small
10.3
18.20
SIRA-Large
37.2
138.60
We also provide a comprehensive cost analysis of our method in comparison to third-party paraphrasing services. Specifically,
we estimate the cost of processing 1 million tokens of watermarked text. According to OpenAI’s pricing, paraphrasing using
GPT-4o (GPT Paraphraser) costs
$0.01 × 2 × 10 = $20,
where $0.01 is the cost per 1M tokens (input or output), the factor 2 accounts for both input and output, and 10 iterations are
assumed.
In contrast, our method (SIRA-Small), based on LLaMA3-8B deployed via AWS Bedrock, incurs a significantly lower cost:
$0.22 × 2 × 2 = $0.88,
where $0.22 is the per-1M-token cost (input or output), the first factor of 2 accounts for input and output, and the second
factor of 2 accounts for two rewriting iterations. The cost can be further reduced using SIRA-Tiny (LLaMA3-3B).
C. Best F1 score and TPR/FPR
In Table 6, we list the specific data from the figure in Figure 2, which reflects different attack method’s performance of
dynamically adjusting the watermark detector’s z-threshold until a specified false positive rate is achieved. We report
both the F1 score and the true positive rate. It can be observed that, in most cases, our attack method achieves the best
performance.
15
Submission and Formatting Instructions for ICML 2025
Table 6. In this experiment, we dynamically adjust the z-score threshold of the watermarking algorithm until achieving specified false
positive rates for the watermark detector. Lower TPR and F1 scores indicate that the watermark detector struggles more to differentiate
between attack texts and human-written texts, suggesting a more effective attack.
Method
Attack Type
1% FPR
10% FPR
Best F1 (%)
TPR (%) F1 (%) TPR (%) F1 (%)
F1 (%)
KGW-1
No attack
100
99.5
100
95.2
99.8
DIPPER -1
1.6
3.1
7.8
13.3
66.6
DIPPER -2
0.8
1.6
7.0
12.1
66.6
GPT Paraphraser
1.8
3.6
8.7
14.0
66.8
SIRA Tiny
26.4
41.4
60.0
70.6
79.2
SIRA-Small
1.1
2.1
8.4
14.0
66.6
SIRA Large
1.1
2.1
8.0
13.6
66.6
Unigram
No attack
100
99.5
100
95.2
99.8
DIPPER -1
89.0
93.7
97.6
95.8
95.4
DIPPER -2
86.0
91.8
96.8
94.2
94.6
GPT Paraphraser
73.6
84.3
91.7
91.6
91.6
SIRA Tiny
42.2
58.9
71.4
78.7
82.5
SIRA-Small
29.0
44.6
62.2
72.7
80.0
SIRA Large
25.8
40.7
59.2
69.9
78.8
UPV
No attack
100
99.5
100
95.2
99.8
DIPPER -1
74.8
85.2
94.4
93.1
93.1
DIPPER -2
67.8
80.4
91.6
91.6
91.6
GPT Paraphraser
53.0
69.2
82.2
86.2
86.9
SIRA Tiny
40.8
57.5
74.4
80.7
83.4
SIRA-Small
27.0
42.3
65.6
75.4
81.4
SIRA Large
25.2
39.9
65.0
74.3
80.3
EWD
No attack
100
99.5
100
95.2
99.8
DIPPER -1
66.2
79.2
91.4
90.8
90.8
DIPPER -2
54.8
70.3
83.2
81.2
81.2
GPT Paraphraser
46.6
63.1
75.4
81.3
83.8
SIRA Tiny
22.0
35.8
52.2
64.4
77.0
SIRA-Small
10.2
18.3
35.8
49.1
71.6
SIRA Large
7.4
13.7
31.2
44.2
71.3
DIP
No attack
100
99.5
100
95.2
99.8
DIPPER -1
5.4
10.0
24.0
36.1
67.7
DIPPER-2
2.2
4.3
16.4
26.2
66.7
GPT Paraphraser
4.3
8.3
20.4
32.0
76.6
SIRA Tiny
1.4
2.7
11.8
19.4
66.7
SIRA-Small
1.6
3.1
11.2
18.7
66.7
SIRA Large
1.0
1.9
11.4
18.8
66.7
SIR
No attack
100
99.5
100
95.2
99.8
DIPPER -1
64.6
78.0
82.4
85.6
85.6
DIPPER -2
57.6
72.6
72.6
83.4
83.4
GPT Paraphraser
66.2
79.2
85.2
87.3
87.3
SIRA Tiny
52.8
68.7
77.6
82.7
85.1
SIRA-Small
42.8
59.5
70.2
77.9
82.4
SIRA Large
48.4
64.8
77.4
82.6
84.1
EXP
No attack
100
99.5
100
95.2
99.8
DIPPER -1
0.8
1.6
1.2
2.1
66.6
DIPPER -2
0.4
0.8
2.0
3.8
66.7
GPT Paraphraser
0.4
0.8
2.0
3.8
82.6
SIRA Tiny
0.6
1.2
4.4
7.7
66.6
SIRA-Small
0.4
0.8
9.3
15.6
66.6
SIRA Large
0.4
0.8
6.2
10.7
66.6
16
Submission and Formatting Instructions for ICML 2025
D. Detail number of PPL and sentence bert score
In this section, we list the detail number of PPL and sentence-bert score we present in the Section 4.3.
Attack
Watermark
KGW-1
Unigram
UPV
EWD
DIP
SIR
EXP
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
PPL(↓)
s-BERT(↑)
No attack
12.00
0.55
11.49
0.56
9.27
0.56
11.64
0.57
10.60
0.57
11.76
0.56
16.48
0.54
Word delete
NaN
0.03
NaN
0.03
NaN
0.03
NaN
0.01
NaN
0.04
NaN
0.03
NaN
0.04
Synonym Substitution
252.85
0.01
252.85
0.01
252.85
0.01
252.85
0.00
252.85
0.01
252.85
0.02
252.85
0.02
GPT Paraphraser
9.19
0.88
8.96
0.87
8.28
0.87
9.20
0.88
8.79
0.88
9.52
0.87
11.98
0.86
DIPPER-1
12.00
0.80
11.80
0.79
10.31
0.81
11.87
0.76
11.93
0.80
12.43
0.79
16.56
0.77
DIPPER-2
12.15
0.79
11.80
0.79
10.34
0.80
11.96
0.76
11.86
0.79
12.42
0.78
16.45
0.76
SIRA-Tiny (Ours)
9.97
0.77
9.14
0.76
8.93
0.76
10.45
0.76
9.43
0.77
10.09
0.77
10.96
0.75
SIRA-Small (Ours)
10.59
0.78
9.37
0.78
8.91
0.77
9.10
0.78
9.02
0.77
9.74
0.78
10.93
0.75
SIRA-Large (Ours)
10.14
0.80
8.62
0.77
9.39
0.81
10.22
0.81
8.93
0.77
10.35
0.81
11.32
0.79
Table 7. Performance of different attack methods against various watermark techniques, including SIRA variants.
E. Fill in blank instruction
We present our generation prompts(final step) and reference text generation prompts below. The reference text generation
followed the same prompt of (Sadasivan et al., 2023). During the generation process, the reference text and the masked text
are replaced by the two texts obtained in the first step.
Generation Prompts
You will be shown one reference paragraph and one incomplete paragraph. Your task is to write a complete paragraph
using incomplete paragraph. The complete paragraph should have similar length with reference paragraph. You
need to include all the information in the reference. but do not take the expression and words in the reference
paragraph. You should only answer the complete paragraph.
reference: [reference text]
incomplete paragraph: [mask text]
Reference Parapharse Prompts
You are a paraphraser. You are given an input passage ’INPUT’. You should paraphrase ’INPUT’ to print ’OUTPUT’.
’OUTPUT’ should be diverse and different as much as possible from ’INPUT’ and should not copy any part verbatim
from ’INPUT’. However, ’OUTPUT’ should preserve the information in the INPUT. You should print ’OUTPUT’
and nothing else so that it is easy for me to parse.:
F. GPT Semantic Judge
GPT Semantic Judge Prompts
You are a helpful assistant. You will receive a original text and a pharased text .Please act as an impartial judge and
evaluate how much the pharased text keep the original text semantic meaning. Be as objective as possible. Rate the
response on a scale from 1 to 10. A rating of 1 signifies the pharased text has totally different meaning with the
original text. A rating of 10 signifies the pharased text has same meaning with the original text . Your answer should
strictly be the format: [Rating].
Here’s the original text: [Watermarked text]
Here’s the pharsed text:[Attack text]
In this section, we conduct extensive experiments to evaluate the overall preservation of the semantic meaning of the original
watermarked text. We use ChatGPT (OpenAI, 2024) as an impartial judge to obtain the quantitative results.
The attack success rate alone is not a sufficient metric for evaluating an attack method. It is also crucial to assess whether
the original and paraphrased outputs preserve similar semantics. The Sentence-BERT score (Reimers & Gurevych, 2019),
presented in Section 4.3 , measures the sentence-level similarity between the original watermarked text and the adversarial
17
Submission and Formatting Instructions for ICML 2025
text. However, it falls short in determining whether the overall semantics are preserved. Inspired by the LLM jailbreak work
PAIR (Chao et al., 2023), which leverages carefully crafted prompts and the powerful capabilities of ChatGPT to score
attack texts and targets for quantitative evaluation, we adapted their prompts to use ChatGPT for assessing the semantic
similarity between watermarked texts and attack texts . This approach allows us to obtain semantic similarity scores that
more closely align with human perception. We show the judge prompt in Appendix F and the result in shown in Table 8.
Table 8. Semantic Preservation for Different Methods
Word Delete
Synonym
GPT Paraphraser
DIPPER-1
DIPPER-2
SIRA-Tiny
SIRA-Small
SIRA-Large
Semantic Preservation
2.59
2.63
8.25
5.28
6.34
6.10
6.84
8.02
We observed that using GPT for paraphrasing alone best preserves the original text’s semantics, whereas methods like word
deletion and synonym replacement were largely ineffective. Our approach demonstrated superior semantic preservation
compared to the DIPPER method.
18
Submission and Formatting Instructions for ICML 2025
G. Self-information, Entropy and Probability
We provide a brief explanation of how the watermark algorithm changes the self-information. To begin, we introduce the
definitions of self-information.
Self-Information (I(x)): This measures the amount of information or ”surprise” associated with a specific token x. It
quantifies how unexpected the occurrence of a token is in a given context:
I(x) = −log2 P(x)
When considering the context h, it becomes the conditional self-information:
I(x | h) = −log2 P(x | h)
where P(x | h) is the probability of token x occurring given the preceding context h.
We first analyze the non-conditional scenario, assuming that watermarking slightly increases the probability of certain tokens
by a small amount δ, while adjusting the probabilities of other tokens to maintain normalization. The δ change in token
influenced by watermark algorithm is usually very small (e.g less than 1e-3).
The adjusted probability for the watermarked token xw is:
P ′(xw) = P(xw) + δ
The adjusted probabilities for other tokens xi (i ̸= w) are:
P ′(xi) = P(xi) −ϵi
where P
i̸=w ϵi = δ.
The change in entropy due to these adjustments is given by:
∆H = H(P ′) −H(P) = −
X
i
[P ′(xi) log P ′(xi) −P(xi) log P(xi)]
The partial derivative of entropy with respect to P(xw) is:
∂H
∂P(xw) = −log P(xw) −1
The change in entropy due to a small change δ in P(xw) is approximately:
∆H ≈
∂H
∂P(xw)δ = −(log P(xw) + 1)δ
In high-entropy contexts, where P(xw) is small, log P(xw) becomes a large negative value. Therefore, log P(xw) + 1 is
still negative, and the product with the small δ results in a tiny ∆H(decrease in logarithmically). This attribute makes the
watermark algorithm need to embed patterns in high-entropy tokens, otherwise it will significantly compromise the
quality of the output.
For self-information, the change in self-information is:
∆I(xw) = −log P ′(xw) + log P(xw)
The derivative of self-information with respect to P(xw) is:
dI(xw)
dP(xw) = −
1
P(xw)
19
Submission and Formatting Instructions for ICML 2025
For small P(xw),
1
P (xw) is large, making ∆I(xw) more significant for small δ compared to ∆H.
Similarly, for conditional self-information, The uniform distribution serves as a theoretical upper bound for high entropy for
a given probability space and helps illustrate high-entropy scenarios where probability mass is thinly spread. In such cases,
we assume that the model predicts N possible next tokens with equal probability. Where:
P(x | Context) = 1
N
For large N, P(x | Context) becomes small.
The adjusted probability for the watermarked token xw is:
P ′(xw | Context) = 1
N + δ
The adjusted probabilities for other tokens xi (i ̸= w) are:
P ′(xi | Context) = 1
N −
δ
N −1,
for xi ̸= xw
The change in Conditional Self-Information is:
∆I(xw | Context) = I′(xw | Context) −I(xw | Context) = −log
 1
N + δ

+ log N
Using a Taylor series approximation for small δ:
log
 1
N + δ

≈log
 1
N

+ Nδ
The approximate change in conditional self-information is:
∆I(xw | Context) ≈−Nδ
Compared to the change in entropy, it is obvious self-information are more sensitive metric:
∆H ≈
∂H
∂P(xw)δ = −(log P(xw) + 1)δ
When P(x | Context) is small, the magnitude of the derivative is large, this indicates that small changes in P(x | Context)
result in bigger changes in I(x | Context). As a result, the green token influenced by the watermark change will have less
self-information than the original.
High-entropy tokens are usually associated with medium,high self-information due to their unpredictability and low
probability of occurrence. Considering the reduced self-information, these potential green tokens generally will exhibit high
or moderate self-information values. Therefore in practice, we filter out all tokens with high or moderate self-information.
This ensures we can comprehensively eliminate potential tokens.
20
Submission and Formatting Instructions for ICML 2025
H. Theoretical Proof
H.1. Preliminaries and Notation
Watermarked Text.
Let y = {y1, y2, . . . , yn} be a sequence of n tokens generated by a watermarked language model M.
A subset W ⊆{1, 2, . . . , n} denotes the indices of “green” (watermarked) tokens.
Base (Attack) Model.
Let Mattack be a language model distinct from M. Under Mattack, each token yi has probability
P(yi | y1, . . . , yi−1; Mattack).
Self-Information.
The self-information of yi under Mattack is defined as
I(yi) = −log P
 yi | y1, . . . , yi−1; Mattack

.
A larger I(yi) indicates yi is more “surprising” or low-probability under Mattack.
Attack Strategy.
• Threshold Selection: Choose a threshold τ (e.g., a certain percentile τϵ) and mask tokens whose self-information
exceeds τ.
• Rewrite Step: Provide the masked text plus a reference text to an LLM, instructing it to fill the placeholders.
• Success Criterion: The attack is considered successful if all watermarked tokens are significantly altered so that the
watermark is no longer detectable.
H.2. Lemmas on Self-Information Changes Due to Watermarking
Lemma H.1 (Bound on Self-Information Shift). Suppose a watermarking algorithm increases the probability of a single
token xw from P(xw) to P ′(xw) = P(xw) + δ, where δ is small (i.e., δ ≪1) and P(xw) ≪1. Let
I(xw) = −log P(xw),
I′(xw) = −log P ′(xw).
Then the drop in self-information, defined as
∆I(xw) = I′(xw) −I(xw),
is bounded by
∆I(xw) ≤−log

1 +
δ
Pmax

,
where Pmax is a small upper bound on P(xw) in the high self-information region.
Proof. Step 1: Express ∆I(xw).
∆I(xw) = [−log(P(xw) + δ)] −[−log P(xw)] = −log
 P(xw) + δ

+ log P(xw).
Step 2: Normalize by P(xw).
∆I(xw) = −log
h
P(xw)
 1 +
δ
P (xw)
i
+ log P(xw) = −log

1 +
δ
P (xw)

.
Step 3: Bound using Pmax. Since P(xw) ≤Pmax and Pmax ≪1, we have
1 +
δ
P (xw) ≥1 +
δ
Pmax .
Hence,
−log

1 +
δ
P (xw)

≤−log

1 +
δ
Pmax

,
21
Submission and Formatting Instructions for ICML 2025
giving
∆I(xw) ≤−log

1 +
δ
Pmax

.
Thus, even after watermarking, a low-probability token remains in a high-self-information regime (downward shift is
limited).
Lemma H.2 (Concentration in High Self-Information Region). Consider a watermarking process that selectively increases
the probability of certain tokens by δ. Let Iα be the α-quantile of self-information values under Mattack, i.e.,
Pr
yi∼Mattack

I(yi) ≥Iα

= α.
For sufficiently small δ, any watermarked token yi satisfies
I(yi) ≥Iα −Cδ,
where Cδ is a small constant capturing the maximum self-information drop due to δ.
Proof. Let yi ∈W be a watermarked token. Its probability is raised from P(yi) to P(yi) + δ. Using Lemma H.1,
I(yi) −I′(yi) ≤−log

1 +
δ
Pmax

= Cδ.
We denote
Cδ = sup
x
∆I(x)
.
Because tokens subject to watermarking are chosen (pre-watermark) from the high self-information region (I(yi) ≥Iα
except possibly some edge cases), their self-information remains at least Iα −Cδ after the slight probability increase. Thus,
I′(yi) ≈I(yi) ≥Iα −Cδ,
showing that watermarked tokens are still near or above Iα −Cδ.
H.3. Bounds on Attack Success Rate
Definition H.3 (Attack Success). Let Wi be the event “token yi is watermarked,” and let Ai be the event “token yi is
removed (masked) by the attack.” The overall attack is considered successful if every watermarked token is removed:
Success(y) =
^
i∈W
Ai.
Equivalently, Success(y) requires I(yi) ≥τϵ for all i ∈W, where τϵ is the chosen self-information threshold (i.e., the
ϵ-percentile).
Theorem H.4 (Attack Success Probability Bounds). Let τϵ be the self-information threshold chosen by the attacker. Then:
1. Lower Bound:
Pr

Success(y)

≥

min
i∈W Pr[I(yi) ≥τϵ | Wi]
|W|
.
2. Upper Bound:
Pr

Success(y)

≤Pr
h \
i∈W
{ I(yi) ≥τϵ}
i
.
Proof. Step 1: Success Event. The event Success(y) is equivalent to
\
i∈W
{I(yi) ≥τϵ}.
22
Submission and Formatting Instructions for ICML 2025
If any watermarked token yi has I(yi) < τϵ, it is not masked and the watermark may remain, so the attack fails.
Step 2: Lower Bound. Let
αi = Pr[I(yi) ≥τϵ | Wi].
Under (conditional) independence or a suitable lower-bounding assumption,
Pr
h \
i∈W
{I(yi) ≥τϵ}
 Wi for each i
i
≥
Y
i∈W
αi.
Then,
Y
i∈W
αi ≥

min
i∈W αi
|W|
.
This implies
Pr

Success(y)

≥

min
i∈W Pr[I(yi) ≥τϵ | Wi]
|W|
.
Step 3: Upper Bound. Clearly,
Pr

Success(y)

= Pr
h \
i∈W
{I(yi) ≥τϵ}
i
≤Pr
h \
i∈W
{I(yi) ≥τϵ}
i
.
In other words, the event that all watermarked tokens exceed τϵ (and hence are masked) is the maximum possible success
scenario for the attacker.
H.4. Corollary: Optimal Threshold in Randomized Watermarking
Corollary H.5 (Optimal Threshold under Random Watermarking). Suppose a watermarking scheme targets tokens above
the γ-quantile Iγ. If the attacker sets τϵ ≈Iγ, then asymptotically:
Pr

Success(y)

≈(1 −η)|W|,
where η is a small factor that captures the mismatch in the shifted distribution (i.e., how many tokens originally near Iγ
drop below τϵ after probability adjustments).
Proof. Step 1: Setup. Under the random watermarking assumption, tokens are chosen in the top γ-quantile of self-
information (i.e., I(yi) ≥Iγ). After adding a small δ, their self-information decreases by at most Cδ (Lemma H.1).
Step 2: Define η. Let
η = Pr
h
I′(yi) < τϵ
 I(yi) ≥Iγ
i
.
If τϵ ≈Iγ and δ is small, η is small because the shift from I(yi) to I′(yi) is minor.
Step 3: Success Probability. By Theorem H.4, each watermarked token has at least (1 −η) probability of lying above τϵ, so
Pr

Success(y)

≥(1 −η)|W|.
Similarly, it cannot exceed the intersection probability that all watermarked tokens are above τϵ, and (1 −η)|W| is a good
approximation when η ≪1. Thus the success probability is high.
The lemmas and theorems above show how minimal probability boosts (δ) ensure that watermarked tokens remain in the
high self-information region. By selecting a threshold τϵ near that region, the attacker can mask or replace the majority of
these tokens. Key points include:
23
Submission and Formatting Instructions for ICML 2025
• Local Context Benefits: Self-information depends on the context, making it more precise than a global entropy
measure.
• Small δ Requirement: Watermarking must keep δ small to avoid degrading output quality, which in turn prevents
drastic drops in self-information for chosen tokens.
• Success Probability Bounds: Theorem H.4 establishes that success probability can be arbitrarily close to 1 for an
appropriate threshold.
• Near-Optimal Threshold: Corollary H.5 suggests an attacker should roughly match the watermark’s targeted quantile
for best results.
The theoretical proof for the self-information rewrite attack shows that by a well-chosen filter we could remove the watermark
in the given text effectively. Our lemmas and bounds show that, under small-δ constraints, high-entropy tokens remain
detectable as high self-information tokens. This explains why token-level self-information filtering outperforms global,
context-agnostic entropy filtering. Consequently, an attacker can remove most or all watermarked tokens while maintaining
strong semantic coherence in the final paraphrased text.
I. Visualization
In this section, we present a visual comparison of our algorithm with other model-based paraphrasing methods, along with
the corresponding z-scores after the attack. For discrete methods, green tokens are marked in green, and red tokens in red.
In the watermarking algorithm, the detector identifies the embedded watermark through green tokens and calculates the
z-score; fewer green tokens or a lower z-score indicate a more successful attack. For continuous methods, the shade of color
denotes the weight of the watermarked token, with darker colors representing higher weights. In the case of attacked text,
lighter colors indicate a more successful attack.
Figure 4. Comparison of different paraphrasing methods on KGW watermarks. Each word’s color indicates whether it is a green or red
token. Fewer green words/lower z-scores suggest a more effective paraphrasing approach. The unwatermarked text represents the
model’s output without the influence of the watermarking algorithm. The example demonstrates that our method achieves a better z-score
than the unwatermarked text..
24
Submission and Formatting Instructions for ICML 2025
Figure 5. Comparison of different paraphrasing methods on Unigram watermarks.
25
Submission and Formatting Instructions for ICML 2025
Figure 6. Comparison of different paraphrasing methods on UPV watermarks. The color of each word indicates whether it belongs to
a green token or a red token. Less green signifies a more effective paraphrasing approach. Our methods show better performance in
removing original watermark text green token.
Figure 7. Comparison of different paraphrasing methods on EWD watermarks.
26
Submission and Formatting Instructions for ICML 2025
Figure 8. Comparison of different paraphrasing methods on EXP watermarks. The color of each word indicates whether it is a green or
red token. For EXP, lighter word colors and higher z-scores indicate a more effective attack.
Table 9. Comparison of watermark algorithms under different attack methods on the OpenGen dataset. Our proposed methods SIRA-Tiny
and SIRA-Small outperform all previous paraphrasing-based attacks under black-box settings.
Attack Success Rate (%) on OpenGen Dataset
Attack
Watermark
KGW-1
Unigram
UPV
EWD
DIP
SIR
EXP
Word delete
21.8
0.8
9.6
17.6
64
36.8
6.6
Synonym
77.4
16.8
67.8
72
98
71.4
47.4
GPT
69
58.2
57.4
73.4
98.2
58.8
74.2
DIPPER-1
89.4
67.8
71.4
88.8
98.8
74.6
83.2
DIPPER-2
89.2
71.2
78.8
92.2
99.0
72.8
85.6
SIRA-Tiny (Ours)
92
84
74.8
94.2
99.6
74.6
81.8
SIRA-Small (Ours)
93.8
91.2
80.6
94.8
99.6
80.2
86.2
J. Extend Experiments
We conduct additional experiments on the OpenGen dataset (Krishna et al., 2024), which consists of sampled passages from
WikiText-103. Specifically, we use a subset of 500 chunks as prompts, following the same experimental protocol described
in our main evaluation—namely, we prompt a target LLM with each chunk and assess the ability of different watermark
removal methods to induce decoding failures in the watermark verifier. We report the attack success rate (ASR) as our
primary metric. As shown in Table 9, our proposed methods consistently achieve the highest ASR across all watermarking
algorithms, demonstrating strong generalization and robustness beyond the training or development set used in previous
sections.
We observe that the performance of DIPPER improves significantly on the OpenGen dataset compared to its performance on
C4. We hypothesize that this may be attributed to distributional similarity between OpenGen and the supervised training
data used to train the DIPPER paraphraser, as both originate from the same source corpus introduced in Krishna et al. (2024).
Despite this advantage, our proposed method SIRA-Small still consistently achieves the highest attack success rates across
all watermarking algorithms, demonstrating stronger generalization to diverse data distributions.
27
Submission and Formatting Instructions for ICML 2025
Table 10. Attack success rate (ASR) on Adaptive Watermark and Waterfall Watermark. Sample size = 200. Our methods outperform all
baselines across both settings.
Adaptive Watermark
Waterfall Watermark
Attack
ASR (%)
Attack
ASR (%)
Word delete
5.6
Del
4.4
Synonym
92.4
Syn
55.6
GPT-4o Paraphraser
61.4
GPT
80.0
DIPPER-1
60.6
DIPPER-1
73.8
DIPPER-2
65.6
DIPPER-2
80.0
SIRA-Tiny (Ours)
96.2
SIRA-T (Ours)
88.4
SIRA-Small (Ours)
98.2
SIRA-S (Ours)
90.8
To further evaluate the generalizability of our proposed methods, we conduct additional experiments on two recently
introduced watermarking schemes: Adaptive Watermark (Liu & Bu, 2024) and Waterfall Watermark (Lau et al., 2024).
Following the same black-box threat model, we apply both baseline and our proposed attack methods to 200 samples from
C4 dataset for each setting. As shown in Table 10, SIRA-Tiny and SIRA-Small achieve significantly higher attack success
rates (ASR) compared to all baselines, including the strong GPT-4o paraphraser and DIPPER variants. Notably, on Adaptive
Watermark, SIRA-Small reaches 98.2% ASR, while the strongest baseline only achieves 92.4%. Similarly, for Waterfall
Watermark, SIRA-Small obtains 90.8% ASR, outperforming the closest baseline by over 10 percentage points. These results
demonstrate the superior robustness and transferability of our attack methods across different watermarking designs.
28


arXiv:2505.05328v1  [cs.CR]  8 May 2025
Timestamp Manipulation: Timestamp-based Nakamoto-style Blockchains are
Vulnerable
Junjie Hu
Department of Computer Science and Engineering
Shanghai Jiao Tong University
Shanghai 200240, China
Email: nakamoto@sjtu.edu.cn
Na Ruan
Department of Computer Science and Engineering
Shanghai Jiao Tong University
Shanghai 200240, China
Email: naruan@sjtu.edu.cn
Abstract—We introduce two advanced attack strategies, the
Unrestricted Uncle Maker (UUM) Attack and the Staircase-
Unrestricted Uncle Maker (SUUM) Attack, which fundamen-
tally threaten the security of timestamp-based Nakamoto-style
blockchains by inflicting permanent systemic harm. Unlike
prior work that merely enhances adversarial rewards, these
attacks exploit vulnerabilities in timestamp manipulation and
fork selection rules to irreversibly destabilize blockchain fair-
ness and incentive mechanisms. Specifically, the SUUM attack
enables adversaries to persistently launch attacks at zero cost,
eliminating constraints on block withholding and risk-free
conditions, while systematically maximizing rewards through
coordinated timestamp adjustments and strategic block release.
Our analysis demonstrates that SUUM adversaries achieve
disproportionate reward advantages over both UUM and the
original Riskless Uncle Maker (RUM) Attack [CCS ’23],
with all three strategies surpassing honest mining. Crucially,
SUUM’s cost-free persistence allows adversaries to indefinitely
drain rewards from honest participants by maintaining min-
imal difficulty risks through precise timestamp manipulation.
This creates a self-reinforcing cycle: adversaries amplify their
profits while suppressing honest returns, thereby permanently
eroding the protocol’s security assumptions. Through rigorous
theoretical modeling and simulations, we validate how SUUM’s
combination of timestamp tampering, block withholding, and
difficulty risk control enables unmitigated exploitation of con-
sensus mechanisms. This work underscores the existential risks
posed by timestamp-based Nakamoto-style protocols and ad-
vocates urgent countermeasures to ensure long-term stability.
1. Introduction
The Proof-of-Work (PoW) blockchains [1], [2], with Bit-
coin [3] and Ethereum 1.x [4], [5] as prominent examples,
have significantly propelled the thriving development of the
cryptocurrency sector, which boasts a market valuation of
1.9 trillion dollars [6]. These advanced blockchain systems
are built upon highly decentralized blockchain protocols and
ingeniously employ the PoW mechanism to ensure their
consistency and security [7], [8], [9], [10], [11], [12]. The
blockchain network is jointly maintained and operated by a
group of active participants known as miners, who possess
and control a certain amount of computational resources,
such as high-performance computers and specialized min-
ing hardware. Participants invest substantial computational
power to solve elaborately designed and extremely complex
cryptographic puzzles, a process referred to as mining [13].
Participants who successfully solve these puzzles gain the
right to record the next valid block on the blockchain.
The blockchain system provides generous incentives to
participants who successfully generate valid blocks, as a
reward for their diligent work and invested computational
resources. These incentives typically consist of a certain
quantity of newly issued cryptocurrencies and possibly
transaction fees included in the block. Ideally, the reward
allocation mechanism designed by the blockchain system is
relatively equitable, accurately reflecting the proportion of
computational resources invested by participants [14], [15],
[16]. This implies that participants with more computational
resources will have a higher probability of mining blocks
and receiving corresponding coin-base rewards, thereby in-
centivizing them to continue contributing to the stable op-
eration and security of the blockchain network. Numerous
cryptocurrencies that emerged after Bitcoin and subsequent
academic literature have proposed and implemented numer-
ous schemes to alter the blockchain reward mechanism [17],
[18], [19], [20]. The purpose of these changes is to ensure
that participants have no incentive to manipulate the system
for personal gain.
In September, 2022, Ethereum transitioned from its
Proof-of-Work mechanism (known as Ethereum 1.x) to a
new Proof-of-Stake mechanism (designated as Ethereum
2.x). It is noteworthy that Ethereum 1.x’s Proof-of-Work
version continues to be utilized by cryptocurrencies such
as Ethereum PoW [21], Ethereum Fair [22] and Ethereum
Classic [23]. These cryptocurrencies have evidently gained
popularity among participants: as of April 1, 2025, their
combined hash power accounted for 13.9% of the peak
hash power observed in the Ethereum 1.x ecosystem [24].
Ethereum 1.x boasts a significantly reduced block time of
approximately 13 seconds on average, compared to Bit-
coin’s average block time of 10 minutes, which results
Figure 1. Attack Flowchart. This figure illustrates the attack flowchart for the proposed RUM, UUM and SUUM attacks in timestamp-based Nakamoto-style
blockchains. The flowchart delineates the systematic process through which adversaries manipulate block timestamps and strategically withhold or release
blocks to gain disproportionate rewards. It highlights the adversarial strategies’ escalation from RUM (risk-constrained) to UUM (risk-tolerant) and SUUM
(withholding-enabled), emphasizing their impact on blockchain protocol and incentive fairness.
in frequent state fork (also known as soft fork) [25]. To
facilitate rapid convergence of blockchain states in the midst
of forks, the Ethereum 1.x protocol mandates that honest
participants select the branch with higher mining difficulty
[4]. Consequently, a series of mining attacks aimed at ma-
liciously manipulating block difficulty have been proposed
and proven effective in reducing blockchain security [16],
[26], [27], [28], [29], [30], [31]. Among them, the most
renowned is the riskless Uncle Maker attack (hereinafter re-
ferred to as RUM), which grants adversaries a risk-free and
highly lucrative advantage by meticulously manipulating
block timestamps. By examining Ethereum 1.x blockchain
data, the authors of RUM provided compelling evidence
indicating that participants executed variants of the RUM
attack for approximately two years [32]. One of the co-
founders of F2Pool (then the second-largest mining pool for
Ethereum 1.x) acknowledged their manipulation of block
timestamps in this manner, marking the first instance of
consensus protocol manipulation by participants in practice
[33].
Our work introduces two advanced attack strategies, the
Unrestricted Uncle Maker (UUM) Attack and the Staircase-
Unrestricted Uncle Maker (SUUM) Attack, that fundamen-
tally threaten the security of timestamp-based Nakamoto-
style blockchains by inflicting permanent systemic harm.
Unlike prior work that merely enhances adversarial re-
wards, these attacks exploit vulnerabilities in timestamp
manipulation and fork selection rules to irreversibly destabi-
lize blockchain fairness and incentive mechanisms. Specif-
ically, the SUUM attack enables adversaries to persistently
launch attacks at zero cost, eliminating constraints on block
withholding and risk-free conditions, while systematically
maximizing rewards through coordinated timestamp adjust-
ments and strategic block release. By combining times-
tamp tampering with staggered block release, adversaries
create a self-reinforcing cycle: they suppress honest par-
ticipants’ returns by manipulating difficulty growth rates
while amplifying their own profits through persistent chain
reorganizations. Through rigorous theoretical modeling and
large-scale simulations, we validate that SUUM adversaries
achieve disproportionate reward advantages (e.g., 33.30%
vs 28.41% for UUM at α = 0.25) over both honest mining
and prior attacks, all while maintaining minimal difficulty
risks through precise timestamp calibration. It is noteworthy
that our proposed attacks are applicable to any blockchain
system that adopts the Ethereum 1.x’s fork selection rule, in-
cluding Ethereum PoW [21], Ethereum Fair [22], Ethereum
Classic [23], and others.
This asymmetric advantage arises from the synergistic
exploitation of three core mechanisms: 1) Timestamp manip-
ulation: Adversaries artificially inflate their block difficulty
by retroactively adjusting timestamps to exploit Ethereum
1.x’s fork selection rules. 2) Block withholding: SUUM
adversaries strategically delay block releases to maximize
chain reorg opportunities, creating persistent forks that dis-
advantage honest miners. 3) Difficulty risk control: By
calibrating timestamps to the granularity of seconds, attack-
ers suppress blockchain difficulty escalation, ensuring their
operations remain cost-free and sustainable indefinitely.
The cumulative effect of these strategies permanently
erodes the protocol’s security assumptions. Honest partic-
ipants face diminishing returns as adversaries drain re-
wards proportionally, a zero-sum game where attackers’
gains directly translate to systemic losses. Our simulations
demonstrate that even adversaries with modest computa-
tional power (e.g., α = 0.3) reduce honest participants’
rewards by 11.85% compared to baseline honest mining.
This imbalance escalates exponentially as adversarial power
grows, ultimately leading to the collapse of the protocol’s
economic model, where rational participants are incentivized
to join adversarial coalitions rather than mine honestly.
This work underscores the existential risks posed by
timestamp-based Nakamoto-style protocols. The SUUM at-
tack’s cost-free persistence and irreversible damage neces-
sitate urgent countermeasures. We advocate for protocol
redesigns that decouple difficulty adjustments from adver-
sarial timestamp control and introduce economic penalties
for abnormal block intervals. Without such interventions, the
self-reinforcing nature of SUUM-like attacks threatens the
long-term viability of Ethereum 1.x derivatives and similar
blockchain systems.
Our Contributions. We summarize the contributions of this
paper as follows:
• Synergistic Attack Vector Design. We formalize a three-
pillar framework combining 1) timestamp manipulation to
inflate difficulty, 2) block withholding to maximize reorgs,
and 3) difficulty risk control via temporal gap optimiza-
tion. This synergy enables adversaries to systematically
drain rewards while suppressing honest participation (Sec-
tion 5.1, Theorem 6).
• Permanent Protocol Harm. We demonstrate that UUM
and SUUM attacks irreversibly destabilize the founda-
tional assumptions of timestamp-based Nakamoto-style
protocols. By exploiting fork selection rules and difficulty
adjustment mechanisms, adversaries create persistent re-
ward distortions that persist even post-attack, eroding
protocol fairness (Section 6.2).
• Cost-free
Attack
Sustainability. SUUM adversaries
achieve cost-free persistence through second-level times-
tamp manipulation and strategic block withholding, elim-
inating traditional constraints like hash power thresholds
(Theorem 7). Simulations confirm minimal difficulty es-
calation (0.21 maximal risk) despite sustained exploitation
(Figure 6).
• Systemic Economic Collapse. We prove SUUM triggers
a death spiral: adversarial rewards scale super-linearly
(e.g., 43.7% at α = 0.4), incentivizing rational miners to
defect. This accelerates protocol abandonment, ultimately
collapsing the economic model (Section 7.3).
• Empirical Validation. We implement a discrete-event
timestamp-based Nakamoto-style blockchan simulator
and conduct large-scale experiments (1M blocks, 10K
trials) to quantify SUUM’s dominance: adversaries with
α
=
0.3 reduce honest rewards by 11.85%, while
SUUM’s forking rate (3.2%) exceeds UUM (2.1%) and
RUM Attack
•
Risk-free baseline
•
Timestamp exploitation
UUM Attack
•
Permanent reward distortion
•
Minimal risk control
SUUM Attack
•
Synergistic strategies
•
Minimal risk control
Comparison
•
Relative reward
•
Difficulty risk
•
Forking rate
•
Cost
Simulated Estimation
•
Steady-state probability
•
Relative reward
•
Minimal difficulty risk
•
Forking rate
Exp. 1 & Def. 1
Thm. 9-12
Thm. 1-5
Thm. 6-8
Fig. 4-6
Figure 2. Roadmap. This figure outlines the research roadmap, starting
with the foundational RUM attack as a baseline, which exploits timestamp
manipulation for risk-free reward extraction. It progresses to the UUM
attack, relaxing risk constraints to enable more frequent attacks, and culmi-
nates in the SUUM attack, which introduces strategic block withholding to
form a three phase synergistic strategy-timestamp manipulation, block with-
holding, and difficulty risk control. The roadmap highlights key theorems
(Thm. 1-12) that formalize attack conditions, state transitions, and reward
dynamics, paired with simulated estimation of steady-state probabilities,
relative rewards, and forking rates to validate SUUM’s dominance.
RUM (1.4%) at equivalent power (Section 7.2, Figure 5-
6).
• Mitigation Framework. We propose countermeasures
including timestamp consensus mechanisms and diffi-
culty decoupling protocols, establishing defense princi-
ples against Uncle Maker attacks (Section 8).
Paper Structure. The structure of this paper is as follows:
we first present the threat model of the system, including
the composition of participants, adversary’s target, honest
participant’s strategy space and adversary’s strategy space
in Section 2. Secondly, we review the design of the original
RUM attack, provide formal definitions for block diffi-
culty and block rewards, and illustrate fork selection and
blockchain variable calculations through two examples in
Section 3. Thirdly, we propose the advanced variant of the
RUM attack, named UUM, and comprehensively analyze
UUM from four aspects: method, state space, state transi-
tion, and reward analysis in Section 4. Fourthly, based on
UUM, we introduce an even more advanced variant, SUUM,
and similarly conduct a comprehensive analysis of SUUM
from the aspects of method, state space, state transition, and
reward analysis in Section 5. Fifthly, we compare RUM,
UUM, SUUM, and honest mining from the perspective
of reward, difficulty risk, forking rate, and attack cost in
Section 6. Sixth, we validate theoretical claims through
large-scale simulations, quantifying steady-state probabil-
ities, reward disparities, and risk impacts in Section 7.
Finally, we explore countermeasures to incentivize against
Uncle Maker-based attacks in Section 8. Semi-formally, the
roadmap in this paper is shown in Figure 2.
2. Threat Model
Participant Composition. We assume a decentralized pro-
tocol, denoted as Γ, which is collectively executed by a set
of participants, P, across consecutive time slots. The set
of participants, P, can be subdivided into two subsets: the
set of honest participants, PH =

p1
h, p2
h, . . . , pn
h
	
, who
strictly adhere to the protocol Γ, and the set of adversaries,
PA, who potentially violate the protocol. Consequently, the
entire set P can be represented as the union of PH and PA,
i.e., P = PH ∪PA.
It is noteworthy that the scope of honest mining par-
ticipants, PH, is not limited to a single entity. Its compo-
sition can be extended to mining pool organizations and
even consortia formed by multiple mining pools. For the
purpose of facilitating theoretical analysis and discussion,
this paper uniformly abstracts such entities into the concept
of a ”single participant”. Correspondingly, the adversary
set, PA, may also exist in the form of mining pools or
mining pool alliances, exhibiting considerable complexity
and diversity. This paper follows the common assumptions
in the blockchain literature [4], [9], [34], namely, that during
the attack period, the hash power of each participant remains
constant, no new participants join the network, all mining
hardware is preconfigured, and relevant cost (including but
not limited to electricity expenses and mining hardware
acquisition cost) are prepaid. In practice, historical data
indicate that the active hashing rate in the network remains
relatively stable over short periods, with minor fluctuations
[35].
In protocol Γ, each participant p ∈P is associated with
a numerical value µp that lies between 0 and 1, such that
P
p∈P µp = 1. Here, µp represents the participation power
ratio of participant p in protocol Γ, which can be embodied
specifically as hash power, stake power, or other relevant
metrics.
Regarding the settings of timestamps and block struc-
tures, we assume that the timestamp of the genesis block B0
is t0 = 0. Starting from the genesis block, the timestamp of
block Bi, which is generations of i away from the genesis
block on the main chain, is denoted as ti, with a corre-
sponding difficulty of Di. Its immediate predecessor (parent
block) Bi−1 has a timestamp of tp
i = ti−1. Additionally, a
variable pui ∈{0, 1} is introduced to indicate whether the
parent block of block Bi references any uncle blocks. If it
does, then pui = 1; otherwise, pui = 0.
Adversary’s Target. Ethereum 1.x, as a cryptocurrency
system, embraces the same notion of fairness as its coun-
terparts, namely, participants with an expected hash rate
proportion of µp should be able to mine a corresponding
proportion of µp blocks and thus obtain µp of the mining
rewards, as reported in [9], [34]. In this study, the core target
of the adversary PA is to surpass their fair share based on
hash rate, specifically by mining more blocks than their pro-
portional share µPA, thereby obtaining rewards exceeding
their deserved portion. The achievement of this target will
be verified through subsequent theoretical analysis.
Honest Participant’s Strategy Space. The definition of
honest mining protocol in this paper refers to the relevant
academic literature in the field of blockchain [34], [36] and
specifically follows the rules established by the Ethereum
1.x White Paper [4]. Accordingly, honest participants always
strive to mine the blocks with the highest total difficulty and
strictly follow the protocol requirements, neither withhold-
ing blocks nor engaging in any form of manipulation of
block timestamps.
Adversary’s Strategy Space. In contrast, adversaries pos-
sess greater freedom in selecting their strategies. Within
the framework of this study, adversaries are permitted to
deviate from the honest mining protocol to a certain extent,
but the blocks they produce must strictly comply with the
validity requirements of the Ethereum 1.x protocol rules [4].
Specifically, adversaries are free to adjust the timestamps of
the blocks they mine, but must ensure that these timestamps
fall within a valid range (as described in Definition 1). Fur-
thermore, adversaries have complete autonomy in choosing
which blocks to mine.
To clearly distinguish the attack models proposed in
this study from the attack strategies presented in previous
literature [34], [36], [37], [38], [39], we introduce two
specific types of adversaries: UUM and SUUM. The UUM
adversary abandons the risk-free constraint of the RUM
attack, increases the steady-state probability of being in the
attack state, and possesses the ability to selectively set block
timestamps, but is not allowed to withhold blocks. Once
a valid block is found by the UUM adversary, it must be
immediately released. The SUUM adversary further relaxes
the constraints by discarding the rule against withholding
blocks in UUM, thereby further increasing its steady-state
probability of being in the attack state. Meanwhile, the
SUUM adversary retains the right to strategically set block
timestamps.
3. The Design of RUM Attack
In this section, we introduce the RUM attack, which
targets vulnerabilities in the incentive mechanism of the
Nakamoto-style protocol. The target of this attack is for a
RUM adversary who deviates from the protocol to obtain
higher rewards than an honest participant who strictly ad-
heres to the protocol specifications. We begin by reviewing
the original RUM attack and, subsequently, build upon
it to propose a low-risk, high-reward UUM attack. This
attack removes the risk-free constraint, further increasing
the probability of an adversary initiating the UUM attack
and thus enhancing the utility of the UUM adversary. Fi-
nally, we further propose the SUUM attack based on this
foundation. This attack lifts the restriction on adversaries
withholding blocks, significantly expanding the adversary’s
strategic space and substantially boosting their utility. The
only cost is a slight increase in block difficulty.
3.1. Preliminaries
Each participant P in the Proof-of-Work blockchain
engages in an iterative process aimed at deriving solutions
to the cryptographic puzzle required for constructing a
valid block. This process can be rigorously abstracted as a
paradigm of Bernoulli trials: participants propose a solution
randomly, and if this solution meets the established criteria,
the trial outcome is recorded as true; otherwise, it is recorded
as false. This series of mutually independent Bernoulli trials
Deployment
Attack
(a) RUM state transition. In the RUM attack, the adversary employs a risk-free
strategy and is not allowed to withhold blocks. The risk-free condition is achieved
through the transition from the deployment state to the attack state when
.
Deployment
Attack
(b) UUM state transition. Building upon the RUM framework, the UUM attack
amplifies the steady-state probability of transitioning to the attack state, trading
minimal risk for higher rewards. Specifically, the condition for transitioning from
the deployment state to the attack state is extended to
.
During the attack state, once the UUM adversary successfully discovers a new
block, the attack is deemed successful by strategically setting the timestamp
.
Deployment
Downgrade
Attack 1
Attack 2
…
(c) SUUM state transition: Building upon the UUM framework, the SUUM attack
further enhances the adversary’s strategy space by allowing the withholding of
blocks. The Markov process of SUUM can be decomposed into two parts. On one
hand, from the local perspective of the deployment and downgrade states, SUUM
reduces to UUM, where the strategies of the two adversaries are identical. On the
other hand, from the local perspective of the deployment and attack states, SUUM
resembles traditional selfish mining, with the sole distinction being that the
SUUM adversary meticulously manipulates the timestamp
to
ensure the success of the SUUM attack.
Figure 3. State Transition Process. This figure illustrates the state transition
process under different mining strategies, delineating the dynamic trans-
formation relationships among different states in the blockchain system.
The diagram clearly presents the path from the initial state to the attack
state through nodes and arrows, including the critical transition conditions
between the deployment state and the attack state. It annotates the proba-
bilities of state transitions and the behaviors of participants, revealing how
attack strategies influence the blockchain’s difficulty and reward distribution
by manipulating timestamps and block release timing.
collectively constitutes a Bernoulli process. Upon observing
this series of trials, the frequency of attempts required to
achieve a successful outcome follows a geometric distribu-
tion. The duration spent on successfully discovering a valid
block is allocated according to an exponential distribution.
Notably, both the geometric and exponential distribu-
tions exhibit the property of memorylessness. This implies
that the success probability of each trial remains constant
and is regulated by the difficulty parameter of the aforemen-
tioned protocol. Therefore, the probability of a participant
finding a valid solution does not fluctuate due to their
previous failures. Once any participant successfully obtains
a valid block, by integrating it into their local blockchain
and restarting the mining process, their opportunity to mine
subsequent blocks remains unchanged. This property is also
referred to as progress-free.
The RUM attack exploits the fact of the protocol Γ
that honest participants PA default to selecting the block
with higher difficulty in the presence of fork competition in
Ethereum 1.x. For ease of understanding, we illustrate an
example of fork selection through Example 1.
We denote the timestamp and difficulty of the i-th block
Bph
i
on the honest branch during a fork competition as
tph
i
and Dph
i , respectively. Similarly, the timestamp and
difficulty of the i-th block Bpa
i
on the adversary’s branch
during a fork competition are denoted as tpa
i
and Dpa
i .
Example 1 (Fork Selection). The blockchain comprises
three blocks, denoted as B0, Bpa
1 , and Bph
1 . The timestamp
of block B0 is represented by tph
0
or tpa
0 , and its difficulty
is denoted by Dph
0
or Dpa
0 . For block Bpa
1 , the timestamp
is tpa
1
and its difficulty is Dpa
1 . Similarly, for block Bph
1 , the
timestamp is tph
1
and its difficulty is Dph
1 . According to the
Ethereum 1.x protocol, participants are instructed to select
the block with the maximum difficulty. Specifically:
(1) Case 1: If Dph
1
= max {Dph
1 , Dpa
1 }, select block Bph
1 .
(2) Case 2: If Dpa
1
= max {Dph
1 , Dpa
1 }, select block Bpa
1 .
(3) Case 3: If Dph
1
= Dpa
1 , select either block arbitrarily.
In the previously introduced attack scenarios, such as
an adversary waiting for the emergence of a new block
with a specific timestamp difference in the RUM attack,
the objective is to leverage the block difficulty calculation
rules under certain conditions, thereby giving the blocks
they mine a competitive edge in the difficulty competition.
Therefore, a thorough understanding of the principles and
rules underlying block difficulty calculation is of significant
importance for analyzing and defending against various at-
tack behaviors targeting the Ethereum 1.x blockchain. Now,
we provide a formal definition of block difficulty.
Definition 1 (Block Difficulty). The difficulty Di of block
Bi satisfies the following equation:
Di
def
= max

217, Dp
i + f ·
 Dp
i
2048

,
where f = max
n
1 + pui −
j
ti−ti−1
9
k
, −99
o
.
Please note that in Ethereum 1.x, the difficulty of blocks
after height 15 exceeds 217. Consequently, in subsequent
analyses concerning block difficulty, the difficulty Di of
block Bi is determined by the following equation:
Di
def
= Dp
i +max

1 + pui −
ti −ti−1
9

, −99

·
 Dp
i
2048

.
3.2. Method
Based on the previously established rules for calculating
block difficulty, it is evident that the difficulty of a block de-
pends on the difficulty of its parent block and the difference
in timestamps between the two blocks. An adversary can
exploit this rule by meticulously and manually manipulating
the block timestamps to make their own block’s difficulty
higher than that of blocks on other branches, thereby in-
creasing the likelihood of their block being selected pref-
erentially. The RUM attack leverages this vulnerability. We
show the state transition process of RUM in Figure 3-(a).
Specifically, the RUM attack manipulates block times-
tamps in two phases to create a difficulty advantage and
achieve risk-free block prioritization. In the deployment
phase, the adversary monitors blocks generated by honest
participants and waits for the timestamp difference between
a new honest block Bph
1
and the previous mainchain block
Bph
0
to fall within the interval tph
1 −tph
0
∈(9, 18] seconds
(i.e.,
j
t
ph
1 −t
ph
1
9
k
= 1). This condition ensures the honest
block is valid and that the adversary’s mining difficulty on
the parent block Bph
0
matches the honest mining difficulty
on Bph
1 , eliminating additional risk. Once this timestamp
difference is met, the attack progresses to the execution
phase.
During the execution phase, the adversary mines on the
parent block Bph
0
(identical to Bph
0
and aims to generate a
valid block Bph
1
before honest participants. The adversary
ensures the timestamp difference between Bph
1
and Bph
0
is
1 ≤tpa
1 −tph
1
< 9 seconds (i.e.,
j
tpa
1 −t
ph
0
9
k
= 0), making
the difficulty of Bpa
1
higher than that of the honest block
Bph
1 . According to Ethereum 1.x’s fork selection rule, which
prioritizes the chain with higher difficulty, other participants
will prefer the adversary’s block, ensuring attack success.
Regardless of success, the process returns to the deployment
phase to await the next valid timestamp difference. By
precisely controlling timestamp differences, the RUM attack
creates a sustained difficulty advantage without additional
risk, exploiting the protocol’s rules to secure preferential
block inclusion and undermine blockchain fairness.
4. The Design of UUM Attack
After discussing the specific method of the RUM attack,
we delve into the expansion of the strategy space in the
UUM attack compared to the RUM attack, particularly
during the deployment phase. The RUM attack imposes
relatively strict constraints on the adversary’s behavior, such
as requiring specific conditions to enter the attack state,
to ensure the risk-free feature of the attack. However, the
UUM attack breaks this constraint, providing adversaries
with more flexible strategic options.
To achieve minimal risk control, adversaries need to
manipulate block timestamps with greater precision during
the UUM attack process. By cleverly selecting timestamps,
adversaries must not only ensure that their mined blocks
have an advantage in the difficulty competition to increase
the probability of attack success but also minimize the
impact on the overall difficulty growth of the blockchain,
making the attack more covert and sustainable. This requires
adversaries to carefully consider the balance between var-
ious factors when executing the attack, aiming to reduce
risks while obtaining benefits.
4.1. Method
Specifically, the UUM attack operationalizes a three
phase framework to achieve low-risk, high-reward objectives
by capitalizing on timestamp manipulation within Ethereum
1.x-style fork selection rules. In the deployment phase,
the attacker monitors the timestamp difference between a
newly generated honest block Bph
1
and its preceding main-
chain block Bph
0 , waiting for tph
1
−tph
0
∈[9, +∞) (i.e.,
j
t
ph
1 −t
ph
0
9
k
≥1), a condition that validates the honest block
and enables selective timestamp manipulation to elevate the
difficulty of the attacker’s subsequent block above that of
honest competitors. When the floor function result equals 1,
the attack reduces to the risk-free RUM variant, whereas
values greater than 1 introduce moderate risk alongside
enhanced excess rewards.
Subsequently, in the execution phase, after satisfying
deployment conditions, the attacker mines on the parent
block of the latest mainchain block and, upon generating a
valid block Bpa
1
before honest participants with a timestamp
difference tp1
a −tp0
a ∈[1, 900), triggers successful attack pro-
gression to the risk control phase; this timestamp range en-
sures block validity and a difficulty advantage (Dpa
1
> Dph
0 ),
thereby compelling honest nodes to prioritize the adversarial
block during forks; failed conditions revert the process to
deployment.
In the minimum risk control phase, the attacker meticu-
lously adjusts the timestamp tp1
a of their block to maximize
difficulty superiority over honest blocks while minimizing
subsequent difficulty growth rates through precise temporal
calibration (e.g., enforcing
j
t
ph
1 −tpa
0
9
k
= 1 for minimal risk),
after which the attack cycle resets to the deployment phase,
establishing a self-reinforcing loop of strategic exploitation
under controlled difficulty fluctuations.
Next, we elaborate on the relevant characteristics of
the UUM attack under these more relaxed deployment
conditions through Theorem 1, further understanding the
advantages and impacts of the UUM attack compared to
the RUM attack.
Theorem 1 (UUM Initiation Condition). The initiation
condition for the UUM attack is given by
j
t
ph
1 −t
ph
0
9
k
∈
[1, +∞).
Proof of Theorem 1. The detailed proof of Theorem 1 can
be found in Appendix B.
The success of the UUM adversary’s execution phase
hinges on the combined effects of multiple critical factors,
which not only encompass the difference in block times-
tamps but are also intimately related to the adversary’s abil-
ity to successfully mine blocks that meet specific conditions.
To gain an accurate understanding of the characteristics of
the UUM attack during its execution phase, we precisely
define the conditions for its success through Theorem 2.
Theorem 2 (UUM Successful Condition). The UUM at-
tack is successful if and only if
j
t
ph
1 −tpa
1
9
k
∈[1, +∞) and
tpa
1 −tpa
0 ∈[1, 900).
Proof of Theorem 2. The detailed proof of Theorem 2 can
be found in Appendix C.
In the course of our in-depth investigation of the UUM
attack, we have already explored its initiation condition and
success condition. However, for adversaries, minimizing the
risks associated with the attack while pursuing success is
also a crucial consideration. Here, risk primarily manifests
in its impact on the difficulty of the blockchain.
Next, we will elaborate on the specific conditions for
minimal risk control in the UUM attack through Theorem 3,
further revealing the internal mechanisms and characteristics
of the UUM attack under risk control strategies.
Theorem 3 (UUM Successful Condition with Minimal
Risk). The UUM attack is successful with minimal risk if
and only if
j
t
ph
1 −tpa
1
9
k
= 1 and tpa
1 −tpa
0 ∈[1, 900).
Proof of Theorem 3. The detailed proof of Theorem 3 can
be found in Appendix D.
As mentioned earlier, the RUM attack has stringent risk
control requirements to achieve what is termed a risk-free
attack. In contrast, the UUM attack relaxes these constraints
to a certain extent, providing adversaries with a broader
strategic space. Under specific settings of block timestamps,
the UUM attack can exhibit similar or even equivalent
characteristics to the RUM attack, providing an important
perspective for us to deeply understand the feature of both
attack methods.
Next, we will delve into the conditions under which
the UUM attack downgrades into the RUM attack through
Theorem 4.
Theorem 4 (UUM Downgrades to RUM). The downgra-
dation of UUM to RUM occurs if and only if
j
t
ph
1 −t
ph
0
9
k
= 1.
Proof of Theorem 4. The detailed proof of Theorem 4 can
be found in E.
4.2. State Space
Based on the analysis of the three phase strategy of
the UUM attack, its state space can be divided into two
categories: the deployment state and the attack state. The
deployment state refers to the scenario where the UUM
attacker waits for an appropriate opportunity to launch
an attack. At this time, the blockchain topology and the
timestamp of the latest block do not meet the attack con-
ditions. The latest block is generated by either the attacker
or honest participants, and the time difference between it
and the previous main chain block is less than 9 seconds.
The attack state means that the blockchain topology and
the timestamp of the latest block comply with the attack
conditions described in Theorem 2, that is, the latest block
is generated by honest participants and the time difference
between it and the previous main chain block is greater than
or equal to 9 seconds.
Regarding state transitions, in the deployment state, if
honest participants generate a block with a time difference
greater than or equal to 9 seconds, the state changes to
the attack state; otherwise, it remains in the deployment
state. In the attack state, if honest participants continue to
generate blocks with a time difference greater than or equal
to 9 seconds, the attack state is maintained. If the attacker
generates a block and strategically sets the timestamp, the
state reverts to the deployment state. In other cases, the state
also changes to the deployment state. The state transition
process of UUM can be found in Figure 3-(b).
4.3. Reward Analysis
By cleverly manipulating block timestamps and employ-
ing attack strategies, UUM adversaries attempt to obtain
rewards exceeding their fair share, which inevitably impacts
the interests of honest participants. Next, we conduct an in-
depth analysis through Theorem 5 to examine the changes
in the share of coin-base rewards between adversaries and
honest participants under the UUM attack, thereby reveal-
ing the specific impact of the UUM attack on the reward
distribution mechanism.
Prior to proving this theorem, we define some additional
notations: RRUM
P
denotes the absolute share of the main
chain block coin-base reward for an RUM participant P,
and E

RRUM
P

represents the expected relative share of the
main chain block coin-base reward for an RUM participant
P.
Theorem 5 (UUM Adversary Rewards). The expected
relative share of coin-base rewards for UUM adversaries
increases, while the absolute share remains unchanged.
Conversely, both the expected relative and absolute shares
of coin-base rewards for honest participants will decrease.
Proof of Theorem 5. Based on the analysis of state tran-
sitions for UUM deployment and attack states presented in
Section 4.2, we calculate the absolute and relative shares
of coin-base rewards for both UUM adversaries and honest
participants.
The reward analysis for all state transitions is analogous
to that of selfish mining. Among these, a particular case
warrants attention, corresponding to the transition from the
Attack State to the Deployment State (sixth row) in Table
1. In this case, the UUM adversary PA discovers the next
valid block and publishes it, carefully setting the timestamp
to ensure that the block’s difficulty exceeds that of an
honest block. This manipulation causes the attacker’s block
to be preferentially selected by other honest participants.
Consequently, PA prevails in the fork competition and earns
a coin-base reward. Conversely, the block generated by
honest participants becomes an orphan block, triggering a
transition from the Deployment State to the Attack State
(third row) in Table 1. This transition results in the recall
of a coin-base reward that was prematurely awarded to
honest participants. Therefore, the reward PH for honest
participants corresponding to this state transition is −1.
Details of the formalized proof are provided in Appendix
F.
The key mechanism lies in the irreversible shift of the
steady-state probability:
• Persistent Existence of the Attack State. The deploy-
ment condition of the UUM attack (⌊t
ph
1 −t
ph
0
9
⌋≥1) is
frequently triggered during the normal operation of the
blockchain, causing the system to remain in the attack
state for an extended period (P(Attack) ↑).
• Self-Reinforcing Cycle. When the attack is successful,
the attacker suppresses the growth of subsequent block
difficulty to the lowest level through timestamp calibration
(see Theorem 3), making the attack cost approach zero
(ACUUM ≈0). This enables the attacker to maintain the
attack state indefinitely, forming a positive feedback loop
of attack →reward extraction →controllable difficulty
risk →continuous attack.
• Zero-Sum Redistribution of Rewards. Each time the
attacker succeeds, the absolute reward share of honest
participants decreases by 1 (as shown in the sixth row of
State Transition Table II), while the relative share of the
attacker grows linearly with the steady-state probability
(E[RUUM
PA ] ∝P(Attack)). Since the difficulty adjustment
cannot automatically correct this deviation, the reward
distortion will be permanently embedded in the protocol’s
economic model.
5. The Design of SUUM Attack
The SUUM attack achieves persistent reward maximiza-
tion through three core synergistic strategies embedded in
its five phase framework, formally defined in Theorem 6-
7 and visualized in Figure 3-(c). These strategies create a
self-reinforcing loop by integrating timestamp manipulation,
block withholding, and difficulty risk control:
• Timestamp Manipulation for Difficulty Dominance.
During the Deployment Phase, once the adversary with-
holds the first private block Bpa
1 , timestamp manipula-
tion becomes critical for difficulty advantage. By set-
ting tpa
1
−tpa
0
∈[1, 9) (Theorem 6 Condition 1), the
attacker ensures: Dpa
1
= Dpa
0 +

1 −
j
tpa
1 −tpa
0
9
k
·
j
Dpa
0
2048
k
,
where
j
tpa
1 −tpa
0
9
k
= 0 (due to t < 9), yielding a posi-
tive difficulty increment. In contrast, honest blocks with
tph
1
−tph
0
≥9 incur a non-positive increment, ensuring
Dpa
1
> Dph
1
and preferential chain selection (Figure 3-(c)
transition from Attack State to Release Phase).
• Block Withholding for Reorganization Cascades. The
withholding strategy extends to subsequent blocks (i ≥
2), where the adversary appends Bpa
i
to the private
chain until an honest block Bph
i
emerges. By controlling
timestamp differences to satisfy

t
ph
i
−t
ph
i−1−(tpa
i
−tpa
i−1)
9

≥
1 (Theorem 6 Condition 2), each released private block
surpasses the honest chain’s difficulty, enabling cascading
reorganizations. As shown in Figure 3-(c), the state transi-
tion from Attack i to Attack i+1 represents ongoing with-
holding, while Attack i to Deployment triggers strategic
release, maximizing fork opportunities (simulations show
SUUM forking rate 3.2% vs. UUM’s 2.1% at α = 0.25,
Figure 6-(b)).
• Difficulty Risk Control for Cost-free Persistence. To
minimize difficulty fluctuations, the adversary restricts
tpa
i
−tpa
i−1 ∈[1, 9) (Theorem 7 Condition 1), ensuring
j
t
ph
i
−tpa
i
9
k
= 1 and minimal risk (maximal difficulty de-
viation 0.21, Figure 6-(a)). The state space’s Downgrade
State (Figure 3-(c)) acts as a safety mechanism, allow-
ing fallback to UUM strategies when honest timestamp
differences exceed 9 seconds, maintaining a steady-state
attack probability 37.8% higher than UUM (Figure 4) and
attack cost ACSUUM ≈0 (Theorem 12).
5.1. Method
Specifically, the SUUM attack achieves the goal of low
risk and high returns through five phases: SUUM downgrade
phase, SUUM deployment phase, SUUM block withholding
phase, SUUM block release phase, and SUUM minimum
risk control phase.
• Phase One: SUUM Downgrade Phase. If adversary
PA in SUUM observes that the difference between the
timestamp tph
1
of a newly generated block Bph
1
by honest
participant PH in the network and the timestamp tph
0
of
the previous main chain block Bph
0
is tph
1 −tph
0
∈[9, +∞),
i.e.,
j
t
ph
1 −t
ph
0
9
k
∈[1, +∞), then SUUM downgrades to
UUM. Note that when
j
t
ph
1 −t
ph
0
9
k
= 1, SUUM further
downgrades to RUM. The subsequent strategies of ad-
versary PA in SUUM are identical to those in UUM. If
adversary PA in SUUM first discovers a valid block, it
proceeds to Phase Two.
• Phase Two: SUUM Deployment Phase. At this point,
adversary PA in SUUM first discovers a valid block Bpa
1 .
PA will withhold this block Bpa
1 , forming a private chain
visible only locally to himself, and then transitions to
Phase Three.
• Phase Three: SUUM Withholding Block Phase. The
adversary PA in SUUM continues mining along the pri-
vate chain. If PA discovers a new valid block Bpa
2 , he
appends this block to its local private chain and contin-
ues executing Phase Three. If, on the other hand, an
honest participant PH discovers a new valid block Bph
1 ,
it transitions to Phase Four.
• Phase Four: SUUM Releasing Block Phase. At this
juncture, the local private chain of adversary PA in
SUUM has a length of at least 1, and honest participant
PH discovers a new valid block Bph
1 . Adversary PA in
SUUM releases a private block Bpa
1
and transitions to
Phase Five. After the process of releasing the block is
completed, if the length of PA’s local private chain still
remains at least 1, he proceeds to Phase Three. If PA
has no private blocks held in reserve, he transitions to
Phase One.
• Phase Five: SUUM Minimum Risk Control Phase. PA
carefully selects the timestamp tpa
1
for the block Bpa
1 ,
aiming to achieve a higher difficulty Dpa
1
compared to
the honest block’s difficulty Dph
1
while minimizing the
subsequent block difficulty growth rate. Upon completion
of this step, PA proceeds with the subsequent steps of
Phase Four.
Compared to the UUM attack, the most notable distinc-
tion of the SUUM attack lies in its allowance for adversaries
to strategically withhold or release blocks under specific cir-
cumstances. This characteristic enables adversaries to more
flexibly respond to various situations within the blockchain
network, increasing the likelihood of attack success and
potential rewards. To fully grasp the mechanism of the
SUUM attack, we first clarify its success conditions in
Theorem 6.
Theorem 6 (SUUM Successful Condition). The SUUM
attack is successful if and only if the following conditions
are met:
(1) For i = 1, the conditions

t
ph
i
−tpa
i−1
9

=
h
t
ph
1 −tpa
0
9
i
∈
[1, +∞) and tpa
i
−tpa
i−1 = tpa
1 −tpa
0 ∈[1, 900) must be
satisfied.
(2) For i ≥2, the conditions

t
ph
i
−t
ph
i−1−(tpa
i
−tpa
i−1)
9

∈
[1, +∞) and tpa
i
−tpa
i−1 ∈[1, 900) must be satisfied.
Proof of Theorem 6. The detailed proof of Theorem 6 can
be found in Appendix G.
After thoroughly discussing the success conditions of the
SUUM attack, we further focus on the minimum risk control
strategy. Due to its more complex attack pattern involving
operations such as withholding and releasing blocks, risk
control becomes particularly important in the SUUM attack.
Similar to the UUM attack, the primary risk associated with
the SUUM attack manifests in its impact on blockchain
difficulty.
Next, we will elaborate on the specific conditions of
the SUUM attack in terms of minimal risk control through
Theorem 7, revealing the internal mechanisms and charac-
teristics of the SUUM attack under risk control strategies.
Theorem 7 (SUUM Successful Condition with Minimal
Risk). The SUUM attack is successful with minimal risk if
and only if the following conditions are met:
(1) For i = 1, the conditions

t
ph
i
−tpa
i−1
9

=
j
t
ph
1 −tpa
0
9
k
= 1
and tpa
i
−tpa
i−1 = tpa
1 −tpa
0 ∈[1, 900) must be satisfied.
(2) For i ≥2, the conditions

t
ph
i
−t
ph
i−1−(tpa
i
−tpa
i−1)
9

= 1
and tpa
i
−tpa
i−1 ∈[1, 900) must be satisfied.
Proof of Theorem 7. The detailed proof of Theorem 7 can
be found in Appendix H.
5.2. State Space
Based on the analysis of the SUUM attack strategy, its
state space is macroscopically divided into three states: the
deployment state, the downgrade state, and the attack state,
where the attack state is microscopically further divided into
the withholding state and the releasing state. The deploy-
ment state refers to the scenario where the SUUM adversary
waits for an opportune moment to launch an attack, where
the blockchain topology and the timestamp of the latest
block do not satisfy the attack conditions of the UUM
adversary, and the latest block can be generated by honest
participants (with previous states being the deployment,
downgrade, or attack 1 state and a timestamp difference less
than 9 seconds) or by the UUM adversary (with the previous
state being the downgrade state). The downgrade state refers
to the situation where the blockchain topology and the
timestamp of the latest block meet the attack conditions
of the UUM attack, prompting SUUM to degrade to UUM
and execute its attack strategy. The attack state refers to the
scenario where the blockchain topology and the timestamp
of the latest block satisfy the SUUM attack conditions (i.e.,
the latest block is generated by honest participants with a
timestamp difference of greater than or equal to 9 seconds
from the previous mainchain block).
Regarding state transitions, the deployment state may
transition to the downgrade state due to a timestamp differ-
ence of greater than or equal to 9 seconds in honest blocks,
to the attack 1 state due to the adversary generating and
withholding a block, or remain unchanged due to a times-
tamp difference of less than 9 seconds in honest blocks. The
downgrade state may transition to the deployment state due
to the adversary generating a block with strategic timestamp
setting or a timestamp difference of less than 9 seconds in
honest blocks, or remain in the downgrade state due to a
timestamp difference of greater than or equal to 9 seconds
in honest blocks. Within the attack state, regardless of the
sub - state (withholding or releasing), if the next block
is generated by honest participants, the adversary immedi-
ately releases the withheld block with strategic timestamp
manipulation; if generated by the adversary, the block is
continuously withheld. In both cases, the state ultimately
transitions back to the deployment state. We show the state
transition process of SUUM in Figure 3-(c).
5.3. Reward Analysis
After a detailed analysis of the mechanisms of the
SUUM attack, including its success conditions and minimal
risk success conditions, we focus our attention on the impact
of the SUUM attack on the reward distribution pattern
within blockchain networks. As we observed in our study
of the UUM attack, any attack behavior has the potential
to disrupt the originally fair reward distribution mechanism
designed in blockchain systems, and the SUUM attack is
no exception, with its impact being even more complex and
far-reaching.
Theorem 8 (SUUM Adversary Rewards). The expected
relative share of the mainchain block coin-base reward for
the SUUM adversary increases, while the absolute share
remains unchanged. In contrast, both the expected relative
share and the absolute share of the main chain block coin-
base reward for honest participants will decrease.
Proof of Theorem 8. Based on the analysis of state transi-
tions in the Deployment State, Downgrade State, and Attack
State of SUUM presented in Section 5.2, we calculate the
absolute and relative shares of coin-base rewards for both
the SUUM adversary and honest participants.
The reward analysis for all state transitions is analogous
to that of the UUM attack. Three special cases deserve
attention, corresponding respectively to the transitions from
the Downgrade state to the Deployment state (sixth row) in
Table 2, from the Attack 1 state to the Deployment state
(seventh row), and from the Attack i, i ≥1 state to the
Attack i + 1 state (eighth row).
In the first case, the SUUM adversary PA, while in
the Downgrade state, discovers the next valid block and
publishes it. By carefully setting the timestamp, PA ensures
that the block’s difficulty exceeds that of honest blocks,
causing the attacker’s block to be preferentially selected
by other honest participants. Consequently, PA wins the
fork competition and earns a coin-base reward. The block
generated by the honest participant coalition becomes an
orphan block, prompting a transition to the Attack state
(third row) and necessitating the recall of a pre-paid coin-
base reward intended for honest participants. Therefore, the
reward PH for honest participants corresponding to this state
transition is −1.
In the second case, an honest participant discovers and
publishes a valid block while in the Attack 1 state. Im-
mediately, the SUUM adversary PA releases a withheld
block, carefully setting its timestamp to ensure its difficulty
exceeds that of the honest block. Ultimately, the selfish
player wins the fork competition, rendering the honest block
an orphan, and PA earns a coin-base reward (pre-paid during
the transition from the Deployment state to the Attack 1
state in the first row). The honest player receives no reward
and triggers a transition from the Attack 1 state to the
Deployment state.
In the third case, when the SUUM adversary PA is in
the Attack i, i ≥1 state and discovers the next valid block,
PA withholds it and transitions the current state to the next
state, Attack i + 1. Regardless of subsequent blockchain
evolutions, by meticulously setting the timestamp, PA en-
sures that the withheld block ultimately becomes part of
the main chain. Consequently, PA earns a coin-base reward
while causing a corresponding loss of a coin-base reward
for competing honest participants.
The detailed proof of Theorem 8 can be found in Ap-
pendix I.
6. Comparison
Compared to the RUM attack, the UUM attack signif-
icantly expands the strategic space. The RUM attack em-
phasize risklessness, with relatively strict attack conditions,
whereas the UUM attack allows adversaries to obtain higher
potential rewards while bearing a certain level of risk. This
change is primarily reflected in the relaxation of conditions
during the deployment and execution stages of the UUM
attack, enabling adversaries to initiate attacks under a wider
range of network states. From the perspective of reward
distribution, the UUM attack results in an increase in the
expected relative share of adversaries and a decrease in the
share of honest participants, disrupting the original reward
balance based on fair computing power input.
The SUUM attack further deepens the strategic capabili-
ties of adversaries based on the UUM attack. They introduce
strategies for withholding and releasing blocks, enabling
adversaries to more flexibly respond to dynamic changes
in blockchain networks. In terms of success conditions and
minimal risk success conditions, the SUUM attack involves
more complex block timestamp relationships and phase
judgments, reflecting the high complexity of their attack
strategies. Similar to the UUM attack, the SUUM attack also
alters the reward distribution pattern, benefiting adversaries
while damaging honest participants. However, due to its
more powerful strategic space, the SUUM attack has a
more profound impact on blockchain networks. Next, we
detailedly compare the advantages of these attack methods
in terms of rewards in Theorem 9.
Theorem 9 (Reward Comparison of Uncle Maker-based
Attacks and Honest Mining). SUUM outperforms UUM,
which in turn outperforms RUM, all of which surpass honest
mining.
Proof of Theorem 9. The detailed proof of Theorem 9 can
be found in Appendix J.
The RUM attack maintains a probabilistically negligi-
ble difficulty risk due to its constrained operation, which
inherently limits both its attack surface and potential im-
pact on blockchain difficulty adjustment. In contrast, the
UUM attack’s relaxation of temporal constraints introduces
measurable but bounded difficulty risk, primarily determined
by the Markovian state transition probabilities post-attack.
The SUUM attack exhibits the highest difficulty risk profile,
as its compounded strategy of staggered block release and
timestamp manipulation in both attack and downgrade states
creates non-linear interactions with the difficulty adjustment
algorithm. Next, we use Theorem 10 to elaborate on the
differences in blockchain difficulty risk between these attack
methods and honest mining.
Theorem 10 (Difficulty Risk Comparison of Uncle Mak-
er-based Attacks and Honest Mining). Compared to hon-
est mining, the difficulty risks posed by RUM, UUM, and
SUUM attacks on blockchain difficulty are as follows:
(1) The increased difficulty risk associated with the RUM
attack is denoted by P 
Attack
PA
any t
⇒
Deploy

,
which represents the sum of the instances where a RUM
adversary successfully attacks and drives the Attack
State to transition to the Deployment State..
(2) The increased difficulty risk associated with the UUM
attack is denoted by P 
Attack
PA
any t
⇒
Deploy

,
which represents the sum of the instances where a UUM
adversary successfully attacks and drives the Attack
State to transition to the Deployment State.
(3) The increased difficulty risk associated with SUUM
is denoted by P
 
Downgrade
PA
any t
⇒
Deploy
+Attack 1
PH
any t
⇒
Deploy
!
,
which represents the sum of the instances of two types
of state transitions corresponding to successful attacks
by an SUUM adversary.
Proof of Theorem 10. The detailed proof of Theorem 10
can be found in Appendix K.
Through the preceding theoretical analysis of three types
of Uncle Maker-based attacks, we understand that their
essence lies in maliciously creating uncle blocks to in-
duce forks in the blockchain and meticulously manipulating
timestamps to prioritize the adoption of adversary blocks by
other network participants. Consequently, the magnitude of
the deliberate forking rate serves as a metric for assessing
the severity of Uncle Maker-based attacks. Theorems 9 and
10 compare RUM, UUM, SUUM, and honest mining from
the perspectives of reward and risk, respectively. Intuitively,
as the maliciousness of RUM, UUM, and SUUM increases,
their forking rates should also increase correspondingly. To
streamline our notation, we use PA
S to denote the steady-state
probability of state S when adversary A employs attack A,
and FRA to represent the forking rate induced by attack
A. In the following, we formally present a comparison of
RUM, UUM, SUUM, and honest mining in terms of block
forking rates.
Theorem 11 (Forking Rate Comparison of Uncle Mak-
er-based Attacks and Honest Mining). For an adversary
A with the same computational power, the block forking
rates induced by adopting RUM, UUM, SUUM, and honest
mining satisfy the following relationship:
FRSUUM > FRUUM > FRRUM > FRHM.
(1)
Specifically,
(1) For honest mining, FRHM = 0.
(2) For RUM, FRRUM = PRUM
Attack · PA(t < 9), where
PA(t < 9) represents a scenario where an adversary
A in RUM attack state finds the next block, and the
difference in timestamps between it and its parent block
is less than 9.
(3) For UUM, FRUUM = PUUM
Attack · PA(any t), which
indicates a scenario where an adversary A in the UUM
attack state finds the next block, regardless of the dif-
ference in timestamps between it and its parent block.
(4) For SUUM, FRSUUM
=
PSUUM
Attack + PSUUM
Downgrade ·
PA(any t), which represents the sum of the steady-
state probability of being in the attack state and the
probability of an adversary in the downgrade state
finding the next block, regardless of the difference in
timestamps between it and its parent block.
Figure 4. Steady-state Probability. This figure illustrates the steady-state
probabilities of three different attack strategies as a function of the adver-
sary’s relative power α. Note that we only show the total probability of all
Attack states within the SUUM model.
Proof of Theorem 11. The detailed proof of Theorem 11
can be found in Appendix L.
Next, we focus our attention on the attack cost asso-
ciated with three types of attacks. It is noteworthy that
we characterize the attack cost as the reduction in the
adversary’s block generation probability resulting from an
increase in block difficulty. Prior to the detailed analysis,
we first introduce some additional notations. We denote
µA as the proportion of power controlled by adversary A,
max target as the maximum target value, and AC as the
attack cost.
Subsequently, in Theorem 12, we formally present the
attack cost for these three types of attacks.
Theorem 12 (Cost Comparison of Uncle Maker-based
Attacks). For an adversary A possessing the same relative
power, the attack cost of RUM, UUM, and SUUM satisfy
the following relationship:
ACSUUM = ACUUM ≈ACRUM = 0.
(2)
Specifically,
(1) For RUM, ACRUM = 0.
(2) For UUM or SUUM, ACUUM = ACSUUM = µA ·
D
ph
0
−D
ph
1
max target ≤µA ·
1
2216.35 ≈0.
Proof. The detailed proof of Theorem 12 can be found in
Appendix M.
This result once again implies that attackers can rela-
tively easily carry out UUM and SUUM attacks with almost
no cost risk, thereby further highlighting the severe threats
posed by these two attack strategies to the security of
timestamp-based Nakamoto-style blockchains. Since nearly
cost-free attacks may prompt more attackers to attempt to
exploit these vulnerabilities, undermining the fairness and
stability of the blockchain.
7. Simulated Estimation
To empirically validate the theoretical analysis of the
UUM and SUUM attacks, we conducted extensive simula-
tions under various adversarial power ratios. These simula-
tions aimed to quantify the steady-state probabilities, reward
distributions, difficulty risks, and forking rates associated
(a) RRAttack
(b) RRHonest
Figure 5. Comparison of Relative Rewards under different Mining Strate-
gies. (a) Comparison of Adversary Relative Rewards under Different Min-
ing Strategies. This figure compares the relative reward gains of adversaries
under different mining strategies, illustrating the reward disparities among
the SUUM, UUM, and RUM attack strategies compared to honest mining.
The results demonstrate that SUUM yields the highest rewards, significantly
outperforming UUM and RUM, while all three attack strategies surpass
honest mining in profitability. This outcome confirms that adversaries
can obtain excess rewards by manipulating timestamps and strategically
withholding blocks. (b) Comparison of Honest Participant Relative Rewards
under Different Mining Strategies. This figure presents a comparative
analysis of honest participants’ relative rewards under different mining
strategies. Notably, SUUM exhibits the most severe reward suppression
effect, followed by UUM and RUM, with all three attack strategies
significantly undercutting the baseline rewards achievable through honest
mining. These results quantitatively validate how timestamp manipulation
and strategic block withholding by adversaries systematically disadvantage
honest participants.
with each attack strategy. By comparing these metrics with
honest mining and the baseline RUM attack, we demonstrate
the enhanced profitability and persistence of the proposed
advanced variants. The simulation setup and results are
detailed in the following subsections.
We implemented a discrete-event simulator to model the
Ethereum 1.x blockchain protocol, incorporating the fork
selection rules and difficulty adjustment mechanisms de-
scribed in Section 3. The simulator tracks block generation,
timestamp manipulation, and adversarial strategies under
controlled conditions. Key parameters include:
• Adversarial power ratio α: Varied from 0 to 0.5 in
increments of 0.05.
• Block generation: Modeled as a Poisson process with a
13-second average block time.
• Timestamp constraints: Enforced Ethereum 1.x style
blockchain validity rules.
• Difficulty adjustment: Calculated dynamically based on
block timestamps and parent difficulties.
Each simulation ran for 1,000,000 blocks to ensure
convergence to steady-state behavior, with results averaged
over 10,000 trials to minimize variance. The following
subsections present the findings for each evaluated metric.
7.1. Estimate the Steady-state Probability
To quantitatively analyze the effectiveness of the pro-
posed attack strategies, we estimate the steady-state proba-
bilities of the RUM, UUM, and SUUM attacks under vary-
ing adversarial power ratios. The steady-state probability
reflects the long-term likelihood of the system being in an
attack state, which directly correlates with the adversary’s
ability to sustain the attack and maximize rewards.
As shown in Figure 4, the steady-state probability of
the deployment state increases with the adversary’s power
for RUM and UUM strategies. However, SUUM exhibits
the highest steady-state probability of the deployment state
across higher power levels, followed by UUM and RUM.
This is because SUUM’s ability to withhold and strategi-
cally release blocks expands its attack opportunities, while
UUM’s relaxation of risk-free constraints allows more fre-
quent transitions to the attack state compared to RUM.
The results validate that SUUM’s design achieves su-
perior persistence in maintaining the attack state, enabling
adversaries to exert sustained influence on the blockchain.
This aligns with Theorem 7, where SUUM’s reward advan-
tage stems from its higher steady-state probability of attack
execution. The findings underscore the need for counter-
measures to mitigate such persistent attacks, as discussed in
Section 8.
7.2. Estimate the Relative Reward
To evaluate the economic impact of the proposed attacks,
we analyze the relative rewards obtained by adversaries
and honest participants under RUM, UUM, SUUM, and
honest mining strategies. The relative reward measures the
proportion of total block rewards captured by each party,
reflecting the fairness and security of the blockchain’s in-
centive mechanism.
The relative rewards for adversaries (RRAttack) and
honest participants (RRHonest) are calculated by dividing
their earned rewards by the total system rewards. As shown
in Figure 5, SUUM consistently yields the highest relative
rewards for adversaries, surpassing UUM and RUM across
all power levels. For instance, at α = 0.25, SUUM en-
ables adversaries to capture 33.30% of the rewards, while
UUM and RUM achieve 28.41% and 26.12%, respectively.
This aligns with Theorem 9, where SUUM’s block with-
holding and timestamp manipulation synergistically amplify
rewards. Honest mining, as expected, adheres to the fair
share, serving as the baseline.
Figure 5 demonstrates the corresponding degradation
in honest participants’ rewards under adversarial strategies.
SUUM inflicts the most severe suppression, reducing honest
rewards by up to 11.85% compared to honest mining at
α = 0.3. UUM and RUM exhibit intermediate effects,
with honest rewards declining linearly as α increases. This
inverse relationship between adversarial and honest rewards
confirms the zero-sum nature of reward redistribution in
these attacks.
The death spiral effect of SUUM, emerges from a self-
reinforcing cycle where adversarial rewards come at the
direct expense of honest participants, driving a catastrophic
breakdown of the protocol’s economic model.
(a) MR
(b) FR
Figure 6. Comparison of Minimal Difficulty Risk and Forking Rates under
Different Attack Strategies. (a) Comparison of Minimal Difficulty Risk
under Different Attack Strategies. This figure presents a comparative assess-
ment of the minimal difficulty risk levels associated with different attack
strategies. Honest mining maintains a baseline risk level of zero, while
RUM introduces only minimal difficulty escalation risk. In contrast, UUM
exhibits marginally higher risk due to its less restrictive attack conditions,
and SUUM demonstrates the most significant risk elevation attributable to
its block withholding mechanism. (b) Comparison of Forking Rates under
Different Mining Strategies. This figure presents a comparative analysis of
forking rates under different attack strategies, illustrating the relationship
between the adversary’s relative power and the resultant forking rate. The
results demonstrate that honest mining maintains a zero forking rate due
to strict protocol compliance, while the RUM, UUM, and SUUM attacks
exhibit progressively increasing fork probabilities. This trend originates
from fundamental differences in attack mechanisms.
7.3. Estimate the Minimal Difficulty Risk
The results underscore how SUUM’s advanced strategies
exploit the fork selection rule more effectively than UUM or
RUM. The disproportionate rewards stem from two factors:
• Timestamp Manipulation: Adversaries artificially inflate
their block difficulty (Section 4.1), increasing mainchain
inclusion.
• Block Withholding: Delayed releases (Section 5.1) dis-
rupt honest miners’ progress, compounding rewards over
time.
This analysis quantifies the economic incentives driving
Uncle Maker attacks, emphasizing the urgency of mitiga-
tions (Section 8) to restore reward fairness. The significant
reward gaps shown in Figure 5 further motivate our pro-
posed countermeasures, such as timestamp verification and
difficulty algorithm adjustments.
A critical aspect of Uncle Maker attacks is their im-
pact on blockchain difficulty, which influences long-term
network stability. Here, we evaluate the minimal difficulty
risk-the least additional risk imposed on the blockchain’s
difficulty adjustment mechanism by each attack strategy.
This metric reflects how subtly adversaries can execute
attacks without destabilizing the network.
The minimal difficulty risk is quantified as MR =
DAttack −DHonest, where DAttack and DHonest represent
the difficulty of adversarial and honest blocks at the same
highest height. Results are averaged across 10,000 trials to
ensure statistical robustness.
Figure 6 reveals distinct risk profiles for each strategy.
Honest Mining maintains a baseline risk of zero, as no
difficulty manipulation occurs. RUM introduces negligible
risk, as its strict timestamp constraints (Theorem 3) limit
difficulty fluctuations. UUM exhibits marginally higher risk
due to relaxed initiation conditions (Theorem 1), allowing
occasional difficulty spikes. SUUM poses the highest risk,
as its block withholding strategy (Section 5.1) disrupts dif-
ficulty adjustment continuity. We further heuristically find
three observations:
• Low Difficulty Risk Attacks: All strategies induce sub-
0.21 difficulty risk, confirming that Uncle Maker attacks
are low difficulty risk.
• Trade-off with Profitability: SUUM’s higher risk aligns
with its superior rewards (Section 7), demonstrating a
risk-reward balance.
• Network Stability: Even SUUM’s maximal risk remains
manageable (e.g., < 0.21 at α = 0.37), explaining why
such attacks could persist undetected in practice.
Crucially, SUUM’s minimal difficulty risk allows this
death spiral to proceed undetected, as the attack remains
cost-free (Theorem 12). By calibrating timestamps to 1-
second granularity (Section 5.1), adversaries avoid trigger-
ing difficulty spikes that would otherwise penalize their
mining efficiency. This stealth enables sustained reward
extraction, as seen in Figure 5-(b). The result is a low-risk,
high-reward environment that incentivizes even moderate
power miners to defect, amplifying the spiral.
7.4. Estimate the Forking Rate
SUUM’s elevated forking rate directly correlates with
honest reward suppression in Figure 5-(b). Each fork in-
validates honest blocks, reducing their effective hash power
contribution and further discouraging participation. This cre-
ates a vicious cycle: higher forking →fewer honest blocks
→lower incentives →more miners abandon honesty, as
reflected in the steep decline of honest relative rewards for
SUUM compared to UUM/RUM.
We simulate RUM, UUM, SUUM, and honest mining
over 1,000,000 blocks, measuring the forking rate (FR),
where the results are averaged across 10,000 trials, with
adversarial power α varying from 0 to 0.5. We note that
the forking rate is defined as the number of intentionally
induced forks divided by the total number of blocks mined
in the system.
Figure 6 highlights stark contrasts in forking behavior.
Honest Mining maintains a 0% forking rate, as all partic-
ipants adhere to the canonical chain. RUM triggers occa-
sional forks, occurring only when adversaries mine blocks
with timestamps t < 9 (Theorem 11). UUM exhibits higher
fork rates, as its relaxed constraints (Section 4.1) permit
more frequent adversarial interventions. SUUM maximizes
forks by combining withheld block releases (Section 5.1)
and timestamp manipulation, amplifying chain reorganiza-
tions.
The death spiral effec underscores SUUM’s unique
threat: unlike prior attacks, it does not merely increase
adversarial rewards but systematically erodes the incentive
for honest participation, leading to irreversible protocol col-
lapse. The combination of cost-free persistence (Theorem
12), recursive timestamp manipulation, and cascading re-
organizations creates a feedback loop that accelerates as
more miners defect. This highlights the urgent need for
mitigations that break this cycle (Section 8), to restore
honest miners’ incentives and prevent systemic failure.
8. Discussion
We now analyze the essence of the Uncle Maker attack
and propose some mitigation measures to effectively prevent
the Uncle Maker Attack and Its Advanced Variants. These
measures mainly focus on adjusting the consensus mech-
anism and incentive mechanism of the blockchain, aiming
to reduce the profit space of adversaries and enhance the
security and fairness of the blockchain system. The details
can be found in Appendix N.
9. Conclusion
This
study
demonstrates
that
timestamp-based
Nakamoto-style blockchains, particularly Ethereum 1.x
derivatives, face existential threats from the SUUM attack.
Unlike
transient
adversarial
strategies,
SUUM
inflicts
permanent systemic damage by irreversibly distorting the
protocol’s incentive structure through three synergistic
mechanisms:
(1)
precision
timestamp
manipulation
to
inflate
adversarial
difficulty
advantages,
(2)
strategic
block withholding to amplify chain reorganizations, and
(3) granular difficulty risk control to ensure cost-free
sustainability. These mechanisms create a self-reinforcing
cycle:
adversarial
rewards
scale
super-linearly
(e.g.,
achieving 43.7% rewards at α
=
0.4), while honest
participants face diminishing returns (11.85% loss at
α = 0.3), ultimately incentivizing rational miners to defect
and accelerating protocol collapse.
Our large-scale simulations (1M blocks, 10K trials) val-
idate SUUM’s dominance over prior attacks. SUUM adver-
saries achieve a 33.30% reward share at α = 0.25, surpass-
ing UUM (28.41%) and RUM (26.12%), while inducing
higher forking rates (3.2% vs. UUM’s 2.1% and RUM’s
1.4%). Crucially, SUUM bypasses traditional constraints
like hash power thresholds by exploiting timestamp cali-
bration, maintaining minimal difficulty escalation (maximal
risk: 0.21) despite sustained exploitation. This asymmetric
advantage stems from the protocol’s inability to self-correct
reward distortions, leading to a death spiral where adver-
sarial coalitions dominate and honest participation becomes
economically untenable.
Future work must prioritize protocol redesigns that de-
couple difficulty adjustments from adversarial timestamp
control and introduce economic penalties for abnormal block
intervals. This work underscores the urgent need to re-
think consensus layer security assumptions in timestamp-
dependent systems, balancing incentive compatibility with
adversarial resilience in next generation blockchain designs.
References
[1]
C. Dwork and M. Naor, “Pricing via processing or combatting junk
mail,” in Proceedings of the 12th Annual International Cryptology
Conference on Advances in Cryptology, ser. CRYPTO ’92.
Berlin,
Heidelberg: Springer-Verlag, 1992, p. 139–147.
[2]
M. Jakobsson and A. Juels, “Proofs of work and bread pudding
protocols,” in Proceedings of the IFIP TC6/TC11 Joint Working
Conference on Secure Information Networks: Communications and
Multimedia Security, ser. CMS ’99.
NLD: Kluwer, B.V., 1999, p.
258–272.
[3]
S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” 2009.
[4]
V.
Buterin,
“Ethereum
whitepaper,”
2024,
https://ethereum.org/
whitepaper/.
[5]
——, “A next-generation smart contract and decentralized application
platform,” 2014.
[6]
coinmarketcap.com, “Cryptocurrency market capitalizations,” (2024),
https://coinmarketcap.com/.
[7]
R. Zhang and B. Preneel, “Lay down the common metrics: Eval-
uating proof-of-work consensus protocols’ security,” in 2019 IEEE
Symposium on Security and Privacy (SP), 2019, pp. 175–192.
[8]
Y. Lewenberg, Y. Sompolinsky, and A. Zohar, “Inclusive block chain
protocols,” in Financial Cryptography and Data Security: 19th Inter-
national Conference, FC 2015, San Juan, Puerto Rico, January 26-
30, 2015, Revised Selected Papers 19.
Berlin, Heidelberg: Springer,
2015, pp. 528–547, https://doi.org/10.1007/978-3-662-47854-7 33.
[9]
R.
Pass
and
E.
Shi,
“Fruitchains:
A
fair
blockchain,”
in
Proceedings of the ACM Symposium on Principles of Distributed
Computing, ser. PODC ’17.
New York, NY, USA: Association
for Computing Machinery, 2017, p. 315–324. [Online]. Available:
https://doi.org/10.1145/3087801.3087809
[10] R. Pass and E. Shi, “Hybrid Consensus: Efficient Consensus
in the Permissionless Model,” in 31st International Symposium
on Distributed Computing (DISC 2017), ser. Leibniz International
Proceedings in Informatics (LIPIcs), A. Richa, Ed., vol. 91. Dagstuhl,
Germany: Schloss Dagstuhl – Leibniz-Zentrum f¨ur Informatik, 2017,
pp. 39:1–39:16. [Online]. Available: https://drops-dev.dagstuhl.de/
entities/document/10.4230/LIPIcs.DISC.2017.39
[11] I. Eyal, A. E. Gencer, E. G. Sirer, and R. Van Renesse, “Bitcoin-ng:
a scalable blockchain protocol,” in Proceedings of the 13th Usenix
Conference on Networked Systems Design and Implementation, ser.
NSDI’16.
USA: USENIX Association, 2016, p. 45–59.
[12] J. Wang and H. Wang, “Monoxide: Scale out blockchains with
asynchronous consensus zones,” in 16th USENIX Symposium on Net-
worked Systems Design and Implementation (NSDI 19). Boston, MA:
USENIX Association, Feb. 2019, pp. 95–112. [Online]. Available:
https://www.usenix.org/conference/nsdi19/presentation/wang-jiaping
[13] J. Katz and Y. Lindell, Introduction to Modern Cryptography, Second
Edition, 2nd ed.
Chapman & Hall/CRC, 2014.
[14] A. E. K. R. Bowden, H. P. Keeler and P. G. Taylor, “Modeling and
analysis of block arrival times in the bitcoin blockchain,” Stochastic
Models, vol. 36, no. 4, pp. 602–637, 2020. [Online]. Available:
https://doi.org/10.1080/15326349.2020.1786404
[15] Y. Sompolinsky and A. Zohar, “Secure high-rate transaction pro-
cessing in bitcoin,” in Financial Cryptography and Data Security,
R. B¨ohme and T. Okamoto, Eds. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2015, pp. 507–527.
[16] A.
Yaish,
S.
Tochner, and
A. Zohar,
“Blockchain
stretching
&
squeezing:
Manipulating
time
for
your
best
interest,”
in
Proceedings of the 23rd ACM Conference on Economics and
Computation, ser. EC ’22.
New York, NY, USA: Association
for Computing Machinery, 2022, p. 65–88. [Online]. Available:
https://doi.org/10.1145/3490486.3538250
[17] C. Li, P. Li, D. Zhou, Z. Yang, M. Wu, G. Yang, W. Xu, F. Long, and
A. C.-C. Yao, “A decentralized blockchain with high throughput and
fast confirmation,” in Proceedings of the 2020 USENIX Conference on
Usenix Annual Technical Conference, ser. USENIX ATC’20.
USA:
USENIX Association, 2020.
[18] C. Li, P. Li, D. Zhou, W. Xu, F. Long, and A. Yao, “Scaling
nakamoto consensus to thousands of transactions per second,” 2018.
[Online]. Available: https://arxiv.org/abs/1805.03870
[19] H. Yu, I. Nikoli´c, R. Hou, and P. Saxena, “Ohie: Blockchain scaling
made simple,” in 2020 IEEE Symposium on Security and Privacy
(SP), 2020, pp. 90–105.
[20] Y. Sompolinsky, S. Wyborski, and A. Zohar, “Phantom ghostdag: a
scalable generalization of nakamoto consensus,” in Proceedings of
the 3rd ACM Conference on Advances in Financial Technologies,
ser. AFT ’21.
New York, NY, USA: Association for Computing
Machinery, 2021, p. 57–70. [Online]. Available: https://doi.org/10.
1145/3479722.3480990
[21] E. PoW, “Ethereum pow,” (2024), https://ethereumpow.org/.
[22] E. Fair, “Ethereum fair,” (2024), https://etherfair.org/.
[23] E. Classic, “Ethereum classic,” (2024), https://ethereumclassic.org/.
[24] Miningpoolstats, “Mining pool stats,” (2024), https://miningpoolstats.
stream/.
[25] S. Fork, “Fork,” 2024. [Online]. Available: https://en.wikipedia.org/
wiki/Fork (blockchain)
[26] D. Meshkov, A. Chepurnoy, and M. Jansen, “Short paper: Revisiting
difficulty control for blockchain systems,” in Data Privacy Manage-
ment, Cryptocurrencies and Blockchain Technology, J. Garcia-Alfaro,
G. Navarro-Arribas, H. Hartenstein, and J. Herrera-Joancomart´ı, Eds.
Cham: Springer International Publishing, 2017, pp. 429–436.
[27] P. Katsiampa, S. Corbet, and B. Lucey, “High frequency volatility
co-movements in cryptocurrency markets,” Journal of International
Financial Markets, Institutions and Money, vol. 62, pp. 35–52,
2019. [Online]. Available: https://www.sciencedirect.com/science/
article/pii/S104244311930023X
[28] A. Yaish and A. Zohar, “Correct Cryptocurrency ASIC Pricing: Are
Miners Overpaying?” in 5th Conference on Advances in Financial
Technologies (AFT 2023), ser. Leibniz International Proceedings in
Informatics (LIPIcs), J. Bonneau and S. M. Weinberg, Eds., vol.
282.
Dagstuhl, Germany: Schloss Dagstuhl – Leibniz-Zentrum
f¨ur Informatik, 2023, pp. 2:1–2:25. [Online]. Available: https:
//drops.dagstuhl.de/entities/document/10.4230/LIPIcs.AFT.2023.2
[29] G. Goren and A. Spiegelman, “Mind the mining,” in Proceedings
of the 2019 ACM Conference on Economics and Computation,
ser. EC ’19.
New York, NY, USA: Association for Computing
Machinery, 2019, p. 475–487. [Online]. Available: https://doi.org/10.
1145/3328526.3329566
[30] A. Fiat, A. Karlin, E. Koutsoupias, and C. Papadimitriou, “Energy
equilibria in proof-of-work mining,” in Proceedings of the 2019 ACM
Conference on Economics and Computation, ser. EC ’19. New York,
NY, USA: Association for Computing Machinery, 2019, p. 489–502.
[Online]. Available: https://doi.org/10.1145/3328526.3329630
[31] D. I. Ilie, S. M. Werner, I. D. Stewart, and W. J. Knottenbelt,
“Unstable throughput: When the difficulty algorithm breaks,” in 2021
IEEE International Conference on Blockchain and Cryptocurrency
(ICBC), 2021, pp. 1–5.
[32] satofishi, “I can’t stop appreciate this elegant implementation of
whatwe’ve done over the past two years,” 2024. [Online]. Available:
https://twitter.com/satofishi/status/1556518282383036416
[33] ——, “We respect the consensus as is,” 2024. [Online]. Available:
https://twitter.com/satofishi/status/1556510404116889600
[34] I. Eyal and E. G. Sirer, “Majority is not enough: bitcoin mining is
vulnerable,” Commun. ACM, vol. 61, no. 7, p. 95–102, Jun. 2018.
[Online]. Available: https://doi.org/10.1145/3212998
[35] BitInfoCharts, “Bitcoin, ethereum, dogecoin, xrp, ethereum clas
sic, litecoin, monero, bitcoin cash, zcash, bitcoin gold hashrate
historical chart.” 2024. [Online]. Available: https://web.archive.
org/web/20220522122528/https://bitinfocharts.com/comparison/
hashrate-btc-eth-doge-xrp-etc-ltc-xmr-bch-zec-btg.html#3y)
[36] A. Gervais, G. O. Karame, K. W¨ust, V. Glykantzis, H. Ritzdorf,
and S. Capkun, “On the security and performance of proof of work
blockchains,” in Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, ser. CCS ’16.
New
York, NY, USA: Association for Computing Machinery, 2016, p.
3–16. [Online]. Available: https://doi.org/10.1145/2976749.2978341
[37] S.
Azouvi
and
A.
Hicks,
“Sok:
Tools
for
Game
Theoretic
Models
of
Security
for
Cryptocurrencies,”
Cryptoeconomic
Systems,
vol.
0,
no.
1,
apr
5
2021,
https://cryptoeconomicsystems.pubpub.org/pub/azouvi-sok-security.
[38] J. Bonneau, A. Miller, J. Clark, A. Narayanan, J. A. Kroll, and E. W.
Felten, “Sok: Research perspectives and challenges for bitcoin and
cryptocurrencies,” in 2015 IEEE Symposium on Security and Privacy,
2015, pp. 104–121.
[39] A. Yaish, G. Stern, and A. Zohar, “Uncle maker:(time) stamping
out the competition in ethereum,” in Proceedings of the 2023 ACM
SIGSAC Conference on Computer and Communications Security,
2023, pp. 135–149.
[40] A. Sapirshtein, Y. Sompolinsky, and A. Zohar, “Optimal selfish
mining strategies in bitcoin,” in Financial Cryptography and Data
Security, J. Grossklags and B. Preneel, Eds.
Berlin, Heidelberg:
Springer Berlin Heidelberg, 2017, pp. 515–532.
[41] Z. Wang, J. Liu, Q. Wu, Y. Zhang, H. Yu, and Z. Zhou,
“An
analytic
evaluation
for
the
impact
of
uncle
blocks
by
selfish and stubborn mining in an imperfect ethereum network,”
Comput. Secur., vol. 87, no. C, Nov. 2019. [Online]. Available:
https://doi.org/10.1016/j.cose.2019.101581
[42] I. Eyal, “The miner’s dilemma,” in Proceedings of the 2015
IEEE Symposium on Security and Privacy, ser. SP ’15.
USA:
IEEE Computer Society, 2015, p. 89–103. [Online]. Available:
https://doi.org/10.1109/SP.2015.13
[43] Y. Kwon, D. Kim, Y. Son, E. Vasserman, and Y. Kim, “Be
selfish and avoid dilemmas: Fork after withholding (faw) attacks on
bitcoin,” in Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, ser. CCS ’17.
New York,
NY, USA: Association for Computing Machinery, 2017, p. 195–209.
[Online]. Available: https://doi.org/10.1145/3133956.3134019
[44] N. T. Courtois and L. Bahack, “On subversive miner strategies and
block withholding attack in bitcoin digital currency,” CoRR, vol.
abs/1402.1718, 2014. [Online]. Available: http://arxiv.org/abs/1402.
1718
[45] I. Tsabary and I. Eyal, “The gap game,” in Proceedings of
the 11th ACM International Systems and Storage Conference,
ser.
SYSTOR
’18.
New
York,
NY,
USA:
Association
for
Computing Machinery, 2018, p. 132. [Online]. Available: https:
//doi.org/10.1145/3211890.3211905
[46] C. Feng and J. Niu, “Selfish mining in ethereum,” in 2019 IEEE
39th International Conference on Distributed Computing Systems
(ICDCS), 2019, pp. 1306–1316.
[47] K. Nayak, S. Kumar, A. Miller, and E. Shi, “Stubborn mining: Gener-
alizing selfish mining and combining with an eclipse attack,” in 2016
IEEE European Symposium on Security and Privacy (EuroS&P),
2016, pp. 305–320.
[48] A. Judmayer, N. Stifter, A. Zamyatin, I. Tsabary, I. Eyal, P. Gaˇzi,
S. Meiklejohn, and E. Weippl, “Pay to win: Cheap, cross-chain
bribing attacks on pow cryptocurrencies,” in Financial Cryptography
and Data Security. FC 2021 International Workshops, M. Bernhard,
A. Bracciali, L. Gudgeon, T. Haines, A. Klages-Mundt, S. Matsuo,
D. Perez, M. Sala, and S. Werner, Eds.
Berlin, Heidelberg: Springer
Berlin Heidelberg, 2021, pp. 533–549.
[49] J. Bonneau, “Why buy when you can rent?” in Financial Cryp-
tography and Data Security, J. Clark, S. Meiklejohn, P. Y. Ryan,
D. Wallach, M. Brenner, and K. Rohloff, Eds.
Berlin, Heidelberg:
Springer Berlin Heidelberg, 2016, pp. 19–26.
[50] S. Gao, Z. Li, Z. Peng, and B. Xiao, “Power adjusting and
bribery racing: Novel mining attacks in the bitcoin system,” in
Proceedings of the 2019 ACM SIGSAC Conference on Computer
and Communications Security, ser. CCS ’19.
New York, NY, USA:
Association for Computing Machinery, 2019, p. 833–850. [Online].
Available: https://doi.org/10.1145/3319535.3354203
[51] Z. Yang, C. Yin, J. Ke, T. T. A. Dinh, and J. Zhou, “If you
can’t beat them, pay them: Bitcoin protection racket is profitable,”
in Proceedings of the 38th Annual Computer Security Applications
Conference, ser. ACSAC ’22.
New York, NY, USA: Association
for Computing Machinery, 2022, p. 727–741. [Online]. Available:
https://doi.org/10.1145/3564625.3567983
[52] D. Karakostas, A. Kiayias, and T. Zacharias, “Blockchain bribing
attacks and the efficacy of counterincentives,” 2024. [Online].
Available: https://arxiv.org/abs/2402.06352
[53] A.
Yaish,
M.
Dotan,
K.
Qin,
A.
Zohar,
and
A.
Gervais,
“Suboptimality in defi,” Cryptology ePrint Archive, Paper 2023/892,
2023. [Online]. Available: https://eprint.iacr.org/2023/892
[54] L. Zhou, X. Xiong, J. Ernstberger, S. Chaliasos, Z. Wang, Y. Wang,
K. Qin, R. Wattenhofer, D. Song, and A. Gervais, “Sok: Decentralized
finance (defi) attacks,” in 2023 IEEE Symposium on Security and
Privacy (SP), 2023, pp. 2444–2461.
[55] M. Mirkin, Y. Ji, J. Pang, A. Klages-Mundt, I. Eyal, and A. Juels,
“Bdos: Blockchain denial-of-service,” in Proceedings of the 2020
ACM
SIGSAC
Conference
on
Computer
and
Communications
Security, ser. CCS ’20.
New York, NY, USA: Association for
Computing Machinery, 2020, p. 601–619. [Online]. Available:
https://doi.org/10.1145/3372297.3417247
[56] Q. Wang, C. Li, T. Xia, Y. Ren, D. Wang, G. Zhang, and K.-K. R.
Choo, “Optimal selfish mining-based denial-of-service attack,” IEEE
Transactions on Information Forensics and Security, vol. 19, pp. 835–
850, 2024.
[57] Q. Wang, T. Xia, D. Wang, Y. Ren, G. Miao, and K.-K. R. Choo,
“Sdos: Selfish mining-based denial-of-service attack,” IEEE Transac-
tions on Information Forensics and Security, vol. 17, pp. 3335–3349,
2022.
[58] K. Li, Y. Wang, and Y. Tang, “Deter: Denial of ethereum txpool
services,” in Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security, ser. CCS ’21.
New
York, NY, USA: Association for Computing Machinery, 2021,
p. 1645–1667. [Online]. Available: https://doi.org/10.1145/3460120.
3485369
[59] M.
Zhang,
R.
Li,
and
S.
Duan,
“Max
attestation
matters:
Making
honest
parties
lose
their
incentives
in
ethereum
PoS,” in 33rd USENIX Security Symposium (USENIX Security
24).
Philadelphia, PA: USENIX Association, Aug. 2024, pp.
6255–6272. [Online]. Available: https://www.usenix.org/conference/
usenixsecurity24/presentation/zhang-mingfei
[60] J. Neu, E. N. Tas, and D. Tse, “Ebb-and-flow protocols: A resolution
of the availability-finality dilemma,” in 2021 IEEE Symposium on
Security and Privacy (SP), 2021, pp. 446–465.
[61] E. N. T. Joachim Neu and D. Tse, “Two attacks on proof-of-stake
ghost/ethereum,” 2022. [Online]. Available: https://arxiv.org/abs/
2203.01315
[62] M.
Neuder,
D.
J.
Moroz,
R.
Rao,
and
D.
C.
Parkes,
“Selfish
behavior
in
the
tezos
proof-of-stake
protocol,”
Cryptoeconomic
Systems,
vol.
0,
no.
1,
apr
5
2021,
https://cryptoeconomicsystems.pubpub.org/pub/neuder-selfish-
behavior-tezos.
[63] J. Brown-Cohen, A. Narayanan, A. Psomas, and S. M. Weinberg,
“Formal barriers to longest-chain proof-of-stake protocols,” in
Proceedings of the 2019 ACM Conference on Economics and
Computation, ser. EC ’19.
New York, NY, USA: Association
for Computing Machinery, 2019, p. 459–473. [Online]. Available:
https://doi.org/10.1145/3328526.3329567
[64] A. Kiayias, A. Russell, B. David, and R. Oliynykov, “Ouroboros: A
provably secure proof-of-stake blockchain protocol,” in 2019 IEEE
Symposium on Security and Privacy.
San Francisco, CA, USA:
IEEE, 2017, pp. 157–174, https://doi.org/10.1109/SP.2019.00063.
[65] W. Li, S. Andreina, J.-M. Bohli, and G. Karame, “Securing
proof-of-stake blockchain protocols,” in Data Privacy Manage-
ment, Cryptocurrencies and Blockchain Technology, J. Garcia-Alfaro,
G. Navarro-Arribas, H. Hartenstein, and J. Herrera-Joancomart´ı, Eds.
Cham: Springer International Publishing, 2017, pp. 297–315.
[66] B. Yee, “Keep your transactions on short leashes,” 2022. [Online].
Available: https://arxiv.org/abs/2206.11974
[67] S. Azouvi and M. Vukoli´c, “Pikachu: Securing pos blockchains from
long-range attacks by checkpointing into bitcoin pow using taproot,”
in Proceedings of the 2022 ACM Workshop on Developments
in Consensus, ser. ConsensusDay ’22.
New York, NY, USA:
Association for Computing Machinery, 2022, p. 53–65. [Online].
Available: https://doi.org/10.1145/3560829.3563563
[68] F. Luo, H. Lin, Z. Li, X. Luo, R. Luo, Z. He, S. Song, T. Chen, and
W. Luo, “Towards automatic discovery of denial-of-service weak-
nesses in blockchain resource models,” in Proceedings of the 31st
ACM Conference on Computer and Communications Security (CCS),
Oct. 2024, aCM Conference on Computer and Communications Se-
curity (CCS 2024) ; Conference date: 14-10-2024.
[69] Y. Wang, Y. Tang, K. Li, W. Ding, and Z. Yang, “Understanding
ethereum mempool security under asymmetric DoS by symbolized
stateful fuzzing,” in 33rd USENIX Security Symposium (USENIX
Security 24). Philadelphia, PA: USENIX Association, Aug. 2024, pp.
4747–4764. [Online]. Available: https://www.usenix.org/conference/
usenixsecurity24/presentation/wang-yibo
[70] A. Yaish, K. Qin, L. Zhou, A. Zohar, and A. Gervais, “Speculative
Denial-of-Service attacks in ethereum,” in 33rd USENIX Security
Symposium (USENIX Security 24).
Philadelphia, PA: USENIX
Association, Aug. 2024, pp. 3531–3548. [Online]. Available: https:
//www.usenix.org/conference/usenixsecurity24/presentation/yaish
[71] C. Schwarz-Schilling, J. Neu, B. Monnot, A. Asgaonkar, E. N. Tas,
and D. Tse, “Three attacks on proof-of-stake ethereum,” in Financial
Cryptography and Data Security, I. Eyal and J. Garay, Eds.
Cham:
Springer International Publishing, 2022, pp. 560–576.
[72] N. Ruaro, F. Gritti, R. McLaughlin, I. Grishchenko, C. Kruegel, and
G. Vigna, “Not your type! detecting storage collision vulnerabilities
in ethereum smart contracts,” in 31st Annual Network and Distributed
System Security Symposium, NDSS 2024, San Diego, California, USA,
February 26 - March 1, 2024.
The Internet Society, 2024.
[73] W.
Zhang,
Z.
Zhang,
Q.
Shi,
L.
Liu,
L.
Wei,
Y.
Liu,
X. Zhang, and S. Cheung, “Nyx: Detecting exploitable front-
running vulnerabilities in smart contracts,” in IEEE Symposium on
Security and Privacy, SP 2024, San Francisco, CA, USA, May
19-23, 2024.
IEEE, 2024, pp. 2198–2216. [Online]. Available:
https://doi.org/10.1109/SP54263.2024.00146
[74] C. Sendner, L. Petzi, J. Stang, and A. Dmitrienko, “Large-scale
study of vulnerability scanners for ethereum smart contracts,”
in 2024 IEEE Symposium on Security and Privacy (SP).
Los
Alamitos, CA, USA: IEEE Computer Society, May 2024, pp.
2273–2290. [Online]. Available: https://doi.ieeecomputersociety.org/
10.1109/SP54263.2024.00230
[75] Z. He, Z. Li, A. Qiao, X. Luo, X. Zhang, T. Chen, S. Song, D. Liu, and
W. Niu, “Nurgle: Exacerbating resource consumption in blockchain
state storage via mpt manipulation,” in 2024 IEEE Symposium on
Security and Privacy (SP), 2024, pp. 2180–2197.
Appendix A.
Related Work
We now embark on a discussion concerning the related
work of this paper, primarily focusing on three aspects:
attacks targeting vulnerabilities in incentive models and con-
sensus protocols of Nakamoto-like blockchains, Ethereum
2.0-like blockchains, and other facets.
A.1. Attacks on Incentive Model and Consensus
Protocol of Nakamoto-like Blockchains
Withholding Attack. In Nakamoto-like blockchains, With-
holding Attack represents a prevalent malicious behavior
[34], [40], [41], [42], [43], [44], [45], [46]. Most consensus-
layer attacks rely on block withholding and specific capa-
bilities of the attacker, exemplified by the Selfish Mining
attack, where the adversary withholds blocks and strategi-
cally chooses the timing of their release to increase their
share of blocks. Variants such as Stubborn Mining attacks
involve the adversary continuing to mine even when their
selfish fork lags behind the honest chain [41], [47]. These
attacks undermine the fairness and normal operation of
blockchain networks. By impeding the timely dissemination
of certain blocks, adversaries attempt to control the pace
of block generation within the network and disrupt the
normal functioning of honest nodes. This not only results
in the potential waste of computing power and resources
of honest nodes but also complicates and destabilizes the
network’s fork situation, reducing its security and reliability.
Consequently, user trust in Nakamoto-like blockchains is
eroded, exerting a negative impact on the entire blockchain
ecosystem.
Bribing Attack. In Nakamoto-like blockchains, the Bribing
Attack poses a severe threat to network security and stability
[48], [49], [50], [51], [52]. First described by Bonneau,
this type of attack encompasses multiple mechanisms. Early
research indicated that bribery attacks may intensify when
participants rely solely on transaction fees for compensation.
For instance, bribery attacks implemented through smart
contracts exhibit ”inbound” and ”outbound” modes, with
subsequent research continuously enhancing their efficiency,
such as through cross-system double-spending conspiracies
or leveraging smart contract payments. The motives for
these attacks are diverse, including double-spending, con-
sensus disruption, censorship, transaction front-running, or
the sabotage of hash-time locked contracts (HTLCs) [53],
[54]. Recent research has proposed bribery attack models
targeting longest-chain blockchains (such as Bitcoin), with
some assuming a dichotomy between honest and rationally
bribe-accepting participants, employing ”inbound” bribery
(paid in native tokens). Other models may be more general,
considering rationality on all sides, with ”outbound” bribery
(e.g., paid in USD) unaffected by token price fluctuations.
These attacks significantly disrupt the normal operational
order of blockchains.
DoS attack. In Nakamoto-like blockchains, Denial of Ser-
vice (DoS) attacks primarily disrupt system availability by
consuming network resources [55], [56], [57], [58]. At
the network layer, adversaries often launch traffic flooding
attacks, such as sending a massive number of false re-
quests or packets to target nodes, rapidly consuming network
bandwidth and causing nodes to become overwhelmed with
processing these invalid flows, thereby preventing them from
timely responding to legitimate transactions. For example,
a deluge of spam transaction requests can clog network
channels, hindering the smooth propagation and process-
ing of normal transactions. Such attacks significantly in-
terfere with the normal operation of blockchain networks,
increasing transaction confirmation times and reducing sys-
tem efficiency. They undermine the decentralized feature of
blockchain, as nodes under attack are unable to participate
equally in network activities. Furthermore, DoS attacks may
trigger a chain reaction, affecting users’ trust in blockchain
and impeding its application and development across various
domains.
Timestamp Attack. In Nakamoto-like blockchains, Times-
tamp Manipulation Attacks exploit the configurable feature
of block timestamps, allowing adversaries to meticulously
set timestamps that may interfere with the normal generation
and confirmation processes of blocks [16]. For instance,
adversaries can manipulate mining difficulty adjustments by
setting unreasonable timestamps, thereby impacting their
mining rewards or network stability. This attack vector
potentially undermines the fairness and normal operational
order of blockchain, granting adversaries undue advantages
and posing a latent threat to the security and reliability of
Nakamoto-like blockchains. Some research has addressed
the role of timestamps in attacks, such as in Ethereum where
timestamps were used to attack smart contracts. However,
there is limited research on timestamp attacks at the consen-
sus layer. Stretch identified two timestamp vulnerabilities in
the geth codebase, one of which could be used to reduce
honest mining difficulty, but did not delve into the impact
on consensus mechanisms.
It is worth mention that the UUM attack proposed in
our paper falls within the category of timestamp attacks,
while SUUM combines withholding attacks with timestamp
attacks.
A.2. Attacks on Incentive Model and Consensus
Protocol of Ethereum 2.0-like Blockchains
Withholding
Attack.
In
Ethereum
2.0-like
PoS
blockchains, the Withholding Attack poses a threat to
network stability. An adversary may withhold blocks to
prevent honest nodes from propagating them, releasing the
withheld blocks at an opportune moment to gain undue
benefits [59], [60], [61], [62]. This attack resembles the
withholding attack observed in Nakamoto-style blockchains
but exhibits distinct characteristics due to the unique
protocol mechanisms of Ethereum 2.0 PoS. For instance,
adversaries can exploit the staking and voting mechanisms
of validator nodes to disrupt the normal block confirmation
process during consensus. By withholding blocks they
have mined or validated, they can influence the block
height and fork conditions within the network, thereby
undermining
network
consistency
and
certainty.
Such
attacks may result in wasted efforts by honest nodes,
increase network uncertainty, and diminish user trust in
the network. Furthermore, they may afford the adversary
an advantageous position in subsequent block competitions
or network decisions, thereby impacting the fairness and
security of the entire Ethereum 2.0-like blockchain network.
Nothing-at-stake
Attack.
In
Ethereum
2.0-like
PoS
blockchains, the Nothing-at-Stake Attack represents a severe
threat to network activity and performance [63], [64], [65].
Due to the characteristics of the staking distribution and
validation mechanisms within the PoS system, adversaries
can exploit this vulnerability to contribute effortlessly to
multiple forks. Without bearing any actual risk, adversaries
can interfere with the normal transaction confirmation and
block production processes by operating on different forks.
This leads to a chaotic situation of network forks, making it
difficult for the system to achieve a unified consensus and
reducing the network’s efficiency in processing transactions.
For example, under normal circumstances, validators should
choose to support a single correct fork based on their
own staking and network rules. However, adversaries can
freely stake on multiple forks, disrupting the stability and
reliability of the network. This, in turn, affects users’ trust
in the Ethereum 2.0-like blockchain network, hinders its
normal development, and has a negative impact on the entire
blockchain ecosystem.
Long-range Attack. The Long-Range Attack is a potential
threat to Ethereum 2.0-like PoS blockchains, exploiting a
vulnerability in the PoS mechanism where adversaries can
secretly construct an alternative chain starting from an ear-
lier point in the blockchain history [64], [66], [67]. This
attack is named for the adversaries’ ability to backtrack to a
”long-range” past point in the blockchain without significant
resource consumption and initiate a new chain from there. If
successful, the previous transaction records and states of the
network will become untrusted, undermining the consistency
principle of blockchain data. For instance, adversaries can
alter transaction information in past blocks, reverse com-
pleted transaction states, or create new transactions out of
thin air, severely disrupting the normal operational order
of the network. This attack leverages potential flaws in
Ethereum 2.0-like PoS mechanism in managing historical
data, dealing a severe blow to the trust foundation of the
entire blockchain ecosystem. It may spark user concerns
about network security, thereby impacting the widespread
adoption and sustainable development of Ethereum 2.0-like
PoS blockchains. Consequently, continuous enhancements
in preventive measures are necessary to defend against such
attacks.
DoS Attack. In Ethereum 2.0-like PoS blockchains, DoS
attacks manifest in various forms and pose severe threats. At
the network layer, DoS attacks resemble traditional patterns,
where adversaries launch flood attacks by sending a vast
number of fake requests or data packets to occupy network
bandwidth and node resources, thereby preventing legiti-
mate transactions from being processed normally. Attacks
at the application layer primarily target smart contracts and
transaction pools (Txpool) [68], [69], [70]. At the smart
contract level, adversaries exploit vulnerabilities or design
flaws in contracts to initiate malicious transactions that
cause contract execution to enter infinite loops or exhaust
computational resources. For example, triggering complex
logic operations without resource limits can lead to contract
execution timeouts and node resource depletion, resulting
in a DoS condition that affects the normal operation of
the network. In terms of the Txpool, adversaries send a
large number of transactions with low gas prices but high
computational complexity, causing congestion in the Txpool
and preventing normal transactions from being processed
in a timely manner. This can also manipulate the order
of transactions, influence participants’ choices in packaging
transactions, interfere with the normal entry of transactions
into the blockchain network, and undermine the fairness and
efficiency of transaction processing in the network.
Reorg Attack. The Reorg Attack in Ethereum 2.0-like PoS
blockchains poses a severe threat to network security and
stability [59], [71]. This attack increases the proportion
of blocks belonging to Byzantine validators on the main
chain to gain more profits or downgrade chain quality or
performance. It encompasses Short Reorg Attacks (SRA)
and Long Reorg Attacks (LRA). By leveraging controlled
validator nodes, adversaries release new block branches at
specific times, causing the original main chain to be re-
placed. This results in the transaction states on the previous
main chain becoming uncertain, affecting user fund security
and transaction reliability, disrupting block order and trans-
action confirmation processes, and weakening users’ trust in
the network.
Grinding Attack. The Grinding Attack in Ethereum 2.0-like
PoS blockchains is a malicious act that exploits vulnerabili-
ties in the system’s mechanisms [63]. Adversaries primarily
manipulate the random number generation to influence the
selection of block proposers, leveraging the characteristics
of the Ethereum Virtual Machine (EVM), such as recursive
calls and storage operations, to meticulously construct ma-
licious contracts. These malicious contracts are designed to
exhaust the memory, storage, or computational resources of
nodes, thereby disrupting the fairness and normal operation
of the system. For instance, adversaries may continuously
attempt to generate random numbers favorable to them-
selves, increasing their chances of becoming block pro-
posers and subsequently controlling the direction of network
development. Alternatively, they can exploit recursive call
vulnerabilities in contracts to cause the contracts to fall into
an infinite loop of execution, consuming significant node
resources and preventing other legitimate transactions and
operations from proceeding smoothly. This severely impacts
the stability and efficiency of the Ethereum 2.0-like PoS
blockchain network, exerting a negative influence on the
entire blockchain ecosystem.
A.3. Attacks on Other Aspects
Smart
Contract
Attack.
In
Ethereum
2.0-like
PoS
blockchains, the attack vectors targeting smart contracts are
diverse and pose significant risks [72], [73], [74]. Reen-
trancy vulnerabilities represent one of the common attack
methods, where adversaries exploit flaws in the contract’s
failure to correctly update its state during external calls,
resulting in repeated invocations of contract functions and
the abnormal transfer of contract assets. The infamous DAO
incident suffered substantial losses due to a reentrancy vul-
nerability. Overflow vulnerabilities are also noteworthy, as
errors in computation may arise when data exceeds the range
of variable types, disrupting the normal logical execution
of contracts. Furthermore, adversaries exploit vulnerabilities
in contract permission management to obtain unauthorized
operational privileges, allowing them to tamper with contract
data or execute malicious operations. These attacks not only
render the contracts ineffective in fulfilling their intended
functions but may also lead to user fund losses, transaction
data chaos, and severely impact the stability and trust of
the Ethereum ecosystem. While formal verification and fuzz
testing techniques offer certain defenses to a degree, new
attack vectors continue to emerge, necessitating ongoing
research and the enhancement of defensive measures.
Txpool Attack. In Ethereum 2.0-like PoS blockchains, at-
tacks against the Txpool primarily exploit its mechanism
characteristics to disrupt transaction processing [58], [69].
Adversaries often employ a strategy of submitting a large
number of transactions with low gas prices but high com-
putational complexity, thereby causing congestion within
the Txpool. Since the Txpool typically sorts and processes
transactions based on factors such as gas price, these mali-
cious transactions, despite paying less gas, consume sub-
stantial resources for verification and processing due to
their computational complexity. This leads to a situation
where legitimate transactions cannot be timely packaged
by participants, thereby extending transaction confirmation
times. Furthermore, adversaries may attempt to manipulate
the order of transactions within the Txpool by controlling the
timing of transaction broadcasts and their queuing positions,
thereby influencing participants’ selection of transactions.
This enables certain specific transactions to be prioritized
or delayed in processing, disrupting the fairness and normal
flow of transaction processing. Consequently, this affects
the transaction efficiency and user experience of the entire
Ethereum 2,0-like blockchain network, posing a threat to
the network’s normal operation.
Data
Storage
Attack.
In
Ethereum
2.0-like
PoS
blockchains, attacks targeting data storage pose significant
threats [75]. Adversaries may exploit vulnerabilities in
the storage mechanism to illegally manipulate storage
pointers, maliciously tampering with account balances,
data, or access control information, resulting in erroneous
or inconsistent account states. Additionally, adversaries can
leverage the characteristics of the data structures used in
account storage by carefully crafting accounts that increase
the cost of account access upon insertion, thereby achieving
the purpose of raising storage and access cost. For instance,
modifying account balance data can lead to abnormal fund
displays or illegal transfers; disrupting access controls
can grant unauthorized account operation privileges. Such
attacks may also interfere with the account state update
process, causing account states to become disconnected
from actual transaction conditions. If successful, these
attacks can lead to severe consequences such as user
asset losses and transaction record chaos, undermining
the accurate processing and trust mechanisms of account
information within the entire blockchain system.
Appendix B.
Proof of Theorem 1
The initiation condition for the UUM attack is Dph
1
≤
Dph
0 . Based on the difficulty calculation formula, we have:
Dph
0 + max

1 −
tph
1 −tph
0
9

, −99

·
 Dph
0
2048

≤Dph
0
max

1 −
tph
1 −tph
0
9

, −99

·
 Dph
0
2048

≤0
tph
1 −tph
0
9

≥1.
(3)
Hence, we have
j
t
ph
1 −t
ph
0
9
k
∈[1, +∞).
Appendix C.
Proof of Theorem 2
Firstly, for the adversary’s block Bpa
i
to be valid, it is
necessary for block Bpa
1 to be generated after its parent block
Bpa
0 . Consequently, the timestamp tpa
1
of block Bpa
1
should
be greater than the timestamp tpa
0
of its parent block Bpa
0 ,
i.e.:
tpa
1 −tpa
0 ≥1.
(4)
Secondly, only when the difficulty Dpa
1
of the adver-
sary’s block Bpa
1
is greater than the difficulty Dph
1
of the
honest block Bph
0
will other honest participants choose the
adversary’s block. At this point, we have: Dpa
1
> Dph
1 .
Based on the difficulty calculation formula, we can derive
the following inequality:
Dpa
0 + max

1 −
tpa
1 −tpa
0
9

, −99

·
 Dpa
0
2048

> Dph
0 + max

1 −
tph
1 −tph
0
9

, −99

·
 Dph
0
2048

.
(5)
Since Dph
0
= Dpa
0
and tph
0
= tpa
0 , we therefore have:
max

1 −
tpa
1 −tpa
0
9

, −99

> max

1 −
tph
1 −tpa
0
9

, −99

.
(6)
The above inequality can be transformed into the fol-
lowing system of inequalities:



1 −
j
tpa
1 −tpa
0
9
k
> 1 −
j
t
ph
1 −tpa
0
9
k
(1)
1 −
j
tpa
1 −tpa
0
9
k
> −99
(2)
.
(7)
Based on Inequality (1), we have:
tph
1 −tpa
0
9

−
tpa
1 −tpa
0
9

> 0.
(8)
Further rearranging the above inequality, we can derive:
tph
1 −tpa
1
9

> 0.
(9)
Since
j
t
ph
1 −tpa
1
9
k
can only take integer values, i.e.,
j
t
ph
1 −tpa
1
9
k
∈N, we therefore have:
tph
1 −tpa
1
9

≥1.
(10)
Based on the inequality above, we can get
j
t
ph
1 −tpa
1
9
k
∈
[1, +∞).
Based on the Inequality (10), we can derive:
tph
1 −tpa
1 ≥9.
(11)
Based on the Inequality (2), we can derive:
j
tpa
1 −tpa
0
9
k
< 100
(12)
Since
j
tpa
1 −tpa
0
9
k
can only take integer values, i.e.,
j
tpa
1 −tpa
0
9
k
∈N, we therefore have:
j
tpa
1 −tpa
0
9
k
≤99. Based
on the aforementioned inequalities, we have:
tpa
1 −tpa
0 < 900.
(13)
Combining Inequality (4) and Inequality (13), we obtain:
1 ≤tpa
1 −tpa
0 < 900, which implies that tpa
1 −tpa
0 ∈[1, 900).
Appendix D.
Proof of Theorem 3
According to Theorem 2, the conditions for a successful
UUM attack are:
j
t
ph
1 −tpa
1
9
k
∈[1, +∞) and tpa
1
−tpa
0
∈
[1, 900). To minimize the risk associated with the UUM
attack, which corresponds to minimizing the block difficulty
growth rate, Theorem 2 suggests that we take the mini-
mum value within the condition
j
t
ph
1 −tpa
1
9
k
∈[1, +∞), i.e.,
j
t
ph
1 −tpa
1
9
k
= 1. This implies that tph
1
−tpa
1
∈[9, 18). By
integrating these two conditions, we can prove the theorem.
Appendix E.
Proof of Theorem 4
The condition for the RUM attack is that mining on top
of the former block incurs no additional risk, i.e., Dph
1
=
Dph
0 . Based on the difficulty calculation formula, we have:
Dph
0 + max

1 −
tph
1 −tph
0
9

, −99

·
 Dph
0
2048

= Dph
0
max

1 −
tph
1 −tph
0
9

, −99

= 0
tph
1 −tph
0
9

= 1.
(14)
TABLE 1. UUM STATE TRANSITION.
State
Destination
Transition
Probability
Reward
PH
PS
Deployment
Deployment
PA any t
PA(any t)
0
1
Deployment
Deployment
PH t < 9
PH(t < 9)
1
0
Deployment
Attack
PH t ≥9
PH(t ≥9)
1
0
Attack
Attack
PH t ≥9
PH(t ≥9)
1
0
Attack
Deployment
PH t < 9
PH(t < 9)
1
0
Attack
Deployment
PA any t
PA(any t)
−1
1
Appendix F.
Proof of Theorem 5
Based on the analysis of state transitions for UUM
deployment and attack states presented in Section 4, we cal-
culate the absolute and relative shares of coin-base rewards
for both UUM adversaries and honest participants.
The absolute share of coin-base rewards for UUM ad-
versary PA is:
RUUM
PA
= P (Deploy) · PA (any t) + P (Attack) · PA (any t)
= (P (Deploy) + P (Attack)) · PA (any t)
= PA (any t) .
(15)
Therefore, the absolute share of coin-base rewards for
UUM adversary PA remains unchanged.
The absolute share of coin-base rewards for honest par-
ticipant PH is:
RUUM
PH
= P (Deploy) · PH (t < 9) + P (Deploy) · PH (t ≥9)
+ P (Attack) · PH (t ≥9) + P (Attack) · PH (t < 9)
−P (Attack) · PA (any t)
= P (Deploy) · (PH (t < 9) + PH (t ≥9))
+ P (Attack) · (PH (t ≥9) + PH (t < 9))
−P (Attack) · PA (any t)
= P (Deploy) · PH (any t) + P (Attack) · PH (any t)
−P (Attack) · PA (any t)
= (P (Deploy) + P (Attack)) · PH (any t)
−P (Attack) · PA (any t)
= PH (any t) −P (Attack) · PA (any t)
< PH (any t) .
(16)
Therefore, the absolute share of coin-base rewards for
honest participant PH decreases.
The expected relative share of coin-base rewards for
UUM adversary PA is:
E

RUUM
PA

=
RUUM
PA
RUUM
PA
+ RUUM
PH
=
PA (any t)

PA (any t) + PH (any t)
−P (Attack) · PA (any t)

>
PA (any t)
PA (any t) + PH (any t)
= PA (any t) .
(17)
Therefore, the expected relative share of coin-base re-
wards for UUM adversary PA increases.
The expected relative share of coin-base rewards for
honest participant PH is:
E

RUUM
PH

=
RUUM
PH
RUUM
PA
+ RUUM
PH
= PH (any t) −P (Attack) · PA (any t)

PA (any t) + PH (any t)
−P (Attack) · PA (any t)

<
PH (any t)
PA (any t) + PH (any t)
= PH (any t) .
(18)
Therefore, the expected relative share of coin-base re-
wards for honest participant PH decreases.
Appendix G.
Proof of Theorem 6
The timestamps of the honest block Bph
i
and the SUUM
adversary’s block Bpa
i
at the same height i are denoted as
tph
i
and tpa
i , respectively, with corresponding difficulties Dph
i
and Dpa
i . For the RUM attack to be successful, the difficulty
Dpa
i
of the SUUM adversary’s block Bpa
i
at the same height
should be greater than the difficulty Dph
i
of the honest block
Bph
i . According to the difficulty calculation formula, we
have:
Dph
i
= Dph
i−1 + max

1 −
tph
i
−tph
i−1
9

, −99

·
Dph
i−1
2048

(19)
and
Dpa
i
= Dpa
i−1 + max

1 −
tpa
i
−tpa
i−1
9

, −99

·
Dpa
i−1
2048

.
(20)
Given that tph
0
= tpa
0
and Dph
0
= Dpa
0
(representing the
same block), for i = 1, 2 , . . . , n, it is necessary to ensure
that Dpa
i
> Dph
i
holds true consistently.
(1) For i = 1, we need to ensure that the following condi-
tion holds:
Dpa
i
> Dph
i
⇒Dpa
1
> Dph
1 .
(21)
According to the difficulty calculation formula, we have:
Dpa
0 + max

1 −
tpa
1 −tpa
0
9

, −99

·
 Dpa
0
2048

> Dph
0 + max

1 −
tph
1 −tph
0
9

, −99

·
 Dph
0
2048

⇒max

1 −
tpa
1 −tpa
0
9

, −99

> max

1 −
tph
1 −tph
0
9

, −99

.
(22)
By rearranging this inequality, we obtain the following
system of inequalities:



1 −
j
tpa
1 −tpa
0
9
k
> 1 −
j
t
ph
1 −tpa
0
9
k
(1)
1 −
j
tpa
1 −tpa
0
9
k
> −99
(2)
.
(23)
According to inequality (1), we have:
tph
1 −tph
0 −(tpa
1 −tpa
0 ) ≥9
⇒tph
1 −tpa
1 ≥9.
(24)
Thus, we have:
tph
1 −tpa
1
9

∈[1, +∞).
(25)
According to inequality (2), we have:
tpa
1 −tpa
0
9

< 100.
(26)
According to this inequality, we obtain tpa
1 −tpa
0 < 900.
In order for a block Bpa
1
to be valid, we derive tpa
1 −
tpa
0 > 0. Since tpa
1 −tpa
0 ∈N, we have:
tpa
1 −tpa
0 ∈(1, 900).
(27)
According to equations (25) and (27), Theorem 6 (1) is
proved. Below we prove Theorem 6 (2).
(2) Similarly, for i = 2, we need to ensure that the following
condition holds:
Dpa
i
> Dph
i
⇒Dpa
2
> Dph
2 .
(28)
According to the difficulty calculation formula, we have:
Dph
2
= Dph
1 +max

1 −
tph
2 −tph
1
9

, −99

·
 Dph
1
2048

(29)
and
Dpa
2
= Dpa
1 +max

1 −
tpa
2 −tpa
1
9

, −99

·
 Dpa
1
2048

.
(30)
Therefore, we can derive:
Dpa
2 −Dph
2
=
>0
z
}|
{
(Dpa
1 −Dph
1 )
+ max

1 −
tpa
2 −tpa
1
9

, −99

−max

1 −
tph
2 −tph
1
9

, −99

≥0.
(31)
We take the example of a minimum-risk attack (where
the difficulty of an adversarial block at the same height
in the SUUM model is one greater than that of an honest
block).
(2.1) For
j
Dpa
1
2048
k
=
j
D
ph
1
2048
k
, it suffices to ensure that the
following condition holds:
max

1 −
tpa
2 −tpa
1
9

, −99

−max

1 −
tph
2 −tph
1
9

, −99

≥0.
(32)
Convert the above inequality into the following system
of inequalities:



1 −
j
tpa
2 −tpa
1
9
k
≥1 −
j
t
ph
2 −t
ph
1
9
k
(1)
1 −
j
tpa
2 −tpa
1
9
k
≥−99
(2)
.
(33)
To solve inequality (1), we have:
tph
2 −tph
1 −(tpa
2 −tpa
1 )
9

≥0.
(34)
To solve inequality (2), we have:
tpa
2 −tpa
1
9

≤100.
(35)
Therefore, the solution to the above system of inequali-
ties is

t
ph
2 −t
ph
1 −(tpa
2 −tpa
1 )
9

≥0 and
j
tpa
2 −tpa
1
9
k
≤100.
To ensure the legitimacy of block Bpa
2 , the following
conditions must be satisfied: tpa
2 −tpa
1
> 0. Therefore,
if i = 2 and
j
Dpa
1
2048
k
=
j
D
ph
1
2048
k
, the SUUM attack is
successful if and only if the following conditions hold:

t
ph
2 −t
ph
1 −(tpa
2 −tpa
1 )
9

≥0 and tpa
2 −tpa
1 ∈[1, 900).
(2.2) For D
ph
1
+1
2048
=
j
D
ph
1
2048
k
, we have
j
Dpa
1
2048
k
=
j
D
ph
1
2048
k
+
1. At this point, it is only necessary to ensure that the
following conditions hold:
max
n
1 −
j
t
ph
2 −t
ph
1
9
k
, −99
o
·
j
D
ph
1
2048
k
−max
n
1 −
j
tpa
2 −tpa
1
9
k
, −99
o
·
j
Dpa
1
2048
k
≥0
⇒max
n
1 −
j
t
ph
2 −t
ph
1
9
k
, −99
o
·
j
Dps
1
2048
k
−1

−max
n
1 −
j
tpa
2 −tpa
1
9
k
, −99
o
·
j
Dpa
1
2048
k
≥0.
Since max
n
1 −
j
tpa
2 −tpa
1
9
k
, −99
o
< 0, it follows that:
max

1−

tph
2
−tph
1
9

,−99

max

1−

tpa
2
−tpa
1
9

,−99
 ≤

Dpa
1
2048


Dps
1
2048

−1
⇒

max

1−

tph
2
−tph
1
9

,−99

max

1−

tpa
2
−tpa
1
9

,−99

≤1
⇒max
n
1 −
j
t
ph
2 −t
ph
1
9
k
, −99
o
−max
n
1 −
j
tpa
2 −tpa
1
9
k
, −99
o
≥0
⇒



1 −
j
t
ph
2 −t
ph
1
9
k
≥1 −
j
tpa
2 −tpa
1
9
k
(1)
1 −
j
tpa
2 −tpa
1
9
k
≥−99
(2)
.
(36)
To solve inequality (1), we have:
tpa
2 −tpa
1 −(tph
2 −tph
1 )
9

≥0.
(37)
To slove inequality (2), we have:
tpa
2 −tpa
1
9

≤100.
(38)
In order for a block Bpa
2
to be valid, it needs to be
satisfied: tpa
2 −tpa
1 ≥1. Thus we have:
tpa
2 −tpa
1 ∈[1, 900).
(39)
Combining inequalities (37) and (39), if i = 2 and
D
ph
1
+1
2048
=
j
D
ph
1
2048
k
, SUUM attack succeeds if and only if
the following conditions hold:

t
ph
2 −t
ph
1 −(tpa
2 −tpa
1 )
9

≥
0 and tpa
2 −tpa
1 ∈[1, 900).
(3) For i ≥3, the proof process is analogous to the case
where i = 2.
Appendix H.
Proof of Theorem 7
To minimize the risk posed by the SUUM attack, which
corresponds to minimizing the block difficulty growth rate,
according to Theorem 6, we proceed as follows:
(1) For i = 1, we take the minimum value within the
condition

t
ph
i
−tpa
i−1
9

∈[1, +∞), i.e.,
j
t
ph
1 −tpa
0
9
k
= 1.
(2) For i
≥
2, we take the minimum value within
the condition

t
ph
i
−t
ph
i−1−(tpa
i
−tpa
i−1)
9

∈[1, +∞), i.e.,

t
ph
i
−t
ph
i−1−(tpa
i
−tpa
i−1)
9

= 1.
By integrating these two cases, we can prove the theo-
rem.
Appendix I.
Proof of Theorem 8
Based on the analysis of state transitions in the Deploy-
ment State, Downgrade State, and Attack State of SUUM
presented in Section 5.2, we calculate the absolute and
relative shares of coin-base rewards for both the SUUM
adversary and honest participants.
The absolute share of coin-base rewards for the SUUM
adversary PA is:
RSUUM
PA
= P (Deploy) · PA (any t)
+ P (Downgrade) · PA (any t)
+ P (Attack i, i ≥1) · PA (any t)
=

P (Deploy) + P (Downgrade)
+P (Attack i, i ≥1)

· PA (any t)
= PA (any t) .
(40)
Therefore, the absolute share of coin-base rewards for
the SUUM adversary PA remains unchanged.
The absolute share of coin-base rewards for honest par-
ticipant PH is:
RSUUM
PH
= P (Deploy) · PH (t < 9)
+ P (Deploy) · PH (t ≥9)
+ P (Downgrade) · PH (t < 9)
+ P (Downgrade) · PH (t ≥9)
+ P (Attack i + 1, i ≥1) · PH (any t)
−P (Downgrade) · PA (any t)
−P (Attack i, i ≥1) · PA (any t)
=

P (Deploy) + P (Downgrade)
+P (Attack i, i ≥1)

· PH (any t)
−P (Attack 1) · PH (any t)
−P (Downgrade) · PA (any t)
−P (Attack i, i ≥1) · PA (any t)
= PH (any t) −P (Attack 1)
−P (Downgrade) · PA (any t)
−P (Attack i + 1, i ≥1) · PA (any t)
< PH (any t) .
(41)
Therefore, the absolute share of coin-base rewards for
honest participants decreases.
The relative share of coin-base rewards for the SUUM
adversary PA is:
E

RSUUM
PA

=
RSUUM
PA
RSUUM
PA
+ RSUUM
PH
=
PA (any t)


PA (any t) + PH (any t) −P (Attack 1)
−P (Downgrade) · PA (any t)
+P (Attack i + 1, i ≥1) · PA (any t)


>
PA (any t)
PA (any t) + PH (any t)
= PA (any t) .
(42)
Therefore, the expected relative share of coin-base re-
wards for the SUUM adversary PA increases.
The expected relative share of coin-base rewards for
honest participant PH is:
E

RSUUM
PH

=
RSUUM
PH
RSUUM
PA
+ RSUUM
PH
=


PH (any t) −P (Attack 1)
−P (Downgrade) · PA (any t)
+P (Attack i + 1, i ≥1) · PA (any t)




PA (any t) + PH (any t) −P (Attack 1)
−P (Downgrade) · PA (any t)
+P (Attack i + 1, i ≥1) · PA (any t)


<
PH (any t)
PA (any t) + PH (any t)
= PH (any t) .
(43)
Therefore, the expected relative share of coin-base re-
wards for honest participants PH decreases.
Appendix J.
Proof of Theorem 9
Firstly, it has been proved in the literature [39] that RUM
outperforms honest mining. This provides us with a starting
point for our subsequent comparisons.
Next, let’s focus on the comparison between UUM and
RUM. When we look at their state space and transition
processes, we can find that there is a key difference in the
conditions that trigger the transition from the deployment
state to the attack state.
For RUM, it transitions from the deployment state to
the attack state when an honest participant finds a new block
whose timestamp differs from the timestamp of the previous
block in the main chain by a certain value. Specifically, this
value needs to be greater than or equal to 9 and less than
18, which we can denote as PH (9 ≤t < 18). In a practical
blockchain scenario, this means that only when the time
interval between the generation of consecutive blocks by
honest participants falls within this specific range will RUM
enter the attack state.
In contrast, for UUM, it transitions from the deployment
state to the attack state when an honest participant finds
a new block whose timestamp differs from the previous
block’s timestamp in the main chain by a value greater than
or equal to 9, denoted as PH (t ≥9). For example, if we
imagine the blockchain as a sequence of events over time,
UUM is more likely to start an attack as it has a broader
range of time differences that can trigger the attack state
compared to RUM.
This difference in the transition conditions leads to a
higher steady-state probability of being in the attack state for
UUM compared to RUM. And as a result, UUM adversaries
can obtain higher rewards than RUM adversaries.
Similarly, when we consider the comparison between
SUUM and UUM, the approach to proving that SUUM
outperforms UUM follows a similar logic. SUUM expands
the adversary’s state space in a significant way. In the
attacking state, adversaries in SUUM can release held-
back blocks with carefully selected timestamps. Let’s say,
they can choose the most opportune moments to release
these blocks to maximize their impact on the blockchain’s
operation and ultimately obtain higher rewards than UUM
adversaries. This is somewhat like having more strategic
options in a game, which gives SUUM an advantage over
UUM.
Appendix K.
Proof of Theorem 10
We discuss the difficulty risks posed by each of the three
types of attacks as follows:
(1) First, we analyze the difficulty risk posed by the RUM
attack. Recalling Theorems 2 and 3 from Section 3, we
understand that each successful execution of a RUM
attack increases the difficulty risk of the blockchain
by 1. We use the notation Attack
PA
any t
⇒
Deploy
to represent this situation. That is, every time a RUM
adversary successfully executes an attack and triggers
the state change from the attack state to the deployment
state, it leads to an increment in the blockchain’s dif-
ficulty risk. Consequently, the increased risk associated
with the RUM attack can be quantified as the number
of successful attacks by a RUM adversary, denoted by
P 
Attack
PA
any t
⇒
Deploy

.
(2) The proof of UUM follows a methodology analogous
to that of RUM.
(3) Finally, we analyze the difficulty risk posed by SUUM
attack. Recalling Theorems 6 and 7 from Section 5,
we understand that each successful execution of a
SUUM attack also increases the difficulty risk of the
blockchain by 1. This increase in risk is associated with
two specific types of state transitions, represented by
Downgrade
PA
any t
⇒
Deploy and Attack 1
PH
any t
⇒
Deploy. In other words, when an SUUM adversary
successfully conducts an attack and makes the state
change happen in either of these two ways, it adds
to the overall risk related to the blockchain’s dif-
ficulty. Therefore, the increased risk associated with
SUUM attack can be quantified as the number of
successful attacks by a SUUM adversary, denoted by
P
 
Downgrade
PA
any t
⇒
Deploy
+Attack 1
PH
any t
⇒
Deploy
!
.
Appendix L.
Proof of Theorem 11
We discuss the forking rate posed by each of the three
types of attacks and honest mining as follows:
(1) For honest mining, all participants adhere to the protocol
and engage in honest mining practices. Under such
circumstances, no participant undertakes malicious ac-
tions deliberately intended to cause forks. Consequently,
the deliberate forking rate induced by honest mining,
denoted as FRHM = 0.
(2) For the RUM attack, the adversary executes the RUM
attack while other honest participants continue to mine
honestly. Under such circumstances, revisiting the RUM
attack methodology outlined in Section 3, we under-
stand that the deliberate forking of the blockchain occurs
as a result of a successful RUM attack by the adver-
sary. A successful RUM attack is contingent upon the
RUM adversary, who is in the attack state, successfully
generating the next block, with the timestamp difference
between it and its parent block being less than 9. There-
fore, the deliberate forking rate induced by the RUM
attack, denoted as FRRUM = PRUM
Attack · PA(t < 9).
(3) For the UUM attack, the adversary executes the UUM
attack while other honest participants continue to mine
honestly. Under such circumstances, revisiting the UUM
attack methodology outlined in Section 4, we under-
stand that the deliberate forking of the blockchain arises
due to a successful UUM attack by the adversary. A
successful UUM attack occurs if and only if the UUM
adversary, who is in the attack state, successfully gen-
erates the next block and strategically manipulates its
timestamp such that the adversary’s block in the fork
competition is preferentially selected by other honest
participants over the honest chain. Therefore, the delib-
erate forking rate induced by the UUM attack, denoted
as FRUUM = PUUM
Attack · PA(any t).
(4) For SUUM attack, the adversary executes the SUUM
attack while other honest participants continue to mine
honestly. In such a scenario, revisiting the SUUM at-
tack methodology outlined in Section 5, we can iden-
tify two scenarios that lead to deliberate forking of
the blockchain. The first scenario occurs when the
blockchain topology is in the attack state, where the
withholding of blocks by the SUUM adversary will
inevitably cause a blockchain fork. The corresponding
probability for this scenario is Pn
i=0 PSUUM
Attack i. The
second scenario is when the SUUM adversary, who
is in the downgrade state, successfully generates the
next block and strategically manipulates its timestamp
such that this block is preferentially selected, leading to
deliberate forking of the blockchain. The corresponding
TABLE 2. SUUM STATE TRANSITION.
State
Destination
Transition
Probability
Reward
PH
PS
Deployment
Attack 1
PA any t
PA(any t)
0
1
Deployment
Deployment
PH t < 9
PH(t < 9)
1
0
Deployment
Downgrade
PH t ≥9
PH(t ≥9)
1
0
Downgrade
Deployment
PH t < 9
PH(t < 9)
1
0
Downgrade
Downgrade
PH t ≥9
PH(t ≥9)
1
0
Downgrade
Deployment
PA any t
PA(any t)
−1
1
Attack 1
Deployment
PH any t
PH(any t)
0
0
Attack i,
i ≥1
Attack i + 1
PA any t
PA(any t)
−1
1
Attack i + 1,
i ≥1
Attack i
PH any t
PH(any t)
1
0
probability for this scenario is PSUUM
Downgrade ·PA(any t).
Therefore, the deliberate forking rate induced by the
SUUM attack, denoted as FRSUUM, is given by the
sum of the probabilities of these two scenarios:
FRSUUM =
n
X
i=0
PSUUM
Attack i + PSUUM
Downgrade · PA (any t)
= PSUUM
Attack + PSUUM
Downgrade · PA(any t).
(44)
Next, we proceed to compare the magnitudes of the
forking rates arising from these four scenarios. On
the one hand, according to Theorem 9, for adversaries
possessing equivalent computational power, the steady-
state probabilities of being in the attack state for SUUM,
UUM, and RUM decrease sequentially, i.e.,
PSUUM
Attack > PUUM
Attack > PRUM
Attack.
(45)
On the other hand, it is evident that
1 > PA (any t) > PA(t < 9).
(46)
Therefore, we conclude that
PSUUM
Attack > PUUM
Attack · PA (any t) > PRUM
Attack · PA (t < 9)
⇒FRSUUM > FRUUM > FRRUM > FRHM.
(47)
Appendix M.
Proof of Theorem 12
We know that the relationship between target and the
difficulty D can be expressed as:
target = max target
D
.
(48)
Where, max target is a constant, and for Ethereum 1.x, its
value is 2256.
The probability PA for adversary A to find the next
block can be calculated as follows:
PA = µA ·
1
target.
(49)
Since target is inversely proportional to the difficulty
D, we can replace target with an expression related to D:
PA = µA ·
D
max target.
(50)
1) For RUM attack, its cost can be expressed as:
ACRUM = P
B
ph
0
A
−P
B
ph
1
A
= µA ·
Dph
0
max target −µA ·
Dph
1
max target
= µA · (Dph
0 −Dph
1 )
max target .
(51)
According to [39], the initiation condition for the RUM
attack is
j
t
ph
1 −t
ph
0
9
k
∈[1, 9), i.e., Dph
0
= Dph
1 . There-
fore, we have:
ACRUM = 0.
(52)
2) For UUM and/or SUUM attacks, their cost can be
expressed as:
ACUUM = ACSUUM = P
B
ph
0
A
−P
B
ph
1
A
= µA ·
Dph
0
max target −µA ·
Dph
1
max target
= µA · (Dph
0 −Dph
1 )
max target .
(53)
According to Theorem 1 and Theorem 6, the initiation
condition for UUM and SUUM attacks is
j
t
ph
1 −t
ph
0
9
k
∈
[9, +∞), i.e., Dph
0 −Dph
1
≥1. Therefore, we have:
ACUUM = ACSUUM = µA · (Dph
0 −Dph
1 )
max target
> µA ·
1
max target
> 0.
(54)
Taking Ethereum 1.x as an example, by substituting
max target with 2256, we obtain:
PA = µA ·
D
2256 .
(55)
Thus, the probability PA for an adversary A, possess-
ing a power ratio of µA, to find the next block is the
proportion of its power to the total power, multiplied
by the ratio of the block difficulty D to the maximum
target value.
It is noteworthy that, upon reviewing historical data
from Ethereum 1.x, we observe that the maximum dif-
ference in difficulty between two consecutive blocks is
approximately 8.86441324 × 1012 ≈239.65. Therefore,
we can derive:
ACUUM = ACSUUM ≤µA · max {Dph
0 −Dph
1 }
2256
≤µA · 239.65
2256 ≈µA ·
1
2216.35
≈0.
(56)
Appendix N.
Mitigations
N.1. Adjust the Difficulty Adjustment Algorithm
The difficulty adjustment algorithm of Ethereum 1.x
is at risk of being exploited in the face of Uncle Maker
attacks. Adversaries can manipulate the timestamp to influ-
ence the block difficulty and thus gain an unfair advantage.
Therefore, it is necessary to design a more robust and
manipulation-resistant difficulty adjustment algorithm. For
example, more factors can be considered to determine the
block difficulty. Instead of relying solely on the timestamp
and the difficulty of the parent block, dynamic factors
such as the actual computational power distribution of the
network and the number of transactions can also be incor-
porated. In this way, it becomes difficult for adversaries
to simply manipulate the timestamp to reduce their attack
difficulty, thereby increasing the cost and difficulty of the
attack and reducing the probability of the attack occurring.
One possible improvement direction is to adopt a moving
average-based difficulty adjustment method, which takes
into account the generation time and difficulty of multiple
past blocks instead of just the current block and its parent
block. This can smooth the difficulty adjustment process
and reduce the exploitability of short-term fluctuations by
adversaries. Additionally, upper and lower limits for diffi-
culty adjustment can be set to prevent adversaries from caus-
ing significant drops or rises in difficulty through extreme
timestamp manipulations, thereby maintaining the stability
and predictability of the blockchain difficulty.
N.2. Strengthen Timestamp Verification
Given that the Uncle Maker attack is highly reliant on
the manipulation of timestamps, strengthening the times-
tamp verification mechanism is one of the key measures to
mitigate such attacks. A more rigorous and reliable source
of timestamps can be established. For instance, a network
of distributed timestamp servers can be employed to ensure
that all nodes can obtain consistent and accurate time in-
formation. Simultaneously, stricter limitations on the range
of block timestamps should be imposed to prevent adver-
saries from arbitrarily setting unreasonable timestamps. For
example, it can be stipulated that the block timestamp must
fall within a reasonable interval, be in line with the average
block generation time of the network, and possess reason-
able continuity with the timestamps of preceding blocks.
A timestamp consensus algorithm can be introduced,
mandating that multiple nodes perform consensus verifica-
tion on the block timestamp. Only when a certain proportion
of mining power approve can the timestamp be regarded as
valid. Additionally, for blocks with abnormal timestamps,
more in-depth examination and verification can be carried
out. Even the block can be temporarily rejected until the
legality of its timestamp is ascertained. This can effectively
prevent adversaries from launching Uncle Maker attacks by
manipulating timestamps and enhance the security of the
blockchain system.
N.3. Introduce an Economic Penalty Mechanism
To further deter adversaries, an economic penalty mech-
anism can be introduced. For nodes or participants detected
to be involved in the Uncle Maker attack, in addition to
confiscating the improper gains obtained through the attack,
additional economic penalties can be imposed on them, such
as deducting a certain proportion of collateral assets (if
applicable) or future mining rewards. This can increase the
cost of the attack and make adversaries more cautious when
considering launching an attack.
A reporting mechanism can be established to encourage
other nodes to report suspicious attack behaviors. For nodes
that report successfully, a certain reward can be given, and
the source of the reward can be the fines imposed on the ad-
versaries. In this way, a community supervision mechanism
can be formed to jointly maintain the security and fairness of
the blockchain. At the same time, the attack behaviors and
penalty situations should be regularly publicized to serve as
a warning and reduce the number of potential adversaries.
N.4. Improve
Network
Monitoring
and
Early
Warning Capabilities
Real-time monitoring of the operating status of the
blockchain network and timely detection of abnormal block
generation patterns and timestamp behaviors are crucial for
quickly responding to and mitigating Uncle Maker attacks.
Specialized monitoring tools and algorithms can be de-
ployed to perform real-time monitoring and analysis of key
indicators such as block timestamps, difficulty changes, and
uncle block generation in the network. Once an abnormal
situation is detected, an early warning signal should be
issued in a timely manner to notify network participants
to take corresponding measures, such as suspending the ac-
ceptance of suspicious blocks and activating the emergency
response mechanism.
Utilize machine learning and artificial intelligence tech-
nologies to conduct in-depth analysis of network data and
establish prediction models for attack behaviors. Through
learning from historical data, patterns and trends that may
indicate the imminent occurrence of Uncle Maker attacks
can be identified, and preventive measures can be taken in
advance. For example, if it is found that the block timestamp
setting pattern of a certain node or participant is signifi-
cantly different from normal behavior and is accompanied
by an abnormal increase in the frequency of uncle block
generation, the system can automatically mark the node as
a suspicious object and strengthen the monitoring of its
subsequent behaviors. At the same time, the detected abnor-
mal situations should be shared with the entire blockchain
community to promote the community to jointly respond to
attack threats and improve the security and stability of the
entire network.


arXiv:2505.05370v1  [cs.DC]  8 May 2025
Walrus: An Efficient Decentralized Storage Network
George Danezis1,2, Giacomo Giuliari1, Eleftherios Kokoris Kogias1, Markus Legner1,
Jean-Pierre Smith1, Alberto Sonnino1,2, Karl Wüst1
1Mysten Labs
2University College London (UCL)
Abstract
Decentralized storage systems face a fundamental trade-off between
replication overhead, recovery efficiency, and security guarantees.
Current approaches either rely on full replication, incurring sub-
stantial storage costs, or employ trivial erasure coding schemes
that struggle with efficient recovery especially under high storage-
node churn. We present Walrus, a novel decentralized blob storage
system that addresses these limitations through multiple technical
innovations.
At the core of Walrus is Red Stuff, a two-dimensional erasure
coding protocol that achieves high security with only 4.5x repli-
cation factor, while enabling self-healing recovery that requires
bandwidth proportional to only the lost data (𝑂(|𝑏𝑙𝑜𝑏|/𝑛) versus
𝑂(|𝑏𝑙𝑜𝑏|) in traditional systems). Crucially, Red Stuff is the first
protocol to support storage challenges in asynchronous networks,
preventing adversaries from exploiting network delays to pass ver-
ification without actually storing data.
Walrus also introduces a novel multi-stage epoch change proto-
col that efficiently handles storage node churn while maintaining
uninterrupted availability during committee transitions. Our sys-
tem incorporates authenticated data structures to defend against
malicious clients and ensures data consistency throughout stor-
age and retrieval processes. Experimental evaluation demonstrates
that Walrus achieves practical performance at scale, making it
suitable for a wide range of decentralized applications requiring
high-integrity, available blob storage with reasonable overhead.
1
Introduction
Blockchains support decentralized computation through the State
Machine Replication (SMR) paradigm [36]. However, they are prac-
tically limited to distributed applications that require little data
for operation. Since SMR requires all validators to replicate data
fully, it results in a large replication factor ranging from 100 to 1000,
depending on the number of validators in each blockchain.
While full data replication is practically needed for comput-
ing on state, it introduces substantial overhead when applications
only need to store and retrieve binary large objects (blobs) not
computed upon1. Dedicated decentralized storage [6] networks
emerged to store blobs more efficiently. For example, early net-
works like IPFS [30] offer robust resistance to censorship, enhanced
reliability and availability during faults, via replication on only a
small subset of nodes [46].
Decentralized blob storage is invaluable to modern decentralized
applications. We highlight the following use-cases:
• Digital assets, managed on a blockchain, such as non fungible
tokens (NFTs) need high integrity and availability guarantees
1A recent example includes ‘inscriptions’ on bitcoin and other chains, see https:
//medium.com/@thevalleylife/crypto-terms-explained-exploring-bitcoin-
inscriptions-51699dc218d2.
provided by decentralized blob stores. The current practice of
storing data off-chain on traditional stores only secures metadata,
while the actual NFT data remains vulnerable to removal or
misrepresentation depending on the browser2.
• Digital provenance of data assets is also increasingly important
in the age of AI: to ensure the authenticity of documentary mate-
rial; to ensure training data sets are not manipulated or polluted;
and to certify that certain models generated specific instances of
data [44]. These applications benefit from authenticity, traceabil-
ity, integrity and availability decentralized stores provide.
• Decentralized apps, whether web-based or as binaries, need
to be distributed from decentralized stores. Today, the major-
ity of decentralized apps rely on traditional web hosting to
serve their front ends and client-side code, which offers poor
integrity and availability. Decentralized stores may be used to
serve web and dapps content directly while ensuring its integrity
and availability. Similarly, decentralized stores can ensure binary
transparency for software and support the storage needs of full
pipelines of reproducible builds to support the strongest forms
of software auditing and chain of custody [22, 29].
• Decentralized storage plays a critical role in ensuring data avail-
ability for roll-ups [1], the current scaling strategy of Ethereum.
In this setting, storage nodes hold the data temporarily allowing
blockchain validators to recover it for execution. As a result, the
system imposes replication costs solely on the netted state of
the roll-up, rather than the full sequence of updates (e.g. transac-
tions).
• Decentralized social network platforms [18] are trying to chal-
lenge centralized incumbents. But the nature of social network-
ing requires support for rich media user content, such as long
texts, images or videos. Beyond social, collaborative platforms as
well as civic participation platforms [4] need a way to store both
public interest data and the application data itself in credibly
neutral stores such as decentralized stores.
• Finally, the integration of decentralized storage with encryp-
tion techniques marks a significant paradigm shift [19]. This
approach offers users comprehensive data management aligned
with the Confidentiality, Integrity, and Availability (CIA) triad,
eliminating the need to rely on cloud services as fiduciaries. This
integration unlocks numerous promising applications, including
sovereign data management, decentralized data marketplaces,
and computational operations over encrypted datasets. Although
this paper does not focus on these applications, our decentralized
storage system, Walrus, can naturally function as the storage
layer for encrypted blobs. This approach provides a structured,
layered framework that allows encryption overlays to focus on
2A recent proof of concept attack is described here: https://moxie.org/2022/01/07/web3-
first-impressions.html
Danezis et. al
creating a secure and efficient Key Management System (KMS)
without worrying about data availability.
In brief, secure decentralized blob stores are critical for all appli-
cations where data is relied upon by multiple mutually distrustful
parties, and needs to stored in a credibly neutral store that provides
high authenticity, integrity, auditability and availability – all this
at a reasonable cost and low complexity.
Approaches to Decentralized Storage
Protocols for decentralized storage generally fall into two main
categories. The first category includes systems with full replication,
with Filecoin [30] and Arweave [45] serving as prominent examples.
The main advantage of these systems is the complete availability
of the blob on the storage nodes, which allows for easy access and
seamless migration if a storage node goes offline. This setup enables
a permissionless environment since storage nodes do not need to
rely on each other for file recovery. However, the reliability of these
systems hinges on the robustness of the selected storage nodes.
For instance, assuming a classic 1/3 static adversary model and an
infinite pool of candidate storage nodes, achieving “twelve nines” of
security – meaning a probability of less than 10−12 of losing access
to a file – requires storing more than 25 copies on the network3.
This results in a 25x storage overhead. A further challenge arises
from Sybil attacks [16], where malicious actors can pretend to store
multiple copies of a file, undermining the system’s integrity.
The second category of decentralized storage services [23] uses
Reed-Solomon (RS) encoding [32]. RS encoding reduces replication
requirements significantly. For example, in a system similar to
blockchain operations, with𝑛nodes, of which 1/3 may be malicious,
and in an asynchronous network, RS encoding can achieve sufficient
security with the equivalent of just 3x storage overhead. This is
possible since RS encoding splits a file into smaller pieces, that we
call slivers, each representing a fraction of the original file. Any set
of slivers greater in total size to the original file can be decoded
back into the original file.
However, an issue with erasure coding arises when a storage
node goes offline, and needs to be replaced by another. Unlike fully
replicated systems, where data can simply be copied from one node
to another, RS-encoded systems require that all existing storage
nodes send their slivers to the substitute node. The substitute can
then recover the lost sliver, but this process results in 𝑂(|blob|)
data being transmitted across the network. Frequent recoveries can
erode the storage savings achieved through reduced replication,
which means that these systems need a low churn of storage nodes
and hence be less permisionless.
Regardless of the replication protocol, all existing decentral-
ized storage systems face an additional challenges: the need for a
continuous stream of challenges to ensure that storage nodes are
incentivized to retain the data and do not discard it. This is crucial
in an open, decentralized system that offers payments for storage
and goes beyond the honest/malicious setting. Current solutions
always assume that the network is synchronous such that the ad-
versary cannot read any missing data from honest nodes and reply
to challenges in time.
3The chance that all 25 storage nodes are adversarial and delete the file is 3−25 =
1.18 × 10−12.
Introducing Walrus
We introduce Walrus, a new approach to decentralized blob storage.
It follows the erasure codes type of architecture in order to scale
to 100s of storage nodes providing high resilience at a low storage
overhead. At the heart of Walrus, lies a new encoding protocol,
called Red Stuff that uses a novel two-dimensional (2D) encoding
algorithm that is self-healing. Specificaly, it enables the recovery
of lost slivers using bandwidth proportional to the amount of lost
data (𝑂( |blob|
𝑛
) in our case). Moreover, Red Stuff incorporates
authenticated data structures to defend against malicious clients,
ensuring that the data stored and retrieved remains consistent.
One unique feature of Red Stuff is its ability to work in an
asychronous network while supporting storage challenges, making
it the first of its kind. This is only possible thanks to the two-
dimensional encoding that allows for different encoding thresholds
per dimension. The low-threshold dimension can be used from
nodes that did not get the symbols during the write flow to recover
what they missed, whereas the high-threshold dimension can be
used for the read flow to prevent the adversary from slowing down
honest nodes during challenge periods and collecting sufficient
information to reply to challenges.
One final challenge for Walrus, and in general, any encoding-
based decentralized storage system is operating securely across
epochs each managed by a different committee of storage nodes.
This is challenging because we want to ensure uninterrupted avail-
ability to both read and write blobs during the naturally occurring
churn of a permissionless system, but if we keep writing data in the
nodes about to depart, they keep needing to transfer them to the
nodes that are replacing them. This creates a race for the resources
of those nodes, which will either stop accepting writes or fail to ever
transfer responsibility. Walrus deals with this through its novel
multi-stage epoch change protocol that naturally fits the principles
of decentralized storage systems.
In summary, we make the following contributions:
• We define the problem of Asynchronous Complete Data-Sharing
and propose Red Stuff, the first protocol to solve it efficiently
even under Byzantine Faults (Section 3)
• We present Walrus, the first permissionless decentralized stor-
age protocol designed for low replication cost and the ability to
efficiently recover lost data due to faults or participant churn
(Section 4).
• We show how Walrus leverages Red Stuff to implement the
first asynchronous challenge protocol (Section 4.6)
• We provide a production-ready implementation of Walrus and
deploy a public testnet of Walrus. We then measure its perfor-
mance and scalability in a real environment (Section 6).
2
Models and Definitions
Walrus relies on the following assumptions.
Cryptographic assumptions. Throughout the paper, we useℎ𝑎𝑠ℎ()
to denote a collision resistant hash function. We also assume the
existence of secure digital signatures and binding commitments.
Network and adversarial assumptions. Walrus runs in epochs,
each with a static set of storage nodes. At the end of the epoch
𝑛= 3𝑓+ 1 storage nodes are elected as part of the the storage
Walrus
Table 1: Comparing Replication Algorithms
Replication for 10−12 Security
Write/Read Cost
Single Shard Recovery Cost
Asychronous Challenges
Replication
25x
𝑂(𝑛|𝑏𝑙𝑜𝑏|)
𝑂(|𝑏𝑙𝑜𝑏|)
Unsupported
Classic ECC
3x
𝑂(|𝑏𝑙𝑜𝑏|)
𝑂(|𝑏𝑙𝑜𝑏|)
Unsupported
RedStuff
4.5x
𝑂(|𝑏𝑙𝑜𝑏|)
𝑂( |𝑏𝑙𝑜𝑏|
𝑛
)
Supported
committee of the epoch and each one controls a storage shard such
that a malicious adversary can control up to 𝑓of them.
The corrupted nodes can deviate arbitrarily from the protocol.
The remaining nodes are honest and strictly adhere to the protocol.
If a node controlled by the adversary at epoch 𝑒is not a part of the
storage node set at epoch 𝑒+ 1 then the adversary can adapt and
compromise a different node at epoch 𝑒+ 1 after the epoch change
has completed.
We assume every pair of honest nodes has access to a reliable
and authenticated channel. The network is asynchronous, so the
adversary can arbitrarily delay or reorder messages between honest
nodes, but must eventually deliver every message unless the epoch
ends first. If the epoch ends then the messages can be dropped.
Our goal is not only to provide a secure decentralized system
but to also detect and punish any storage node that does not hold
the data that it is assigned. This is a standard additional assumption
for dencentralized storage system to make sure that honest parties
cannot be covertly compromised forever.
Erasure codes. As part of Walrus, we propose Asynchronous
Complete Data Storage (ACDS) that uses an erasure coding scheme.
While not necessary for the core parts of the protocol, we also
assume that the encoding scheme is systematic for some of our
optimizations, meaning that the source symbols of the encoding
scheme also appear as part of its output symbols.
Let Encode(𝐵,𝑡,𝑛) be the encoding algorithm. Its output are 𝑛
symbols such that any 𝑡can be used to reconstruct 𝐵. This happens
by first splitting 𝐵into 𝑡symbols of size 𝑂( |𝐵|
𝑡) which are called
source symbols. These are then expanded by generating 𝑛−𝑡repair
symbols for a total of 𝑛output symbols. On the decoding side,
anyone can call Decode(𝑇,𝑡,𝑛) where𝑇is a set of at least𝑡correctly
encoded symbols, and it returns the blob 𝐵.
Blockchain substrate. Walrus uses an external blockchain as
a black box for all control operations that happen on Walrus. A
blockchain protocol can be abstracted as a computational black
box that accepts a concurrent set of transactions, each with an
input message 𝑇𝑥(𝑀) and outputs a total order of updates to be
applied on the state 𝑅𝑒𝑠(𝑠𝑒𝑞,𝑈). We assume that the blockchain
does not deviate from this abstract and does not censor 𝑇𝑥(𝑀)
indefinitely. Any high-performance modern SMR protocol satisfies
these requirements, in our implementation we use Sui [8] and have
implemented critical Walrus coordination protocols in the Move
smart contract language [7].
3
Asynchronous Complete Data Storage (ACDS)
We first define the problem of Complete Data Storage in a dis-
tributed system, and describe our solution for an asynchronous
network which we refer to as Asynchronous Complete Data Stor-
age (ACDS). Secondly, we show its correctness and complexity.
3.1
Problem Statement
In a nutshell a Complete Data Storage protocol allows a writer to
write a blob to a network of storage nodes (Write Completeness),
and then ensures that any reader can read it despite some failures
and byzantine behaviour amongst storage nodes (Validity); and
read it consistently, despite a potentially byzantine writer (Read
Consistency). More formally:
Definition 1 (Complete Data Storage). Given a network of𝑛= 3𝑓+1
nodes, where up to 𝑓are byzantine, let 𝐵be a blob that a writer 𝑊
wants to store within the network, and share it with a set of readers
𝑅. A protocol for Complete Data Storage guarantees three properties:
• Write Completeness: If a writer𝑊is honest, then every honest node
holding a commitment to blob 𝐵eventually holds a part 𝑝(derived
from 𝐵), such that 𝐵can be recovered from O
 |𝐵|
|𝑝|

parts.
• Read Consistency: Two honest readers, 𝑅1 and 𝑅2, reading a suc-
cessfully written blob 𝐵either both succeed and return 𝐵or both
return ⊥.
• Validity: If an honest writer𝑊successfully writes 𝐵, then an honest
reader 𝑅holding a commitment to 𝐵can successfully read 𝐵.
We present the ACDS protocols in a context where the storage
node set is fixed and static. And in subsequent sections describing
its use within Walrus, we discuss how it is adapted to allow for
churn into the committees of storage nodes.
3.2
Strawman Design
In this section, we iterate first through two strawman designs and
discuss their inefficiencies.
Strawman I: Full Replication. The simplest protocol uses full
replication in the spirit of Filecoin [30] and Arweave [45]. The
writer𝑊broadcasts its blob 𝐵along with a binding commitment to
𝐵(e.g., 𝐻𝐵= ℎ𝑎𝑠ℎ(𝐵)), to all storage nodes and then waits to receive
𝑓+ 1 receipt acknowledgments. These acknowledgments form an
availability certificate which guarantees availability because at least
one acknowledgement comes from an honest node. The writer 𝑊
can publish this certificate on the blockchain, which ensures that it
is visible to every other honest node, who can then request a Read(𝐵)
successfully. This achieves Write Completeness since eventually
all honest nodes will hold blob 𝐵locally. The rest of the properties
also hold trivially. Notice that the reader never reads ⊥.
Although the Full Replication protocol is simple, it requires the
writer to send an O(𝑛|𝐵|) amount of data on the network which is
also the total cost of storage. Additionally, if the network is asyn-
chronous, it can cost up to 𝑓+ 1 requests to guarantee a correct
Danezis et. al
S31
S11
S21
S41
Encode: 
from f+1 to n
slivers
Figure 1: Encoding a Blob in one dimension. First the blob is
split into 𝑓+ 1 systematic slivers and then a further 2𝑓repair
slivers are encoded
replica is contacted, which would lead to O(𝑛|𝐵|) cost per recov-
ering storage node with a total cost of O(𝑛2|𝐵|) over the network.
Similarly, even a read can be very inefficient in asynchrony, as the
reader might need to send 𝑓+ 1 requests costing O(𝑛|𝐵|).
Strawman II: Encode & Share. To reduce the upfront data dissem-
ination cost, some distributed storage protocols such as Storj [38]
and Sia [42] use RS-coding [32]. The writer 𝑊divides its blob 𝐵
into 𝑓+ 1 slivers and encodes 2𝑓extra repair slivers. Thanks to the
encoding properties, any 𝑓+1 slivers can be used to recover 𝐵. Each
sliver has a size of O( |𝐵|
𝑛). The writer 𝑊then commits to all the
slivers using a binding commitment such as a Merkle tree [27] and
sends each node a separate sliver together with a proof of inclusion4.
The nodes receive their slivers and check against the commitment;
if the sliver is correctly committed, they acknowledge reception
by signing the commitment. The writer 𝑊can then generate an
availability certificate from 2𝑓+ 1 signatures and post it on the
blockchain.
A reader continuously requests slivers from the nodes until it
receives 𝑓+ 1 valid replies (i.e., replies that are verified against
the commitment). The reader is guaranteed to receive them since
at least 𝑓+ 1 honest nodes have stored their sliver. The reader
then reconstructs blob 𝐵from the slivers and then additionally, re-
encodes the recovered value and recomputes the commitment [10,
27]. If writer 𝑊was honest, the recomputed commitment will
match the commitment from the availability certificate and the
reader outputs 𝐵. Otherwise, writer 𝑊may not have committed to
a valid encoding, in which case the commitments do not match and
the reader outputs ⊥.
As before, the nodes that did not get slivers during the sharing
phase can recover them by reading 𝐵. If the output of the read
operation is ⊥, the node returns ⊥on all future reads. Otherwise,
the node stores their encoded sliver and discards the rest of 𝐵. Note
this recovery process is expensive: recovery costs O(|𝐵|) even if
the storage cost afterwards is O( |𝐵|
𝑛).
This second protocol reduces the dissemination costs signifi-
cantly at the expense of extra computation (encoding/decoding
and committing to slivers from 𝐵). Disseminating blob 𝐵only costs
O(|𝐵|)5, which is the same cost as reading it. However, complete
dispersal still costs O(𝑛|𝐵|), because as we saw the process of re-
covering missing slivers requires downloading the entire blob 𝐵.
4Writer𝑊could prove consistency among all slivers, but this is overkill for ACDS.
5There may be an extra O(log𝑛) cost depending on the commitment scheme.
Given that there can be up to 𝑓storage nodes that did not manage
to get their sliver from writer 𝑊and need to invoke the recov-
ery protocol, the protocol has O(𝑛|𝐵|) total cost. This is not only
important during the initial dispersal, but also in cases where the
storage node set changes (at epoch boundaries) as the new set of
storage nodes need to read their slivers by recovering them from
the previous set of storage nodes.
3.3
Final design: Red Stuff
The encoding protocol above achieves the objective of a low over-
head factor with very high assurance, but is still not suitable for
a long-lasting deployment. The main challenge is that in a long-
running large-scale system, storage nodes routinely experience
faults, lose their slivers, and have to be replaced. Additionally, in
a permissionless system, there is some natural churn of storage
nodes even when they are well incentivized to participate.
Both of these cases would result in enormous amounts of data
being transferred over the network, equal to the total size of data
being stored in order to recover the slivers for new storage nodes.
This is prohibitively expensive. We would instead want the system
to be self-healing such that the cost of recovery under churn is
proportional only to the data that needs to be recovered, and scale
inversely with 𝑛.
To achieve this, Red Stuff encodes blobs in two dimensions (2D-
encoding). The primary dimension is equivalent to the RS-encoding
used in prior systems. However, in order to allow efficient recovery
of slivers of 𝐵we also encode on a secondary dimension. Red Stuff
is based on linear erasure coding (see section 2) and the Twin-code
framework [31], which provides erasure coded storage with efficient
recovery in a crash-tolerant setting with trusted writers. We adapt
this framework to make it suitable in the byzantine fault tolerant
setting with a single set of storage nodes, and we add additional
optimizations that we describe further below.
Encoding. Our starting point is the second strawman design that
splits the blobs into 𝑓+ 1 slivers. Instead of simply encoding repair
slivers, we first add one more dimension to the splitting process:
the original blob is split into 𝑓+ 1 primary slivers (vertical in
the figure) into 2𝑓+ 1 secondary slivers (horizontal in the figure).
Figure 2 illustrates this process. As a result, the file is now split into
(𝑓+ 1)(2𝑓+ 1) symbols that can be visualized in an [𝑓+ 1, 2𝑓+ 1]
matrix.
Given this matrix we then generate repair symbols in both di-
mensions. We take each of the 2𝑓+ 1 columns (of size 𝑓+ 1) and
extend them to 𝑛symbols such that there are 𝑛rows. We assign
each of the rows as the primary sliver of a node (Figure 2a). This
almost triples the total amount of data we need to send and is very
close to what 1D encoding did in the protocol in Section 3.2. In
order to provide efficient recovery for each sliver, we also take the
initial [𝑓+ 1, 2𝑓+ 1] matrix and extend with repair symbols each
of the 𝑓+ 1 rows (of size 2𝑓+ 1) and extend them to 𝑛symbols
(Figure 2b) using our encoding scheme. This creates 𝑛columns,
which we assign as the secondary sliver of each node, respectively.
Handling Metadata. For each sliver (primary and secondary),
𝑊also computes vector commitments over its symbols. For each
primary sliver, the commitment commits to all symbols in the
expanded row, and for each secondary sliver, it commits to all
Walrus
S31
S11
S21
S41
S32
S12
S22
S42
S33
S13
S23
S43
Encode columns: 
from f+1 to n
primary
slivers
(a) Primary Encoding in two dimensions. The file is split into 2𝑓+ 1 columns
and 𝑓+ 1 rows. Each column is encoded as a separate blob with 2𝑓repair
symbols. Then each extended row is the primary sliver of the respective node.
S14
S24
S11
S21
S12
S22
S13
S23
Encode rows: 
from 2f+1 to n
secondary slivers
(b) Secondary Encoding in two dimensions. The file is split into 2𝑓+1 columns
and 𝑓+ 1 rows. Each row is encoded as a separate blob with 𝑓repair symbols.
Then each extended columns is the secondary sliver of the respective node.
Figure 2: 2D Encoding / Red Stuff
symbols in the expanded column. As a last step, the client creates
a commitment over the list of these sliver commitments, which
serves as a blob commitment.
These vector commitments for each sliver form the blob meta-
data. Using these, nodes can later, when queried for a single symbol,
prove that the symbol they return is the symbol originally written.
However, these proofs require the opening of the commitments for
the respective sliver as well as of the blob commitment w.r.t. the
respective sliver commitment.
A node that holds all of their slivers can easily recompute the
sliver commitment and its openings, but to open the blob commit-
ment, all sliver commitments from all nodes are required.
If we naively replicate this metadata to every single storage node
to enable secure self-healing, we create a large overhead that is
quadratic in the number of nodes, since each node needs to store
the sliver commitments of all nodes. Especially for small blobs, this
can make a large difference in the relative overhead. For example,
using 32B hashes in a system of 1000 nodes would require storing
an additional 64kB on each node, or 64MB in total.
To reduce the overhead, storage nodes maintain an encoded
version of the metadata. Since all storage nodes need to get the
metadata in full when they invoke a write or recovery process,
there is no need for the client to perform the encoding or to do a
2D encoding. Instead, storage nodes can simply locally encode the
metadata with an 1D (f+1)-out-of-n encoding and keep the shard
assigned to them6. This reduces the overhead to a constant per
node, i.e., from quadratic to linear system-wide overhead.
Write protocol. The Write protocol of Red Stuff uses the same
pattern as the RS-code protocol. The writer 𝑊first encodes the
blobs and creates a sliver pair for each node. A sliver pair 𝑖is the
pair of 𝑖th primary and secondary slivers. There are 𝑛= 3𝑓+1 sliver
pairs, as many as nodes.
6They should also compute a commitment and an opening proof of their sliver.
Then, 𝑊sends all of sliver commitments to every node, along
with their respective sliver pair. The nodes check their own sliver in
the pair against the commitments, recompute the blob commitment,
and reply with a signed acknowledgment. When 2𝑓+ 1 signatures
are collected, 𝑊generates a certificate and posts it on-chain to
certify the blob will be available.
In theoretical asynchronous network models with reliable deliv-
ery the above would result in all correct nodes eventually receiving
a sliver pair from an honest writer. However, in practical protocols
the writer may need to stop re-transmitting. It is safe to stop the
re-transmission after 2𝑓+ 1 signatures are collected, leading to at
least 𝑓+ 1 correct nodes (out of the 2𝑓+ 1 that responded) holding
a sliver pair for the blob.
Read Protocol. The Read protocol is the same as for RS-codes.
In order to allow for asychronous challenge nodes only use their
secondary sliver. If this is not necessary, we can use the primary
sliver and have a faster reconstruction threshold of 𝑓+ 1.
𝑅first collects the metadata, i.e., the list of sliver commitments
for the blob commitment. To do so, 𝑅requests the 1D encoded
metadata parts from its peers along with the opening proofs.
After the metadata is decoded, 𝑅checks that the returned set
corresponds to the blob commitment. Then 𝑅requests a read for
the blob commitment from all nodes and they respond with the
secondary sliver they hold (this may happen gradually to save
bandwidth). Each response is checked against the corresponding
commitments in the commitment set for the blob. When 2𝑓+ 1
correct secondary slivers are collected 𝑅decodes 𝐵and then re-
encodes it to recompute the blob commitment and check that it
matches the blob commitment. If it is the same with the one 𝑊
posted on chain then 𝑅outputs 𝐵, otherwise it outputs ⊥.
Sliver recovery. The big advantage of Red Stuff compared to the
RS-code protocol is its self-healing property. This comes into play
when nodes that did not receive their slivers directly from𝑊try to
recover their sliver. Any storage node can recover their secondary
sliver by asking 𝑓+ 1 storage nodes for the symbols that exist in
their row, which should also exist in the (expanded) column of the
requesting node (fig. 3b and fig. 3c). This means that eventually all
2𝑓+ 1 honest nodes will have secondary slivers. At that point, any
node can also recover their primary sliver by asking the 2𝑓+1 honest
nodes for the symbols in their column (Figure 3d) that should also
exist in the (expanded) row of the requesting storage node. In each
case, the responding node also sends the opening for the requested
symbol of the commitment of the source sliver. This allows the
receiving node to verify that it received the symbol intended by the
writer 𝑊, which ensures correct decoding if 𝑊was honest.
Since the size of a symbol is O( |𝐵|
𝑛2 ) each, and each storage node
will download O(𝑛) total symbols, the cost per node remains at
O( |𝐵|
𝑛) and the total cost to recover the file is O(|𝐵|) which is
equivalent to the cost of a Read and of a Write. As a result by
using Red Stuff, the communication complexity of the protocol is
(almost7) independent of 𝑛making the protocol scalable.
Red Stuff is an ACDS. Section 5 provides proofs that Red Stuff
satisfies all properties of a ACDS. Informally, Write Completeness
7Depends on the commitment scheme used.
Danezis et. al
S14
S31
S11
S21
S41
S32
S12
S33
S13
S23
S43
(a) Nodes 1 and 3 collectively hold two rows and two columns
S14
S31
S11
S21
S41
S32
S12
S33
S13
S23
S23
S34
(b) Each node sends the intersection of their row/column with the column/row
of Node 4 to Node 4 (Red). Node 3 needs to encode the row for this.
S14
S24
S31
S11
S23
S41
S32
S12
S22
S42
S33
S13
S23
S43
S34
S44
Recover 
from f+1
(c) Node 4 uses the 𝑓+ 1 symbols on its column to recover the full secondary
sliver (Green). It will then send any other recovering node the recovered inter-
sections of its column to their row.
S14
S24
S31
S11
S23
S41
S32
S12
S22
S42
S33
S13
S23
S43
S34
S44
Recover from 2f+1
(d) Node 4 uses the 𝑓+1 symbols on its row as well as all the recovered secondary
symbols send by other honest recovering nodes (Green) (which should be at
least 2𝑓plus the 1 recovered in the previous step) to recover its primary sliver
(Dark Blue)
Figure 3: Nodes 1 and 3 helping Node 4 recover its sliver pair
is ensured by the fact that a correct writer will confirm that at
least 𝑓+ 1 correct nodes received sliver pairs before stopping re-
transmissions. And the sliver recovery algorithm can ensure that
the remaining honest nodes can efficiently recover their slivers
from these, until all honest nodes eventually hold their respective
sliver, or can prove that the encoding was incorrect. Validity holds
due to the fact that 2𝑓+ 1 correct nodes wil eventually hold correct
sliver pairs, and therefore a reader that contacts all nodes will
eventually get enough slivers to recover the blob. Read Consistency
holds since two correct readers that decode a blob from potentially
different sets of slivers, re-encode it and check the correctness of
the encoding. Either both output the same blob if it was correctly
encoded or both output ⊥if it was incorrectly encoded.
4
The Walrus Decentralized Secure Blob Store
Walrus is the integration of a blockchain as a control plane for
meta-data and governance, with an encoding and decoding algo-
rithm run by a separate committee of storage nodes handling blob
data contents. This architecture uses the Red Stuff encoding/de-
coding algorithm described in section 3.3, Merkle trees [27] as set
commitments, and the Sui blockchain [8] . Walrus can, however, be
generalized to any blockchains and encoding/decoding algorithm
that satisfies the minimal requirements described in Section 2.
We first describe Walrus flows in a single epoch and then we
discuss how we allow for storage node dynamic availability through
reconfiguration. Finally, we look into going beyond honest-malicius
and providing storage challenges. During an epoch, the interactions
of Walrus with the clients is through (a) writing a blob and (b)
reading a blob.
4.1
Writing a Blob
The process of writing a blob in Walrus can be seen in Algorithm 3
and Figure 4.
The process begins with the writer (➊) encoding a blob using Red
Stuff as seen in Figure 2. This process yields sliver pairs, a list of
Blockchain
N1
N2
N4
N3
User
4
5
3
1
2
build 
blob id
buy
space
collect
acks
publish
PoA
build
PoA
Figure 4: Walrus write flow. The user generates the blob id of the file
they wish to store; acquire storage space through the blockchain; submit the
encoded file to Walrus; collect 2𝑓+ 1 acknowledgements; and submit them as
proof of availability to the blockchain.
commitments to slivers, and a blob commitment. The writer derives
a blob id 𝑖𝑑𝐵by hashing the blob commitment with meta-data such
as the length of the file, and the type of the encoding.
Then, the writer (➋) submits a transaction on the blockchain
to acquire sufficient space for the blob to be stored during a se-
quence of epochs, and to register the blob. The size of the blob and
blob commitment are sent, which can be used to rederive 𝑖𝑑𝐵. The
blockchain smart contract needs to secure sufficient space to store
both the encoded slivers on each node, as well as store all metadata
associated with the commitments for the blob. Some payment may
be sent along with the transaction to secure empty space, or empty
space over epochs can be a resource that is attached to this request
to be used. Our implementation allows for both options.
Once the register transaction commits (➌), the writer informs
the storage nodes of their obligation to store the slivers of the blob
identified by 𝑖𝑑𝐵, sending them the transaction together with the
Walrus
commitments and the primary and secondary slivers assigned to
the respective storage nodes along with proofs that the slivers are
consistent with the published 𝑖𝑑𝐵. The storage node verifies the
commitments and responds with a signed acknowledgment over
𝑖𝑑𝐵once the commitments and the sliver pairs are stored.
Finally, the writer waits to collect 2𝑓+ 1 signed acknowledg-
ments (➍), which constitute a write certificate. This certificate is
then published on-chain (➎) which denotes the Point of Availability
(PoA) for the blob in Walrus. The PoA signals the obligation for
the storage nodes to maintain the slivers available for reads for the
specified epochs. At this point, the writer can delete the 𝑏𝑙𝑜𝑏from
local storage, and go offline. Additionally, this PoA can be used as
proof of availability of the 𝑏𝑙𝑜𝑏by the writer to third-party users
and smart-contracts.
Nodes listen to the blockchain for events indicating that a blob
reached its PoA. If they do not hold sliver pairs for this blobs they
execute the recovery process to get commitments and sliver pairs
for all blobs past their PoA. This ensures that eventually all correct
nodes will hold sliver pairs for all blobs.
4.2
Reading a Blob
In the read path, a reader may ask any of the storage nodes for
the commitments and secondary sliver (1) for a blob by 𝑖𝑑𝐵. Once
they collect 2𝑓+ 1 replies with valid proofs against 𝑖𝑑𝐵(2) they
reconstruct the blob. Then (3) the reader re-encodes the blob and
re-computes a blob id 𝑖𝑑′
𝐵. If 𝑖𝑑𝐵= 𝑖𝑑′
𝐵it outputs the blob, otherwise
the blob is inconsistent and the reader outputs ⊥.
Reads happen consistently across all readers thanks to the prop-
erties of Red Stuff. When no failures occur, reads only require
downloading sliver data slightly larger than the byte length of the
original blob in total.
4.3
Recovery of Slivers
One issue with writing blobs in asynchronous networks or when
nodes can crash-recover is that not every node can get their sliver
during the Write. This is not a problem as these protocols can func-
tion without completeness. Nevertheless, in Walrus we opted to
use a two-dimensional encoding scheme because it allows for com-
pleteness, i.e., the ability for every honest storage node to recover
and eventually hold a sliver for every blob past PoA. This allows (1)
better load balancing of read requests all nodes can reply to readers,
(2) dynamic availability of storage nodes, which enables reconfigu-
ration without needing to reconstruct and rewrite every blob, and
(3) the first fully asynchronous protocol for proving storage of parts
(described in Section 4.6).
All these benefits rely on the ability for storage nodes to recover
their slivers efficiently. The protocol closely follows the Red Stuff
recovery protocols illustrated in Figure 3. When a storage node sees
a certificate of a blob for which they did not receive slivers, it tries
to recover its sliver pair from the rest of the storage nodes. For this,
it requests from all storage nodes the symbols corresponding to the
intersection of the recovering node’s primary/secondary sliver with
the signatory nodes’ secondary/primary slivers. Given that 2𝑓+ 1
nodes signed the certificate, at least 𝑓+ 1 will be honest and reply.
This is sufficient for all 2𝑓+ 1 honest nodes to eventually hold their
secondary slivers. As a result, when all honest nodes hold their
secondary slivers, they can share those symbols corresponding to
the recovering nodes’ primary slivers, who will then get to the
2𝑓+ 1 threshold and also recover their primary sliver.
4.4
Handling Inconsistent Encoding from
Malicious Writers
One last case we need to discuss is when the client is malicious
and uploads slivers that do not correspond to the correct encoding
of a blob. In that case, a node may not be able to recover a sliver
that is consistent with the commitment from the symbols that it
received. However, in this case it is guaranteed to generate a third
party verifiable proof of inconsistency, associated with 𝑖𝑑𝐵.
The read process executed by a correct reader rejects any incon-
sistently encoded blob by default, and as a result sharing this proof
is not a necessity to ensure consistent reads. However agreeing
on the inconsistency allows nodes to delete this blobs’ data and
excluding it from the challenge protocol (section 4.6). To prove
inconsistency, the storage node shares the inconsistency proof—
consisting of the symbols that it received for recovery and their
inclusion proofs—with the other nodes who can verify it by per-
forming a trial recovery themselves. After verifying this fraud proof,
the node attests on-chain that 𝑖𝑑𝐵is invalid. After observing a quo-
rum of 𝑓+ 1 such attestations, all nodes will subsequently reply
with ⊥to any request for the inconsistent blob’s slivers, along with
a pointer to the on-chain evidence for the inconsistency.
4.5
Committee Reconfiguration
Walrus is a decentralized protocol, hence it is natural that the
set of storage nodes will fluctuate between epochs. When a new
committee replaces the current committee between epochs, recon-
figuration takes place. The goal of the reconfiguration protocol
is to preserve the invariant that all blobs past PoA are available,
no matter if the set of storage nodes changes. Subject of course
to 2𝑓+ 1 nodes being honest in all epochs. Reconfiguration may
take hours if a significant amount of data needs to be transferred
between nodes. In that period, Walrus must continue to perform
reads and writes for blobs to ensure no downtime.
Core Design. At a high-level the reconfiguration protocol of Wal-
rus is similar to the reconfiguration protocols of blockchain sys-
tems, since Walrus also operates in quorums of storage nodes.
However, the reconfiguration of Walrus has its own challenges
because the migration of state is orders of magnitude more expen-
sive than classic blockchain systems. The main challenge is the
race between writing blobs for epoch 𝑒and transferring slivers
from outgoing storage nodes to incoming storage nodes during
the reconfiguration event between 𝑒and 𝑒+ 1. More specifically,
if the amount of data written in epoch 𝑒is greater than the ability
of a storage node to transfer them over to the new storage node,
then the epoch will never finish. This problem is exacerbated when
some of the outgoing storage nodes of 𝑒are unavailable, as this
means that the incoming storage nodes need to recover the slivers
from the committee of epoch 𝑒. Fortunately, by using Red Stuff,
the bandwidth cost of the faulty case is the same as that of the
fault-free case. but it still requires more messages to be sent over
the network and more computation to verify proofs and to decode
symbols to slivers.
Danezis et. al
To resolve this problem without shutting off the write path, we
take a different approach by requiring writes to be directed to the
committee of 𝑒+ 1 the moment the reconfiguration starts, while
still directing reads to the old committee, instead of having a single
point at which both reads and writes are handed over to the new
committee. This can unfortunately create challenges when it comes
to reading these fresh blobs, as during the handover period it is
unclear which nodes store the data. To resolve this, we include in
the 𝑚𝑒𝑡𝑎𝑑𝑎of every 𝑏𝑙𝑜𝑏the epoch in which it was first written.
If the epoch is 𝑒+ 1 then the client is asked to direct reads to the
new committee; otherwise, it can direct reads to the old committee.
This happens only during handover period (when both committees
need to be live and secure).
Once a member of the new committee has bootstrapped their
part of the state, i.e., they have gotten all slivers for their shard, they
signal that they are ready to take over. When 2𝑓+ 1 members of
the new committee have signaled this, the reconfiguration process
finishes and all reads are redirected to the storage nodes of the new
committee.
Security arguments: In a nutshell, reconfiguration ensures all
ACDS properties across epochs. The key invariant is: the reconfig-
uration algorithm ensures that if a blob is to be available across
epochs, in each epoch 𝑓+1 correct storage nodes (potentially differ-
ent ones) hold slivers. This is the purpose of the explicit signaling
that unlocks the epoch change by 2𝑓+ 1 nodes. Therefore, even-
tually all other honest storage nodes can recover their sliver pairs,
and in all cases, 𝑓+ 1 honest nodes in the next epoch are able to
recover correct sliver pairs as a condition to move epochs.
4.6
Storage Challenges
Walrus uses a challenge protocol to prevent cheating nodes that
trivially never store or serve data from receiving rewards and to
incentivize honest nodes. To the best of our knowledge, we present
here the first storage proof protocol to make no assumptions about
network synchrony. It leverages the completeness property of Red
Stuff and the ability to reconstruct blobs with 2𝑓+ 1 threshold. In
this section, we first present the simple protocol that is theoretically
secure but costly. Then we discuss a relaxation that makes the se-
curity probabilistic but reduces the cost of challenging significantly
and can be tuned dynamically if reads start to fail.
Fully Asynchronous Challenge Protocol. Close to the end of the
epoch, the storage nodes witness a “challenge start” event on-chain,
such as a specific block height. At that point, they stop serving read
and recovery requests and broadcast an acknowledgment. When
2𝑓+1 honest nodes have entered the challenge phase, the challenges
start.
Every challenged node sends the common symbols per blob to
each other along with a proof against the commitment of the writer
of the blob. The receiving nodes check the symbols and send a
confirmation signature. When the proving storage node collects
2𝑓+ 1 signatures, it forms a certificate, which it submits on-chain.
When 2𝑓+ 1 certificates are valid, the challenge period ends, and
the reads and recovery are re-enabled.
During the challenge period, the nodes that witnessed the chal-
lenge start message do not respond to read or recovery requests.
Since the threshold for starting a challenge is 2𝑓+ 1, at least 𝑓+ 1
honest will not reply after the challenged files are determined. As
a result, even if the adversary has 𝑓slivers stored and has slowed
down 𝑓honest nodes to not see the challenge start message, it
can only get 2𝑓symbols from their secondary slivers and then 2𝑓
signatures on its certificate. These are not enough to recover the
full secondary sliver and convince the rest of the honest nodes to
sign the certificate, and as a result, it will fail the challenge. The
proof can be seen in Section 5.4.
Relaxations. Although this protocol is secure, it has the caveat
that no reads are served during the challenge period and that a full-
blown challenge requires bandwidth equal to the amount stored. To
reduce its impact, we plan to trade-off security for allowing most
blobs to be readable and not under a challenge.
For the lighweight challenge protocol, we require the storage
nodes to setup a random coin with a 2𝑓+1 reconstruction threshold.
This is possible using any kind of asynchronous DKG [13, 14, 20]
or randomness generation protocol [17, 39].
The coin is used to seed a pseudo-random function (PRF) that
defines which blobs need to be challenged per storage node. Any
blob not in the set can be accessible directly again. The number
of blobs challenged needs to be sufficiently large compared to the
total number of blobs such that storage nodes have a negligible
probability of holding all the challenged blobs unless they hold the
overwhelming majority of blobs. For example, if a storage node
holds 90% (99%) of the blobs, it has less than a 10−30 probability of
success in a 640 (7000) file challenge.
If we notice that reads fail although challenges pass, it means that
we do not challenge enough files. In this case, Walrus will increase
the challenges up to the point of reenabling the full challenge
protocol. However, for this to happen, it means that the malicious
storage nodes have minimal storage savings (less than a constant
factor), which is unlikely to have a real impact on their resource
cost.
5
Red Stuff and Walrus Proofs
This section completes Section 3 by showing that Red Stuff satis-
fies all the properties of a ACDS. The casual reader can skip it.
5.1
Write Completeness
We show that Red Stuff satisfies Write Completeness. Informally,
if an honest writer writes a blob 𝐵to the network, every honest
storage node eventually holds a primary and secondary correctly
encoded sliver of 𝐵. For this part we assume the writer is honest
and provides a correct vector commitment 𝑀.
Lemma 1 (Primary Sliver Reconstruction). If a party holds a set
of (2𝑓+ 1) symbols {𝐸(𝑖, ∗)}2𝑓+1from a primary sliver 𝑆(𝑝,𝑖), it can
obtain the complete primary sliver 𝑆(𝑝,𝑖).
Proof. The proofs directly follows from the reconstruction
property of erasure codes with reconstruction threshold (2𝑓+
1).
□
Lemma 2 (Secondary Sliver Reconstruction). If a party holds a set
of (𝑓+ 1) symbols {𝐸(∗,𝑖)}𝑓+1 from a secondary sliver 𝑆(𝑠,𝑖), it can
obtain the complete secondary sliver 𝑆(𝑠,𝑖).
Walrus
Proof. The proofs directly follows from the reconstruction
property of erasure codes with reconstruction threshold (𝑓+1).
□
Theorem 1. Red Stuff satisfies Write Completeness (Definition 1).
Proof. To write a blob 𝐵, an honest writer 𝑊sends at least
(2𝑓+ 1) correctly encoded slivers (parts) to different storage nodes,
along with a binding vector commitment 𝑀over those slivers. For
these nodes the property holds by definition. Now let’s assume a
node 𝑗that is not in the initial 2𝑓+ 1 recipients. The node will ask
every node 𝑖for their shared symbols in its primary (i.e., 𝐸(𝑗,𝑖)) and
secondary (i.e., 𝐸(𝑖, 𝑗)) sliver. Given the binding vector commitment
𝑀node 𝑖can either send the true symbols or not reply. Given that
at least 2𝑓+ 1 nodes acknowledged 𝑀then 𝑗will get 𝑓+ 1 correct
symbols for its primary sliver {𝐸(𝑗, ∗)}𝑓+1 and 𝑓+1 correct symbols
for its secondary sliver {𝐸(∗, 𝑗)}𝑓+1. From Lemma 2 this means that
𝑗will reconstruct its full secondary sliver 𝑆(𝑠,𝑗) .
Since this reasoning applies to any generic node 𝑖, it holds for all
nodes. As a result, eventually all 2𝑓+1 honest nodes will reconstruct
their secondary slivers 𝑆(𝑠,∗). Every time a node reconstructs their
secondary sliver, they also reply to node 𝑗with the shared symbol
which is part of the primary sliver of 𝑗(i.e., 𝐸(𝑗, ∗)) . As a result,
eventually 𝑗will go from {𝐸(𝑗, ∗)}𝑓+1 to {𝐸(𝑗, ∗)}2𝑓+1 This allows
node 𝑗to apply Lemma 1 and reconstruct its primary sliver 𝑆(𝑝,𝑗).
Since this reasoning applies to any generic node 𝑖, it holds for all
nodes and concludes the proof that all honest nodes will eventually
hold both their primary and secondary sliver.
□
5.2
Read Consistency
We prove that Red Stuff satisfies Read Consistency. Informally,
if two honest readers read a blob 𝐵written to the network, they
either both eventually obtain 𝐵or both eventually fail and obtain
⊥.
Theorem 2. Red Stuff satisfies Read Consistency (Definition 1).
Proof. Notice that the encoding scheme is deterministic and
the last step of reading is to re-run the encoding and reconstruct
𝑀. As a result, a reader that accepts the read as correct needs to
output 𝐵.
The challenge with Read Consistency is if the writer can convince
different readers that collect different slivers to output 𝐵and ⊥.
Let’s assume that two honest readers 𝑅1 and 𝑅2 read a blob 𝐵from
the network and 𝑅1 eventually obtains 𝐵while 𝑅2 eventually fails
and obtains ⊥.
There are two scenarios for 𝑅2 to output ⊥:
(1) 𝑅2 gets 2𝑓+ 1 replies matching 𝑀and tries to reconstruct.
During reconstruction, the commitment does not much 𝑀
(2) Some node failed to reconstruct their secondary sliver. By the
algorithm this nodes will hold a proof of inconsistency, which
it will send to 𝑅2
In either scenario 𝑅1 during their reconstruction should have
also detected the inconsistency and output ⊥otherwise the bind-
ing property of the vector commitment does not hold. Hence a
contradiction.
□
5.3
Validity
We prove that Red Stuff satisfies Validity. Informally, if an honest
writer writes a correctly encoded blob 𝐵to the network, every
honest reader eventually obtains 𝐵.
Theorem 3 (Validity). Red Stuff satisfies Validity (Definition 1).
Proof. To write a blob 𝐵, an honest writer𝑊construct𝑛correct
encoded slivers (parts) along with a binding vector commitment 𝑀
over those slivers. Since the writer is honest from Theorem 1 all (at
least 2𝑓+ 1) honest storage nodes will hold their respective slivers.
Let’s note by nodes the entire set of storage nodes. An honest
reader queries each storage node 𝑛∈nodes for their secondary
sliver, verifies them against 𝑀and when it holds 2𝑓+ 1 uses them
to reconstruct the 𝐵. Since all honest storage nodes will eventually
reply to the reader and 𝑊was honest, the reader will eventually
obtain 𝐵.
□
5.4
Asychronous Challenges
We prove that no malicious storage node that does not hold all
slivers of blobs will succeed in replying to a challenge. We note
that storage nodes of the adversary can collude and hold a single
version of their common symbols. However, they would still need
to hold 2𝑓+ 1 symbols per sliver which is effectively the cost of a
full sliver as far as storage is concerned.
Theorem 4 (Secure Challenge Protocol). No malicious storage node
running Walrus that does not hold all slivers of blobs will succeed in
replying to a challenge.
Proof. We assume there exists a storage node that deletes a
symbol it is supposed to hold and the respective symbol is held by
an honest node. At challenge time it will need to send this symbol to
the honest node to get a certificate. To do so, it will need to recover
the sliver. For this it will get 𝑓−1 symbols from the other malicious
storage nodes. It can also get 𝑓symbols from slow, honest nodes
through the read path. However 𝑓+ 𝑓−1 = 2𝑓−1. From lemma 1
the node need 2𝑓+ 1 to reconstruct the primary sliver and get this
symbol. Hence it will fail to reply.
If it fails to reply then it cannot get a certificate as only the
2𝑓−1 node mentioned above plus its self-signature will be collected,
resulting in 2𝑓< 2𝑓+ 1 signatures.
□
6
Evaluation
We implement a production-ready networked multi-core Walrus
storage node in Rust. All networking uses HTTPS through axum [35],
it uses fastcrypto [21] for cryptography, rocksdb [28] for storage,
and reed-solomon-simd [24] for erasure coding. We opt to connect
our implementation to Sui [40] as an example of fast blockchain.
We release the codebase as open-source8.
We evaluate Walrus’s performance and scalability on the real,
publicly available, testnet. This is the most realistic evaluation set-
ting, exposing the system to real-world conditions, real users, and
infrastructure outside our control. We observe the Walrus testnet
over a period of 60 days, ending the 22nd of March.
Our evaluation aims at demonstrating the following claims:
8 https://github.com/mystenLabs/walrus
Danezis et. al
eu-north
eu-east
eu-west
ca-central
us-west
us-east
sa-east
ap-southeast
unknown
0
100
200
300
Shards
Figure 5: Geo-distribution of shards.
Hetzner
Cherry servers
Leaseweb
Ovh
Webnx
Worldstream
Skyskipper
Synlinq
Interserver
Unknown
Terraswitch baremetal
Reg.ru
Atomic servers
Teraswitch
Latitude
Aws
Colocation
Alibaba cloud
Data packet
Gcp
Self-Hosted
Interserver.net
Velia
0
50
100
150
Shards
Figure 6: Distribution of shards by hosting providers.
(1) C1 (low latency): Walrus achieves low latency, bounded by
network delay.
(2) C2 (throughput): Walrus clients achieve high read and write
throughput.
(3) C3 (scalability): Walrus’s total capacity scales with the num-
ber of storage nodes.
6.1
Experimental Setup
The Walrus testbed is decentralized, comprising 105 independently
operated storage nodes and 1,000 shards. All reported measure-
ments are based on data voluntarily shared by node operators.
Shards are allocated based on each operator’s stake, reflecting the
mainnet deployment model. Satisfying the 𝑓+ 1 quorum requires
collaboration from at least 19 nodes; the 2𝑓+ 1 quorum requires
38 nodes. No operator controls more than 18 shards. Nodes span
at least 17 countries, including Lithuania, USA, France, Canada,
Netherlands, Thailand, Ireland, Russia, and others. Eleven operators
did not disclose their location. Figure 5 details the shard distribution
by region. The “eu-west” region aggregates shards from at least
five countries. Roughly 220 shards are labeled “unknown” due to
missing regional data. Figure 6 shows shard distribution by hosting
providers. “Self-Hosted” nodes run on-premises, while “Unknown”
indicates missing provider information.
Most nodes run Ubuntu (22.04 or 24.04) with at least 16 CPU
cores, 128 GB RAM, and 1 Gbps bandwidth. Hardware varies across
Intel and AMD CPUs and HDD, SSD, and NVMe storage. Node
storage ranges from 15 to 400 TB (median 56.9 TB, P90 69.98 TB).
0
20M
40M
60M
80M
100M
120M
140M
Blob Size (B)
0
25
50
75
100
125
Latency (s)
read
write
Figure 7: Latency for different blob sizes.
6.2
System Performance
We evaluate performance from the client’s perspective, deploying
two clients on AWS m5d.8xlarge instances (10 Gbps bandwidth,
32 vCPUs, 128 GB RAM, Ubuntu 22.04). One client runs in US East
(N. Virginia), the other in Canada Central.
Walrus Latency. Figure 7 illustrated the end-to-end latency expe-
rienced by the client. We start measuring before the client encodes
the blob and finish when it observes a proof-of-availability con-
firmation on the blockchain. Each point represents the p50 over 5
minutes of runs; error bars indicate p90.
The graph shows that read latency remains low, even for large
blobs. For small blobs (less than 20 MB), the latency stays below 15
seconds. For large blobs (130 MB), the latency increases to around
30 seconds.
Write latency is consistently higher than read latency. For small
blobs (less than 20 MB), write latency remains relatively flat and
stays under 25 seconds. This overhead is primarily due to the
blockchain interaction and the need to upload metadata to all stor-
age nodes, rather than the blob size itself. For large blobs (greater
than 40 MB), latency grows linearly with the blob size as network
transfer becomes the dominant cost. Figure 8 and Figure 9 illus-
trate this behavior by breaking down the latency for small blobs
(1 KB) and large blobs (130 MB), respectively. Each write operation
consists of five key steps: encoding (time to erasure-code the blob),
check status (time to check the blob’s current state), get info (time to
fetch blob status and reserve space), store (time to upload slivers to
storage nodes), and publish PoA (time to commit the proof of avail-
ability to the blockchain). For small blobs, the fixed overhead from
metadata handling and blockchain publication dominates, adding
roughly 6 seconds—about 50% of the total write latency. For large
blobs, the storage phase dominates due to network transfer, while
metadata operations and blockchain interaction remain relatively
constant.
These results validate our claim C1: Walrus achieves low latency
and is bounded by network delays.
Single Client Throughput. Figure 10 illustrates the throughput
that can be achieved by a single client in bytes per second. As
expected, read throughput scales linearly with blob size as it is
mostly network interactions. Write throughput plateaus around
18 MB/s because of the need to interact with the blockchain and
the storage nodes multiple times. This does not mean that a user
cannot upload faster, as Sui supports a much higher throughput in
transactions per second, but that a single blob cannot be uploaded
faster. For much larger blobs, a user can deploy multiple clients,
Walrus
Encoding Check Status
Get Info
Store
Publish PoA
0
2
4
6
Latency (s)
Figure 8: Latency breakdown for small blobs (1KB).
Encoding Check Status
Get Info
Store
Publish PoA
0
25
50
75
100
125
Latency (s)
Figure 9: Latency breakdown for large blobs (130MB).
0
20M
40M
60M
80M
100M
120M
140M
Blob Size (B)
0
20M
40M
60M
Client Throughput (B/s)
read
write
Figure 10: Single client throughput for different blob sizes.
each uploading a chunk of data in parallel, effectively creating a
fan-out pattern.
These results validate C2: Walrus enables clients to read and
write at high throughput.
6.3
Scalability
Over 60 days, Walrus stores a median of 1.18 TB of slivers (P90 1.08
TB) and 221.5 GB of blob metadata (P90 46.34 GB). As described in
Section 6.1, each storage node contributes between 15 and 400 TB
of capacity. Yet, the system as a whole can store over 5 PB—a key
feature of Walrus. Figure 11 illustrates how Walrus’s total storage
capacity scales with the committee size. This result supports our
final claim C5: the system’s capacity grows proportionally with the
number of storage nodes.
7
Related Work
Censorship resistant storage and blob data dissemination motivated
much of the early peer-to-peer movement and the need for decen-
tralization. Within academia Anderson proposed the Eternity ser-
vice [3] in 1996, to ensure documents cannot be suppressed. Within
the commercial and open source communities systems like Nap-
ster [9], Gnutella [33], and Free Haven [15] and early Freenet [11]
used nodes in an unstructured topology to offer storage, routing and
distribution largely of media files. These systems operated on the
0
20
40
60
80
100
Storage Nodes
0
1P
2P
3P
4P
5P
Storage Capacity (B)
Figure 11: Storage capacity versus committee size.
basis of centralized or flood fill algorithms for lookup and search;
and full replication of files, often on node used to route responses.
These provide best effort security and poor performance.
Later research, in the early 2000s, proposed structured peer-to-
peer topologies in the form of distributed hash tables (DHT), such
as Chord [37], Pastry [34], Kademlia [26], largely to improve lookup
performance, as well as reduce the replication factor for each file.
DHTs remarkably do not require consensus or full state machine
replication to operate. However, have been shown to be susceptible
to a number of attacks: Sybil attacks [16] were named and identified
within the context of these systems first; and they are hard to defend
against routing attacks [43]. Many attacks affect current systems
that use them [41]. Bittorrent [12] eventually came to dominate the
file dissemination application space, in part due to its simplicity
and built-in incentives. It initially used a full replication strategy
for storage and centralized trackers for node coordination. It later
added decentralized trackers based on Kademlia.
In contrast to these early system Walrus maintains a full and
consistent list of all nodes through using the Sui [8] blockchain, as
well as their latest meta-data. It assumes these are infrastructure
grade nodes and will not suffer great churn, but rather operate to
get incentives and payments, and come in and out of the system
based on a reconfiguration protocol.
In the blockchain era, IPFS [5] provides a decentralized store
for files, and is extensively being used by blockchain systems and
decentralized apps for their storage needs. It provides content ad-
dressable storage for blocks, and uses a distributed hash table (DHT)
to maintain a link between file replicas and nodes that store them.
Publishers of files need to pin files to storage nodes, to ensure files
remain available, usually against some payment. The underlying
storage uses full replication on a few nodes for each file.
Filecoin [30] extends IPFS, using a longest chain blockchain and a
cryptocurrency (FIL) used to incentivize storage nodes to maintain
file replicas. Publishers acquire storage contracts with a few nodes,
and payments are made in the cryptocurrency. Filecoin mitigates
the risk that these nodes delete the replicas by requiring storage
nodes to hold differently encoded copies of the file, and performing
challenges against each other for the encoded files. These copies are
encoded in such a way that it is slow to reproduce them from the
original copy, to avoid relay attacks. As a result, if the user wants to
access the original file, it needs to wait a long time for the decoding
of a copy, unless some storage node has a hot copy. Since, there
is no in-built incentive for storing hot copies, this service usually
costs extra.
Arweave [45] mitigates slow reads through a Proof-of-Access
algorithm that incentives storage nodes to have as many files as
Danezis et. al
possible locally to maximise rewards. This is implemented in con-
junction with a full replication strategy, and results in replication
levels almost equal to classic state machine replication. Addition-
ally, the system only allows file to be stored ‘for ever’, through a
mechanisms of pre-payment - which lacks the flexibility to control
lifetime and deletion, and is capital inefficient since payment is
upfront.
In contrast to Filecoin and Arweave, Walrus uses erasure coding
to maintain a very low overhead of 4.5x while ensuring data sur-
vives up to 2/3 of any shards being lost, and continues to operate by
allowing writes even if up to 1/3 of shards are unresponsive. Furthe-
more, Walrus does not implement its own separate blockchain to
do node management and provide incentives, but uses Sui instead.
Storj [38] represents another decentralized storage solution that
leverages encoding to achieve a low replication factor. The system
implements a Reed-Solomon based erasure coding scheme with a
29/80 configuration, wherein a file is encoded into 80 parts, with
any 29 sufficient for reconstruction. This approach results in a 2.75𝑥
replication factor, offering a substantial reduction in storage costs
compared to prior systems. However, a key limitation of Storj lies
in its inability to efficiently heal lost parts. The system relies on
users to reconstruct the full file and subsequently re-encode it to
facilitate the recovery of lost parts. In contrast Walrus’s use of Red
Stuff incorporates an efficient reconstruction mechanism which
is critical for the efficient healing of the erasure coding scheme,
especially due to churn which is naturally occuring in a permission-
less system. Red Stuff builds on the Twin-code framework [31],
which uses two linear encodings of data to enhance the efficiency
of sliver recovery. However, unlike the Twin-code framework [25],
Red Stuff encodes data across differently sized dimensions and
integrates authenticated data structures, achieving Completeness
(as defined in Section 2) and ensuring Byzantine Fault Tolerance.
Modern blockchains provide some storage, but it is prohibitively
expensive to store larger blobs due to the costs of full replication
across all validators, as well as potentially long retention times to
allow verifiability. Within the Ethereum eco-system specifically, the
current scaling strategy around L2s involves posting blobs of trans-
actions on the main chain, representing bundles of transactions to
be executed, and verified either via zero-knowledge or fraud proofs.
Specialised networks, such as Celestia based on availability sam-
pling [2], have emerged to fulfill this need off the main Ethereum
chain. In Celestia, two dimensional Reed-Solomon codes are used to
encode blobs, and code words distributed to light nodes to support
‘trustless’ availability. However, all blobs are fully replicated across
the validators of the system, for a limited time period of about
month. Walrus instead offers proofs of availability with arbitrarily
long retention periods and a reduced cost of storage per node which
allows the system to scale inpexpensively.
8
Conclusion
We introduce Walrus, a novel approach to decentralized blob stor-
age that leverages fast erasure codes and a modern blockchain
technology. By utilizing the Red Stuff encoding algorithm and the
Sui blockchain, Walrus achieves high resilience and low storage
overhead while ensuring efficient data management and scalabil-
ity. Our system operates in epochs, with all operations sharded
by 𝑏𝑙𝑜𝑏𝑖𝑑, enabling it to handle large volumes of data effectively.
The innovative two-dimensional BFT encoding protocol of Red
Stuff allows for efficient data recovery, load balancing, and dy-
namic availability of storage nodes, addressing key challenges faced
by existing decentralized storage systems.
Furthermore, Walrus introduces storage proofs that ensure data
availability without relying on network synchrony assumptions,
and its committee reconfiguration protocol guarantees uninter-
rupted data availability during network evolution. By combining
these features, Walrus offers a scalable, and resilient decentral-
ized storage, providing high authenticity, integrity, auditability, and
availability at a reasonable cost. Our contributions include defining
the problem of Asynchronous Complete Data-Sharing, presenting
the Red Stuff protocol, and proposing an asynchronous challenge
protocol for efficient storage proofs, paving the way for future
advancements in decentralized storage technologies.
Acknowledgments
We would like to express our gratitude to Dmitry Perelman, Sadhan
Sood, Zue Wu, He Liu, and Pei Deng for their invaluable contribu-
tions in bringing Walrus to production. We also extend our sincere
appreciation to Damir Shamanaev for his assistance in constructing
the smart contracts that connect Walrus with the Sui blockchain.
Lastly, we would like to extend a special thank you to Joachim
Neu for identifying a serious vulnerability in our previous Testnet
implementation. This vulnerability was related to its utilization of
RaptorQ for erasure coding and lead us to replace it with RS Codes.
References
[1] Mustafa Al-Bassam. 2019. Lazyledger: A distributed data availability ledger with
client-side smart contracts. arXiv preprint arXiv:1905.09274 (2019).
[2] Mustafa Al-Bassam, Alberto Sonnino, Vitalik Buterin, and Ismail Khoffi. 2021.
Fraud and data availability proofs: Detecting invalid blocks in light clients. In
Financial Cryptography and Data Security: 25th International Conference, FC
2021, Virtual Event, March 1–5, 2021, Revised Selected Papers, Part II 25. Springer,
279–298.
[3] Ross Anderson. 1996. The Eternity Service. In Proceedings of Pragocrypt ’96.
[4] Pablo Aragón, Andreas Kaltenbrunner, Antonio Calleja-López, Andrés Pereira,
Arnau Monterde, Xabier E Barandiaran, and Vicenç Gómez. 2017. Deliberative
platform design: The case study of the online discussions in Decidim Barcelona.
In Social Informatics: 9th International Conference, SocInfo 2017, Oxford, UK, Sep-
tember 13-15, 2017, Proceedings, Part II 9. Springer, 277–287.
[5] Juan Benet. 2014. Ipfs-content addressed, versioned, p2p file system. arXiv
preprint arXiv:1407.3561 (2014).
[6] Nazanin Zahed Benisi, Mehdi Aminian, and Bahman Javadi. 2020. Blockchain-
based decentralized storage networks: A survey. Journal of Network and Computer
Applications 162 (2020), 102656.
[7] Sam Blackshear, Evan Cheng, David L Dill, Victor Gao, Ben Maurer, Todd
Nowacki, Alistair Pott, Shaz Qadeer, Dario Russi Rain, Stephane Sezer, et al.
2019. Move: A language with programmable resources. Libra Assoc (2019), 1.
[8] Sam Blackshear, Andrey Chursin, George Danezis, Anastasios Kichidis, Lefteris
Kokoris-Kogias, Xun Li, Mark Logan, Ashok Menon, Todd Nowacki, Alberto
Sonnino, et al. 2023. Sui lutris: A blockchain combining broadcast and consensus.
arXiv preprint arXiv:2310.18042 (2023).
[9] Bengt Carlsson and Rune Gustavsson. 2001. The rise and fall of napster-an
evolutionary approach. In International Computer Science Conference on Active
Media Technology. Springer, 347–354.
[10] Dario Catalano and Dario Fiore. 2013. Vector commitments and their applications.
In Public-Key Cryptography–PKC 2013: 16th International Conference on Practice
and Theory in Public-Key Cryptography, Nara, Japan, February 26–March 1, 2013.
Proceedings 16. Springer, 55–72.
[11] Ian Clarke, Oskar Sandberg, Brandon Wiley, and Theodore W Hong. 2001.
Freenet: A distributed anonymous information storage and retrieval system.
In Designing privacy enhancing technologies: international workshop on design
issues in anonymity and unobservability Berkeley, CA, USA, July 25–26, 2000
Proceedings. Springer, 46–66.
[12] Bram Cohen. 2003. Incentives build robustness in BitTorrent. In Workshop on
Economics of Peer-to-Peer systems, Vol. 6. Berkeley, CA, USA, 68–72.
Walrus
[13] Sourav Das, Zhuolun Xiang, Lefteris Kokoris-Kogias, and Ling Ren. 2023. Prac-
tical asynchronous high-threshold distributed key generation and distributed
polynomial sampling. In 32nd USENIX Security Symposium (USENIX Security 23).
5359–5376.
[14] Sourav Das, Thomas Yurek, Zhuolun Xiang, Andrew Miller, Lefteris Kokoris-
Kogias, and Ling Ren. 2022. Practical asynchronous distributed key generation.
In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2518–2534.
[15] Roger Dingledine, Michael J Freedman, and David Molnar. 2001. The free haven
project: Distributed anonymous storage service. In Designing Privacy Enhancing
Technologies: International Workshop on Design Issues in Anonymity and Unob-
servability Berkeley, CA, USA, July 25–26, 2000 Proceedings. Springer, 67–95.
[16] John R Douceur. 2002. The sybil attack. In International workshop on peer-to-peer
systems. Springer, 251–260.
[17] Kobi Gurkan, Philipp Jovanovic, Mary Maller, Sarah Meiklejohn, Gilad Stern, and
Alin Tomescu. 2021. Aggregatable distributed key generation. In Annual Inter-
national Conference on the Theory and Applications of Cryptographic Techniques.
Springer, 147–176.
[18] Martin Kleppmann, Paul Frazee, Jake Gold, Jay Graber, Daniel Holmgren, Devin
Ivy, Jeromy Johnson, Bryan Newbold, and Jaz Volpert. 2024. Bluesky and the
AT protocol: Usable decentralized social media. arXiv preprint arXiv:2402.03239
(2024).
[19] Eleftherios Kokoris Kogias, Enis Ceyhun Alp, Linus Gasser, Philipp Svetolik
Jovanovic, Ewa Syta, and Bryan Alexander Ford. 2021. Calypso: Private data
management for decentralized ledgers. Proceedings of the VLDB Endowment 14,
4 (2021), 586–599.
[20] Eleftherios Kokoris Kogias, Dahlia Malkhi, and Alexander Spiegelman. 2020.
Asynchronous Distributed Key Generation for Computationally-Secure Ran-
domness, Consensus, and Threshold Signatures.. In Proceedings of the 2020 ACM
SIGSAC Conference on Computer and Communications Security. 1751–1767.
[21] Mysten Labs. 2025. Fastcrypto. =https://github.com/MystenLabs/fastcrypto.
[22] Chris Lamb and Stefano Zacchiroli. 2021. Reproducible builds: Increasing the
integrity of software supply chains. IEEE Software 39, 2 (2021), 62–70.
[23] Chuanlei Li, Minghui Xu, Jiahao Zhang, Hechuan Guo, and Xiuzhen Cheng. 2024.
SoK: Decentralized Storage Network. Cryptology ePrint Archive (2024).
[24] malair. 2025.
Reed-Solomon SIMD.
=https://github.com/AndersTrier/reed-
solomon-simd.
[25] Ninoslav Marina, Aneta Velkoska, Natasha Paunkoska, and Ljupcho Baleski.
2015. Security in twin-code framework. In 2015 7th International Congress on
Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT).
IEEE, 247–252.
[26] Petar Maymounkov and David Mazieres. 2002. Kademlia: A peer-to-peer infor-
mation system based on the xor metric. In International workshop on peer-to-peer
systems. Springer, 53–65.
[27] Ralph C Merkle. 1987. A digital signature based on a conventional encryption
function. In Conference on the theory and application of cryptographic techniques.
Springer, 369–378.
[28] Metar. 2025. Rocksdb. =https://rocksdb.org.
[29] Kirill Nikitin, Eleftherios Kokoris-Kogias, Philipp Jovanovic, Nicolas Gailly, Linus
Gasser, Ismail Khoffi, Justin Cappos, and Bryan Ford. 2017.
{CHAINIAC}:
Proactive {Software-Update} transparency via collectively signed skipchains
and verified builds. In 26th USENIX Security Symposium (USENIX Security 17).
1271–1287.
[30] Yiannis Psaras and David Dias. 2020. The interplanetary file system and the
filecoin network. In 2020 50th Annual IEEE-IFIP International Conference on De-
pendable Systems and Networks-Supplemental Volume (DSN-S). IEEE, 80–80.
[31] KV Rashmi, Nihar B Shah, and P Vijay Kumar. 2011. Enabling node repair in
any erasure code for distributed storage. In 2011 IEEE international symposium
on information theory proceedings. IEEE, 1235–1239.
[32] Irving S Reed and Gustave Solomon. 1960. Polynomial codes over certain finite
fields. Journal of the society for industrial and applied mathematics 8, 2 (1960),
300–304.
[33] Matei Ripeanu. 2001. Peer-to-peer architecture case study: Gnutella network. In
Proceedings first international conference on peer-to-peer computing. IEEE, 99–100.
[34] Antony Rowstron and Peter Druschel. 2001. Pastry: Scalable, decentralized object
location, and routing for large-scale peer-to-peer systems. In Middleware 2001:
IFIP/ACM International Conference on Distributed Systems Platforms Heidelberg,
Germany, November 12–16, 2001 Proceedings 2. Springer, 329–350.
[35] The Tokio rs team. 2025. Axum. =https://github.com/tokio-rs/axum.
[36] Fred B Schneider. 1990. Implementing fault-tolerant services using the state
machine approach: A tutorial. ACM Computing Surveys (CSUR) 22, 4 (1990),
299–319.
[37] Ion Stoica, Robert Morris, David Liben-Nowell, David R Karger, M Frans
Kaashoek, Frank Dabek, and Hari Balakrishnan. 2003. Chord: a scalable peer-
to-peer lookup protocol for internet applications. IEEE/ACM Transactions on
networking 11, 1 (2003), 17–32.
[38] I Storj Labs. 2018. Storj: A decentralized cloud storage network framework.
[39] Ewa Syta, Philipp Jovanovic, Eleftherios Kokoris Kogias, Nicolas Gailly, Linus
Gasser, Ismail Khoffi, Michael J Fischer, and Bryan Ford. 2017. Scalable bias-
resistant distributed randomness. In 2017 IEEE Symposium on Security and Privacy
𝐸(𝑖,𝑗)
Symbol at position (𝑖, 𝑗) of an encoded blob
𝑆𝑝
The set of primary slivers
𝑆𝑠
The set of secondary slivers
𝑆(𝑝,𝑛)
The primary sliver held by storage node 𝑛
𝑆(𝑠,𝑛)
The secondary sliver held by storage node 𝑛
{𝑆(𝑝,∗)}𝑓+1
Any set of 𝑓+ 1 primary slivers
𝑀𝑝
Metadata associated with the primary slivers
𝑀𝑠
Metadata associated with the secondary slivers
𝐷𝑛
The set of shards handled by node 𝑛
Table 2: Main notations
(SP). Ieee, 444–460.
[40] The Sui team. 2025. Build Beyond. =https://sui.io.
[41] Juan Pablo Timpanaro, Thibault Cholez, Isabelle Chrisment, and Olivier Festor.
2011. Bittorrent’s mainline dht security assessment. In 2011 4th IFIP International
Conference on New Technologies, Mobility and Security. IEEE, 1–5.
[42] David Vorick and Luke Champine. 2014. Sia: Simple decentralized storage.
Retrieved May 8 (2014), 2018.
[43] Dan S Wallach. 2002. A survey of peer-to-peer security issues. In International
symposium on software security. Springer, 42–57.
[44] Karl Werder, Balasubramaniam Ramesh, and Rongen Zhang. 2022. Establishing
data provenance for responsible artificial intelligence systems. ACM Transactions
on Management Information Systems (TMIS) 13, 2 (2022), 1–23.
[45] Sam Williams, Viktor Diordiiev, Lev Berman, and Ivan Uemlianin. 2019. Arweave:
A protocol for economically sustainable information permanence. Arweave Yellow
Paper (2019).
[46] Ennan Zhai, Ruichuan Chen, David Isaac Wolinsky, and Bryan Ford. 2014.
Heading Off Correlated Failures through {Independence-as-a-Service}. In 11th
USENIX Symposium on Operating Systems Design and Implementation (OSDI 14).
317–334.
A
Detailed Algorithms
This section supplements Section 4 by providing detailed algo-
rithms for clients (Algorithm 1) and storage nodes operations (Al-
gorithm 3).
In additional to the helper functions specified in Algorithm 2,
these algorithms also leverages the following (intuitive) functions:
ByteSize(𝐵) to compute the size of a blob 𝐵in bytes; MerkleTree(𝑣)
to compute a merkle tree over a vector input 𝑣; Hash(·) to compute
a cryptographic hash; ErasureEncode(𝐵), ErasureReconstruct(·),
and ErasureDecode(·), to respective erasure encode a blob 𝐵, re-
construct a blocb from enough erasure coded parts, and erasure
decode a blob as described in Section 3.3; HandledShards(𝑛) to
get the shards handled by a node 𝑛; and SplitIntoMatrix(·) to
reshape a matrix into the specified size.
Furthermore, the client and storage nodes use the following func-
tions to interact with the blockchain: ReserveBlob(·) to reserve
a blob id on the blockchain; StoreCertificate(·) to store a proof
of storage on the blockchain; IsRegistered(𝑖𝑑) to check if a blob
id 𝑖𝑑is registered on the blockchain; and ReadCertificate(𝑖𝑑) to
read a proof of storage of blob id 𝑖𝑑from the blockchain.
Table 2 summarizes the main notations used in the algorithms.
Subscripts of matrices and vectors denote access to a specific index.
Danezis et. al
Algorithm 1 Walrus client operations
1: nodes
⊲the committee of storage nodes
2: shards
⊲see Section 4
// Store a blob on the network
3: procedure StoreBlob(𝐵,𝑒𝑥𝑝𝑖𝑟𝑦)
4:
// Step 1: Pay and register the blob id on the blockchain
5:
(𝑆𝑝,𝑆𝑠) ←EncodeBlob(𝐵)
6:
𝑀←MakeMetadata(𝑆𝑝,𝑆𝑠)
7:
𝑖𝑑←MakeBlobId(𝑀)
8:
𝑠𝑖𝑧𝑒←ByteSize(𝐵)
⊲size in bytes
9:
ReserveBlob(𝑖𝑑,𝑠𝑖𝑧𝑒,𝑒𝑥𝑝𝑖𝑟𝑦)
⊲on blockchain
10:
11:
// Step 2: Send the encoded slivers to the storage nodes
12:
𝑅←{ }
⊲storage requests to send to nodes
13:
for 𝑛∈nodes do
14:
𝐷𝑛←HandledShards(𝑛)
⊲shards handed by node 𝑛
15:
𝑆(𝑝,𝑛) ←[𝑆𝑝
𝑖: 𝑖∈𝐷𝑛]
16:
𝑆(𝑠,𝑛) ←[𝑆𝑠
𝑖: 𝑖∈𝐷𝑛]
17:
StoreRqst ←(𝑖𝑑, 𝑀,𝑆(𝑝,𝑛),𝑆(𝑠,𝑛) )
18:
𝑅←𝑅∪{(𝑛, StoreRqst)}
19:
await2𝑓+1 : {𝑐←Send(𝑛,𝑟) : (𝑛,𝑟) ∈𝑅}
⊲wait for 2𝑓+ 1 confirmations
20:
21:
// Step 3: Record the proof of storage on the blockchain
22:
StoreCertificate({𝑐},𝑖𝑑)
⊲on blockchain
// Read metadata from the network
23: procedure RetrieveMetadata(𝑖𝑑)
24:
MetadataRqst ←(𝑖𝑑)
25:
𝐷←$ {0, shards}𝑛
⊲request all shards
26:
𝑁←{𝑛∈nodes s.t. ∃𝑠∈𝐷∩HandledShards(𝑛)}
27:
await2𝑓+1 : {𝑀←Send(𝑛, MetadataRqst) : 𝑛∈𝑁}
⊲wait for 2𝑓+ 1 responses
28:
if ∃𝑀∈{𝑀} s.t. MakeBlobId(𝑀) = 𝑖𝑑then return 𝑀
29:
return ⊥
// Read a blob from the network
30: procedure ReadBlob(𝑖𝑑)
31:
𝑀←RetrieveMetadata(𝑖𝑑)
32:
SliversRqst ←(𝑖𝑑)
33:
await2𝑓+1
:
{𝑆𝑠,𝑛)
←
Send(𝑛, SliversRqsts) s.t. 𝑛
∈
nodes
:
VerifySliver(𝑆(𝑠,𝑛), 𝑀)}
34:
𝐵←DecodeBlob({𝑆(𝑠,∗) }2𝑓+1, 𝑀)
35:
return 𝐵
Algorithm 2 Helper functions
1: nodes
⊲the committee of storage nodes
2: shards
⊲see Section 4
3: procedure EncodeBlob(𝐵)
4:
𝐸←ErasureEncode(𝐵)
⊲expand size: [(𝑓+ 1) × (2𝑓+ 1)] →[shards × shards]
5:
𝑆𝑝←[𝐸(𝑖,∗) : 𝑖∈[0, shards]]
⊲encoded primary slivers: [shards × 1]
6:
𝑆𝑠←[𝐸(∗,𝑖) : 𝑖∈[0, shards]]⊤
⊲encoded secondary slivers: [1 × shards]
7:
return (𝑆𝑝,𝑆𝑠)
8: procedure MakeMetadata(𝑆𝑝,𝑆𝑠)
9:
𝑀𝑝←[Hash(𝑠) : 𝑠∈𝑆𝑝]
⊲length: 2𝑓+ 1
10:
𝑀𝑠←[Hash(𝑠) : 𝑠∈𝑆𝑠]
⊲length: 𝑓+ 1
11:
𝑀←(𝑀𝑝, 𝑀𝑠)
12:
return 𝑀
13: procedure MakeBlobId(𝑀)
14:
(𝑀𝑝, 𝑀𝑠) ←𝑀
15:
𝑖𝑑←(MerkleTree(𝑀𝑝), MerkleTree(𝑀𝑠))
16:
return 𝑖𝑑
17: procedure VerifySliver(𝑆(∗,𝑛), 𝑀)
18:
(𝑀𝑝, 𝑀𝑠) ←𝑀
19:
return (Hash(𝑠) = 𝑀𝑝
𝑛: ∀𝑠∈𝑆(𝑝,𝑛) ) ∨(Hash(𝑠) = 𝑀𝑠𝑛: ∀𝑠∈𝑆(𝑠,𝑛) )
20: procedure DecodeBlob({𝑆(𝑝,∗) }𝑓+1, 𝑀)
21:
𝑆𝑝←ErasureReconstruct({𝑆(𝑝,∗) }𝑓+1)
⊲reconstruct encoded slivers
22:
𝐸←SplitIntoMatrix(𝑆𝑝)
⊲size: shard × shard
23:
𝑆𝑠←[𝐸(∗,𝑖) : 𝑖∈[0, shards]]⊤
24:
𝑀′ ←MakeMetadata(𝑆𝑝,𝑆𝑠)
25:
if 𝑀≠𝑀′ then return ⊥
⊲verify encoding correctness, see Section 4.2
26:
𝐵←ErasureDecode(𝐸)
⊲matrix: (𝑓+ 1) × (2𝑓+ 1)
27:
return 𝐵
Algorithm 3 Walrus store operations
1: n
⊲the identifier of the storage node
2: nodes
⊲the committee of storage nodes
3: shards
⊲see Section 4
4: db𝑚
⊲perists the metadata
5: db𝑏
⊲perists the slivers
// Store slivers
6: procedure StoreSlivers(StoreRqst)
7:
(𝑖𝑑, 𝑀,𝑆(𝑝,𝑛),𝑆(𝑠,𝑛) ) ←StoreRqst
8:
9:
// Check 1: Ensure the node is responsible for the shards
10:
𝐷𝑛←HandledShards(n)
11:
if ∃𝑠𝑖∈𝑆𝑝∪𝑆𝑠s.t. 𝑖∉𝐷𝑛then return ⊥
12:
13:
// Check 2: Verify the blob id is registered on chain
14:
if ¬IsRegistered(𝑖𝑑) then return ⊥
⊲read blockchain
15:
16:
// Check 3: Verify the metadata is correctly formed
17:
if ¬VerifySliver(𝑆(𝑝,𝑛), 𝑀) then return ⊥
18:
if ¬VerifySliver(𝑆(𝑠,𝑛), 𝑀) then return ⊥
19:
𝑖𝑑′ ←MakeBlobId(𝑀)
20:
if 𝑖𝑑≠𝑖𝑑′ then return ⊥
21:
22:
db𝑚[𝑖𝑑] ←𝑀
⊲persist the metadata
23:
db𝑏[𝑖𝑑] ←(𝑆(𝑝,𝑛),𝑆(𝑠,𝑛) )
⊲persist the slivers
24:
Send(𝑎𝑐𝑘)
⊲reply with an acknowledgment
// Server metadata
25: procedure ServeMetadata(MetadataRqst)
26:
𝑖𝑑←MetadataRqst
27:
return db𝑚[𝑖𝑑]
⊲return the metadata or ⊥if not found
28:
Reply(𝑎𝑐𝑘)
// Server slivers
29: procedure ServeSlivers(SliversRqst)
30:
𝑖𝑑←SliversRqst
31:
if ¬ReadCertificate(𝑖𝑑) then return ⊥
⊲proof of storage on the blockchain
32:
(𝑆(𝑝,𝑛),𝑆(𝑠,𝑛) ) ←db𝑏[𝑖𝑑]
⊲return the slivers or ⊥if not found
33:
Reply(𝑆(𝑠,𝑛) )
// Recover slivers
34: procedure RecoverSlivers(𝑖𝑑)
35:
𝑐←Client(nodes, shards)
⊲build a Walrus client (Algorithm 1)
36:
𝐵←𝑐.ReadBlob(𝑖𝑑)
37:
𝐷n ←HandledShards(n)
⊲shards handed by node 𝑛
38:
𝑆(𝑝,n) ←[𝑆𝑝
𝑖: 𝑖∈𝐷n]
39:
𝑆(𝑠,n) ←[𝑆𝑠
𝑖: 𝑖∈𝐷n]
40:
db𝑚[𝑖𝑑] ←𝑀
⊲persist the metadata
41:
db𝑏[𝑖𝑑] ←(𝑆(𝑝,n),𝑆(𝑠,n) )
⊲persist the slivers
